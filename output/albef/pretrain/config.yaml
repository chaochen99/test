alpha: 0.4
batch_size: 8
bert_config: /nlp_group/wuxing/ALBEF/configs/config_bert_chinese.json
embed_dim: 256
image_res: 256
mlm_probability: 0.15
momentum: 0.995
optimizer: {lr: 1e-05, opt: adamW, weight_decay: 0.02}
queue_size: 65536
schedular: {cooldown_epochs: 0, decay_rate: 1, epochs: 30, lr: 1e-05, min_lr: 1e-06,
  sched: cosine, warmup_epochs: 20, warmup_lr: 1e-06}
temp: 0.07
train_file: [/nlp_group/wuxing/yuhuimu/AB-layoutlmv3/data/dataset_albef.json]
vision_width: 768
