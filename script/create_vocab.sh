python ./src/create_vocab.py \
    --input_path /nlp_group/wuxing/yuhuimu/AB-layoutlmv3/data/dataset.json \
    --output_dir /nlp_group/wuxing/yuhuimu/AB-layoutlmv3/data/tokenizer_albef \
    --model_name hfl/chinese-roberta-wwm-ext \
    --vocab_size 50000