nohup: ignoring input
Namespace(batch_size=4, datasize=None, input_file='/nlp_group/wuxing/yuhuimu/AB-layoutlmv3/data/data_processed/', learning_rate=0.0001, max_epochs=2, model_name='microsoft/layoutlmv3-base-chinese', model_params=None, output_file_name='pretrained_debug.params', output_model_dir='/nlp_group/wuxing/yuhuimu/AB-layoutlmv3/output/debug/', pretrained='/nlp_group/wuxing/yuhuimu/AB-layoutlmv3/pytorch_model.bin', ratio_train=0.9, tokenizer_vocab_dir='/nlp_group/wuxing/yuhuimu/AB-layoutlmv3/data/tokenizer/')
Missing keys:  ['model.mask_token', 'HeadForMLM.bias', 'HeadForMLM.dense.weight', 'HeadForMLM.dense.bias', 'HeadForMLM.LayerNorm.weight', 'HeadForMLM.LayerNorm.bias', 'HeadForMLM.decoder.weight', 'HeadForMLM.decoder.bias', 'HeadForMIM.bias', 'HeadForMIM.dense.weight', 'HeadForMIM.dense.bias', 'HeadForMIM.LayerNorm.weight', 'HeadForMIM.LayerNorm.bias', 'HeadForMIM.decoder.weight', 'HeadForMIM.decoder.bias', 'HeadForWPA.bias', 'HeadForWPA.dense.weight', 'HeadForWPA.dense.bias', 'HeadForWPA.LayerNorm.weight', 'HeadForWPA.LayerNorm.bias', 'HeadForWPA.decoder.weight', 'HeadForWPA.decoder.bias']
Unexpected keys:  []
iter:  0
0  train_loss: 22.60223388671875, valid_loss: 22.4813711643219
epoch:0, iter:0, 0,  train_loss: 22.60223388671875, valid_loss: 22.4813711643219, idiv_loss:(12.567061722278595, 9.19157087802887, 0.7227386943995953), acc:(0.0, 0.0)
14  train_loss: 19.586809158325195, valid_loss: 20.17204260826111
epoch:0, iter:14, 14,  train_loss: 19.586809158325195, valid_loss: 20.17204260826111, idiv_loss:(10.42309820652008, 8.743230521678925, 1.0057136975228786), acc:(0.07377581670880318, 0.0018862235156120732)
28  train_loss: 17.418842315673828, valid_loss: 17.092280387878418
epoch:0, iter:28, 28,  train_loss: 17.418842315673828, valid_loss: 17.092280387878418, idiv_loss:(8.440950334072113, 8.026170015335083, 0.625160189345479), acc:(0.07367199612781405, 0.013787139861960895)
42  train_loss: 15.224747657775879, valid_loss: 14.997944235801697
epoch:0, iter:42, 42,  train_loss: 15.224747657775879, valid_loss: 14.997944235801697, idiv_loss:(6.739966005086899, 7.613540917634964, 0.6444372870028019), acc:(0.07367199612781405, 0.01714497276407201)
56  train_loss: 13.435384750366211, valid_loss: 13.32432734966278
epoch:0, iter:56, 56,  train_loss: 13.435384750366211, valid_loss: 13.32432734966278, idiv_loss:(5.311122477054596, 7.404972434043884, 0.6082324925810099), acc:(0.07181786466389894, 0.02721730350458529)
70  train_loss: 12.50405502319336, valid_loss: 12.705649495124817
epoch:0, iter:70, 70,  train_loss: 12.50405502319336, valid_loss: 12.705649495124817, idiv_loss:(4.530732244253159, 7.316403448581696, 0.8585138954222202), acc:(0.07367199612781405, 0.021352418611058965)
84  train_loss: 11.742130279541016, valid_loss: 11.927901923656464
epoch:0, iter:84, 84,  train_loss: 11.742130279541016, valid_loss: 11.927901923656464, idiv_loss:(4.182015359401703, 7.150251090526581, 0.5956355333328247), acc:(0.07367199612781405, 0.02702024599420838)
98  train_loss: 11.387526512145996, valid_loss: 11.877076923847198
epoch:0, iter:98, 98,  train_loss: 11.387526512145996, valid_loss: 11.877076923847198, idiv_loss:(4.080842047929764, 7.080819845199585, 0.715415058657527), acc:(0.07350097317248583, 0.02890942245721817)
112  train_loss: 11.712042808532715, valid_loss: 11.502681732177734
epoch:0, iter:112, 112,  train_loss: 11.712042808532715, valid_loss: 11.502681732177734, idiv_loss:(4.01149420440197, 7.024302423000336, 0.46688517183065414), acc:(0.07312679337337613, 0.037289748986950144)
126  train_loss: 11.421943664550781, valid_loss: 11.387584865093231
epoch:0, iter:126, 126,  train_loss: 11.421943664550781, valid_loss: 11.387584865093231, idiv_loss:(4.005264222621918, 6.9552390575408936, 0.42708168691024184), acc:(0.07128182495944202, 0.037887993807089515)
140  train_loss: 10.943896293640137, valid_loss: 11.287741243839264
epoch:0, iter:140, 140,  train_loss: 10.943896293640137, valid_loss: 11.287741243839264, idiv_loss:(3.9976630806922913, 6.918780744075775, 0.3712973203510046), acc:(0.050023611169308424, 0.03583079398958944)
epoch 0 11.137373924255371
143  train_loss: 10.607638359069824, valid_loss: 11.607355773448944
epoch:1, iter:143, 0,  train_loss: 10.607638359069824, valid_loss: 11.607355773448944, idiv_loss:(3.992415741086006, 7.229167222976685, 0.38577287271618843), acc:(0.06394480518065393, 0.021368647314375266)
157  train_loss: 11.77998161315918, valid_loss: 12.15974110364914
epoch:1, iter:157, 14,  train_loss: 11.77998161315918, valid_loss: 12.15974110364914, idiv_loss:(3.991482824087143, 7.525479882955551, 0.642778292298317), acc:(0.06377769121900201, 0.010017508378950879)
171  train_loss: 11.669493675231934, valid_loss: 12.14402037858963
epoch:1, iter:171, 28,  train_loss: 11.669493675231934, valid_loss: 12.14402037858963, idiv_loss:(3.9748405665159225, 7.552859246730804, 0.6163206491619349), acc:(0.07362779369577765, 0.010868326513445936)
185  train_loss: 11.75897216796875, valid_loss: 12.226594090461731
epoch:1, iter:185, 42,  train_loss: 11.75897216796875, valid_loss: 12.226594090461731, idiv_loss:(3.9711755514144897, 7.540830820798874, 0.7145878076553345), acc:(0.07006559055298567, 0.010035704108304344)
199  train_loss: 11.943821907043457, valid_loss: 12.184011995792389
epoch:1, iter:199, 56,  train_loss: 11.943821907043457, valid_loss: 12.184011995792389, idiv_loss:(3.9847392439842224, 7.543320894241333, 0.6559516899287701), acc:(0.0633901150431484, 0.01211623172275722)
213  train_loss: 12.040109634399414, valid_loss: 12.248516738414764
epoch:1, iter:213, 70,  train_loss: 12.040109634399414, valid_loss: 12.248516738414764, idiv_loss:(3.9725315272808075, 7.53501957654953, 0.7409656308591366), acc:(0.06649182736873627, 0.011077356728492305)
227  train_loss: 12.003548622131348, valid_loss: 12.108623504638672
epoch:1, iter:227, 84,  train_loss: 12.003548622131348, valid_loss: 12.108623504638672, idiv_loss:(3.955695614218712, 7.526670724153519, 0.6262572817504406), acc:(0.07225428149104118, 0.011077356728492305)
241  train_loss: 11.710371017456055, valid_loss: 12.15165489912033
epoch:1, iter:241, 98,  train_loss: 11.710371017456055, valid_loss: 12.15165489912033, idiv_loss:(3.9885089844465256, 7.531881421804428, 0.6312644872814417), acc:(0.07114379899576306, 0.011077356728492305)
255  train_loss: 11.872750282287598, valid_loss: 12.119997143745422
epoch:1, iter:255, 112,  train_loss: 11.872750282287598, valid_loss: 12.119997143745422, idiv_loss:(3.965428501367569, 7.526663601398468, 0.6279050931334496), acc:(0.07317577302455902, 0.011077356728492305)
269  train_loss: 11.985434532165527, valid_loss: 12.20475858449936
epoch:1, iter:269, 126,  train_loss: 11.985434532165527, valid_loss: 12.20475858449936, idiv_loss:(3.9539569318294525, 7.526544004678726, 0.7242576070129871), acc:(0.07367199612781405, 0.011077356728492305)
283  train_loss: 12.228867530822754, valid_loss: 12.156734824180603
epoch:1, iter:283, 140,  train_loss: 12.228867530822754, valid_loss: 12.156734824180603, idiv_loss:(3.950860872864723, 7.519737988710403, 0.6861359542235732), acc:(0.07320789294317365, 0.011285690095974132)
epoch 1 11.869115829467773
/opt/conda/envs/layoutlmv3/lib/python3.7/site-packages/transformers/modeling_utils.py:831: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.
  "The `device` argument is deprecated and will be removed in v5 of Transformers.", FutureWarning
