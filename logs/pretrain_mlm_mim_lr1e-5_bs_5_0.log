/opt/conda/envs/layoutlmv3/lib/python3.7/site-packages/torch/distributed/launch.py:188: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  FutureWarning,
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Namespace(batch_size=5, datasize=None, device='cuda', dist_url='env://', input_file='/nlp_group/wuxing/yuhuimu/AB-layoutlmv3/data/data_processed_ori/', learning_rate=1e-05, max_epochs=20, model_name='microsoft/layoutlmv3-base-chinese', model_params=None, output_model_dir='/nlp_group/wuxing/yuhuimu/AB-layoutlmv3/output/pretrain_mlm_mim_lr1e-5_bs_5/', pretrained='/nlp_group/wuxing/yuhuimu/AB-layoutlmv3/pytorch_model.bin', ratio_train=0.9, seed=42, tokenizer_vocab_dir='/nlp_group/wuxing/yuhuimu/AB-layoutlmv3/data/tokenizer/', world_size=1)Namespace(batch_size=5, datasize=None, device='cuda', dist_url='env://', input_file='/nlp_group/wuxing/yuhuimu/AB-layoutlmv3/data/data_processed_ori/', learning_rate=1e-05, max_epochs=20, model_name='microsoft/layoutlmv3-base-chinese', model_params=None, output_model_dir='/nlp_group/wuxing/yuhuimu/AB-layoutlmv3/output/pretrain_mlm_mim_lr1e-5_bs_5/', pretrained='/nlp_group/wuxing/yuhuimu/AB-layoutlmv3/pytorch_model.bin', ratio_train=0.9, seed=42, tokenizer_vocab_dir='/nlp_group/wuxing/yuhuimu/AB-layoutlmv3/data/tokenizer/', world_size=1)

Namespace(batch_size=5, datasize=None, device='cuda', dist_url='env://', input_file='/nlp_group/wuxing/yuhuimu/AB-layoutlmv3/data/data_processed_ori/', learning_rate=1e-05, max_epochs=20, model_name='microsoft/layoutlmv3-base-chinese', model_params=None, output_model_dir='/nlp_group/wuxing/yuhuimu/AB-layoutlmv3/output/pretrain_mlm_mim_lr1e-5_bs_5/', pretrained='/nlp_group/wuxing/yuhuimu/AB-layoutlmv3/pytorch_model.bin', ratio_train=0.9, seed=42, tokenizer_vocab_dir='/nlp_group/wuxing/yuhuimu/AB-layoutlmv3/data/tokenizer/', world_size=1)
Namespace(batch_size=5, datasize=None, device='cuda', dist_url='env://', input_file='/nlp_group/wuxing/yuhuimu/AB-layoutlmv3/data/data_processed_ori/', learning_rate=1e-05, max_epochs=20, model_name='microsoft/layoutlmv3-base-chinese', model_params=None, output_model_dir='/nlp_group/wuxing/yuhuimu/AB-layoutlmv3/output/pretrain_mlm_mim_lr1e-5_bs_5/', pretrained='/nlp_group/wuxing/yuhuimu/AB-layoutlmv3/pytorch_model.bin', ratio_train=0.9, seed=42, tokenizer_vocab_dir='/nlp_group/wuxing/yuhuimu/AB-layoutlmv3/data/tokenizer/', world_size=1)
| distributed init (rank 0, word 4): env://
| distributed init (rank 1, word 4): env://
| distributed init (rank 3, word 4): env://
| distributed init (rank 2, word 4): env://
ai-platform-wlf1-ge10-1:85751:85751 [0] NCCL INFO Bootstrap : Using eth01:10.80.205.179<0>
ai-platform-wlf1-ge10-1:85751:85751 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
ai-platform-wlf1-ge10-1:85751:85751 [0] NCCL INFO cudaDriverVersion 11040
NCCL version 2.14.3+cuda11.7
ai-platform-wlf1-ge10-1:85753:85753 [2] NCCL INFO cudaDriverVersion 11040
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO Failed to open libibverbs.so[.1]
ai-platform-wlf1-ge10-1:85753:85753 [2] NCCL INFO Bootstrap : Using eth01:10.80.205.179<0>
ai-platform-wlf1-ge10-1:85753:85753 [2] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO NET/Socket : Using [0]eth01:10.80.205.179<0>
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO Using network Socket
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO Failed to open libibverbs.so[.1]
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO NET/Socket : Using [0]eth01:10.80.205.179<0>
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO Using network Socket
ai-platform-wlf1-ge10-1:85755:85755 [3] NCCL INFO cudaDriverVersion 11040
ai-platform-wlf1-ge10-1:85755:85755 [3] NCCL INFO Bootstrap : Using eth01:10.80.205.179<0>
ai-platform-wlf1-ge10-1:85755:85755 [3] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO Failed to open libibverbs.so[.1]
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO NET/Socket : Using [0]eth01:10.80.205.179<0>
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO Using network Socket
ai-platform-wlf1-ge10-1:85752:85752 [1] NCCL INFO cudaDriverVersion 11040
ai-platform-wlf1-ge10-1:85752:85752 [1] NCCL INFO Bootstrap : Using eth01:10.80.205.179<0>
ai-platform-wlf1-ge10-1:85752:85752 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO Failed to open libibverbs.so[.1]
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO NET/Socket : Using [0]eth01:10.80.205.179<0>
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO Using network Socket
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO Could not enable P2P between dev 1(=24000) and dev 0(=1000)
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO Could not enable P2P between dev 2(=81000) and dev 0(=1000)
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO Could not enable P2P between dev 3(=e1000) and dev 0(=1000)
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO Could not enable P2P between dev 0(=1000) and dev 1(=24000)
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO Could not enable P2P between dev 2(=81000) and dev 1(=24000)
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO Could not enable P2P between dev 3(=e1000) and dev 1(=24000)
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO Could not enable P2P between dev 0(=1000) and dev 2(=81000)
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO Could not enable P2P between dev 1(=24000) and dev 2(=81000)
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO Could not enable P2P between dev 3(=e1000) and dev 2(=81000)
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO Could not enable P2P between dev 0(=1000) and dev 3(=e1000)
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO Could not enable P2P between dev 1(=24000) and dev 3(=e1000)
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO Could not enable P2P between dev 2(=81000) and dev 3(=e1000)
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO Could not enable P2P between dev 1(=24000) and dev 0(=1000)
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO Could not enable P2P between dev 2(=81000) and dev 0(=1000)
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO Could not enable P2P between dev 3(=e1000) and dev 0(=1000)
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO Could not enable P2P between dev 0(=1000) and dev 1(=24000)
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO Could not enable P2P between dev 2(=81000) and dev 1(=24000)
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO Could not enable P2P between dev 3(=e1000) and dev 1(=24000)
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO Could not enable P2P between dev 0(=1000) and dev 2(=81000)
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO Could not enable P2P between dev 1(=24000) and dev 2(=81000)
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO Could not enable P2P between dev 1(=24000) and dev 0(=1000)
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO Could not enable P2P between dev 3(=e1000) and dev 2(=81000)
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO Could not enable P2P between dev 2(=81000) and dev 0(=1000)
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO Could not enable P2P between dev 3(=e1000) and dev 0(=1000)
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO Could not enable P2P between dev 0(=1000) and dev 3(=e1000)
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO Could not enable P2P between dev 1(=24000) and dev 3(=e1000)
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO Could not enable P2P between dev 0(=1000) and dev 1(=24000)
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO Could not enable P2P between dev 2(=81000) and dev 3(=e1000)
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO Could not enable P2P between dev 2(=81000) and dev 1(=24000)
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO Could not enable P2P between dev 3(=e1000) and dev 1(=24000)
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO Setting affinity for GPU 1 to ffffffff,00000000,ffffffff
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO Could not enable P2P between dev 0(=1000) and dev 2(=81000)
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO Could not enable P2P between dev 1(=24000) and dev 2(=81000)
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO Could not enable P2P between dev 3(=e1000) and dev 2(=81000)
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO Could not enable P2P between dev 0(=1000) and dev 3(=e1000)
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO Could not enable P2P between dev 1(=24000) and dev 3(=e1000)
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO Could not enable P2P between dev 2(=81000) and dev 3(=e1000)
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO Could not enable P2P between dev 1(=24000) and dev 0(=1000)
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO Could not enable P2P between dev 2(=81000) and dev 0(=1000)
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO Could not enable P2P between dev 3(=e1000) and dev 0(=1000)
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO Could not enable P2P between dev 0(=1000) and dev 1(=24000)
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO Could not enable P2P between dev 2(=81000) and dev 1(=24000)
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO Could not enable P2P between dev 3(=e1000) and dev 1(=24000)
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO Could not enable P2P between dev 0(=1000) and dev 2(=81000)
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO Could not enable P2P between dev 1(=24000) and dev 2(=81000)
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO Could not enable P2P between dev 3(=e1000) and dev 2(=81000)
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO Could not enable P2P between dev 0(=1000) and dev 3(=e1000)
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO Could not enable P2P between dev 1(=24000) and dev 3(=e1000)
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO Could not enable P2P between dev 1(=24000) and dev 0(=1000)
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO Could not enable P2P between dev 2(=81000) and dev 3(=e1000)
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO Could not enable P2P between dev 2(=81000) and dev 0(=1000)
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO Could not enable P2P between dev 3(=e1000) and dev 0(=1000)
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO Setting affinity for GPU 0 to ffffffff,00000000,ffffffff
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO Could not enable P2P between dev 0(=1000) and dev 1(=24000)
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO Could not enable P2P between dev 2(=81000) and dev 1(=24000)
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO Could not enable P2P between dev 3(=e1000) and dev 1(=24000)
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO Could not enable P2P between dev 0(=1000) and dev 2(=81000)
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO Could not enable P2P between dev 1(=24000) and dev 2(=81000)
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO Could not enable P2P between dev 3(=e1000) and dev 2(=81000)
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO Could not enable P2P between dev 0(=1000) and dev 3(=e1000)
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO Could not enable P2P between dev 1(=24000) and dev 3(=e1000)
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO Could not enable P2P between dev 2(=81000) and dev 3(=e1000)
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO Could not enable P2P between dev 1(=24000) and dev 0(=1000)
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO Could not enable P2P between dev 2(=81000) and dev 0(=1000)
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO Could not enable P2P between dev 3(=e1000) and dev 0(=1000)
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO Could not enable P2P between dev 0(=1000) and dev 1(=24000)
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO Could not enable P2P between dev 2(=81000) and dev 1(=24000)
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO Could not enable P2P between dev 3(=e1000) and dev 1(=24000)
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO Could not enable P2P between dev 0(=1000) and dev 2(=81000)
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO Could not enable P2P between dev 1(=24000) and dev 2(=81000)
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO Could not enable P2P between dev 3(=e1000) and dev 2(=81000)
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO Could not enable P2P between dev 0(=1000) and dev 3(=e1000)
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO Could not enable P2P between dev 1(=24000) and dev 3(=e1000)
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO Could not enable P2P between dev 2(=81000) and dev 3(=e1000)
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO Setting affinity for GPU 2 to ffffffff,00000000,ffffffff,00000000
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO Could not enable P2P between dev 1(=24000) and dev 0(=1000)
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO Could not enable P2P between dev 2(=81000) and dev 0(=1000)
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO Could not enable P2P between dev 3(=e1000) and dev 0(=1000)
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO Could not enable P2P between dev 0(=1000) and dev 1(=24000)
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO Could not enable P2P between dev 2(=81000) and dev 1(=24000)
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO Could not enable P2P between dev 3(=e1000) and dev 1(=24000)
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO Could not enable P2P between dev 0(=1000) and dev 2(=81000)
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO Could not enable P2P between dev 1(=24000) and dev 2(=81000)
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO Could not enable P2P between dev 3(=e1000) and dev 2(=81000)
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO Could not enable P2P between dev 0(=1000) and dev 3(=e1000)
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO Could not enable P2P between dev 1(=24000) and dev 3(=e1000)
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO Could not enable P2P between dev 2(=81000) and dev 3(=e1000)
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO Could not enable P2P between dev 1(=24000) and dev 0(=1000)
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO Could not enable P2P between dev 2(=81000) and dev 0(=1000)
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO Could not enable P2P between dev 3(=e1000) and dev 0(=1000)
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO Could not enable P2P between dev 0(=1000) and dev 1(=24000)
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO Could not enable P2P between dev 2(=81000) and dev 1(=24000)
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO Could not enable P2P between dev 3(=e1000) and dev 1(=24000)
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO Could not enable P2P between dev 0(=1000) and dev 2(=81000)
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO Could not enable P2P between dev 1(=24000) and dev 2(=81000)
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO Could not enable P2P between dev 3(=e1000) and dev 2(=81000)
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO Could not enable P2P between dev 0(=1000) and dev 3(=e1000)
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO Could not enable P2P between dev 1(=24000) and dev 3(=e1000)
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO Could not enable P2P between dev 2(=81000) and dev 3(=e1000)
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,00000000,ffffffff,00000000
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO Channel 00/04 :    0   1   2   3
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO Channel 01/04 :    0   1   2   3
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO Channel 02/04 :    0   1   2   3
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO Channel 03/04 :    0   1   2   3
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO Could not enable P2P between dev 2(=81000) and dev 1(=24000)
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO Could not enable P2P between dev 1(=24000) and dev 0(=1000)
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO Could not enable P2P between dev 3(=e1000) and dev 2(=81000)
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO Could not enable P2P between dev 0(=1000) and dev 3(=e1000)
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO Could not enable P2P between dev 2(=81000) and dev 1(=24000)
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO Could not enable P2P between dev 0(=1000) and dev 3(=e1000)
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO Could not enable P2P between dev 1(=24000) and dev 0(=1000)
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO Could not enable P2P between dev 3(=e1000) and dev 2(=81000)
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO Could not enable P2P between dev 2(=81000) and dev 1(=24000)
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO Could not enable P2P between dev 1(=24000) and dev 0(=1000)
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO Could not enable P2P between dev 0(=1000) and dev 3(=e1000)
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO Could not enable P2P between dev 3(=e1000) and dev 2(=81000)
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO Could not enable P2P between dev 2(=81000) and dev 1(=24000)
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO Could not enable P2P between dev 1(=24000) and dev 0(=1000)
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO Could not enable P2P between dev 0(=1000) and dev 3(=e1000)
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO Could not enable P2P between dev 3(=e1000) and dev 2(=81000)
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO Could not enable P2P between dev 2(=81000) and dev 3(=e1000)
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO Channel 00 : 2[81000] -> 3[e1000] via SHM/direct/direct
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO Could not enable P2P between dev 2(=81000) and dev 3(=e1000)
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO Channel 01 : 2[81000] -> 3[e1000] via SHM/direct/direct
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO Could not enable P2P between dev 2(=81000) and dev 3(=e1000)
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO Channel 02 : 2[81000] -> 3[e1000] via SHM/direct/direct
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO Could not enable P2P between dev 2(=81000) and dev 3(=e1000)
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO Channel 03 : 2[81000] -> 3[e1000] via SHM/direct/direct
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO Could not enable P2P between dev 1(=24000) and dev 2(=81000)
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO Could not enable P2P between dev 0(=1000) and dev 1(=24000)
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO Could not enable P2P between dev 3(=e1000) and dev 0(=1000)
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO Channel 00 : 0[1000] -> 1[24000] via SHM/direct/direct
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO Could not enable P2P between dev 0(=1000) and dev 1(=24000)
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO Channel 00 : 1[24000] -> 2[81000] via SHM/direct/direct
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO Could not enable P2P between dev 1(=24000) and dev 2(=81000)
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO Channel 00 : 3[e1000] -> 0[1000] via SHM/direct/direct
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO Could not enable P2P between dev 3(=e1000) and dev 0(=1000)
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO Channel 01 : 0[1000] -> 1[24000] via SHM/direct/direct
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO Could not enable P2P between dev 0(=1000) and dev 1(=24000)
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO Channel 01 : 1[24000] -> 2[81000] via SHM/direct/direct
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO Could not enable P2P between dev 1(=24000) and dev 2(=81000)
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO Channel 01 : 3[e1000] -> 0[1000] via SHM/direct/direct
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO Could not enable P2P between dev 3(=e1000) and dev 0(=1000)
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO Channel 02 : 0[1000] -> 1[24000] via SHM/direct/direct
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO Could not enable P2P between dev 0(=1000) and dev 1(=24000)
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO Channel 02 : 1[24000] -> 2[81000] via SHM/direct/direct
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO Could not enable P2P between dev 1(=24000) and dev 2(=81000)
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO Channel 02 : 3[e1000] -> 0[1000] via SHM/direct/direct
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO Could not enable P2P between dev 3(=e1000) and dev 0(=1000)
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO Channel 03 : 0[1000] -> 1[24000] via SHM/direct/direct
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO Channel 03 : 1[24000] -> 2[81000] via SHM/direct/direct
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO Channel 03 : 3[e1000] -> 0[1000] via SHM/direct/direct
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO Connected all rings
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO Could not enable P2P between dev 0(=1000) and dev 1(=24000)
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO Connected all rings
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO Could not enable P2P between dev 2(=81000) and dev 3(=e1000)
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO Connected all rings
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO Could not enable P2P between dev 1(=24000) and dev 2(=81000)
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO Connected all rings
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO Could not enable P2P between dev 3(=e1000) and dev 2(=81000)
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO Channel 00 : 3[e1000] -> 2[81000] via SHM/direct/direct
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO Could not enable P2P between dev 3(=e1000) and dev 2(=81000)
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO Channel 01 : 3[e1000] -> 2[81000] via SHM/direct/direct
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO Could not enable P2P between dev 3(=e1000) and dev 2(=81000)
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO Channel 02 : 3[e1000] -> 2[81000] via SHM/direct/direct
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO Could not enable P2P between dev 3(=e1000) and dev 2(=81000)
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO Channel 03 : 3[e1000] -> 2[81000] via SHM/direct/direct
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO Could not enable P2P between dev 0(=1000) and dev 1(=24000)
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO Could not enable P2P between dev 2(=81000) and dev 3(=e1000)
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO Could not enable P2P between dev 1(=24000) and dev 2(=81000)
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO Could not enable P2P between dev 0(=1000) and dev 1(=24000)
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO Could not enable P2P between dev 2(=81000) and dev 3(=e1000)
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO Could not enable P2P between dev 1(=24000) and dev 2(=81000)
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO Could not enable P2P between dev 2(=81000) and dev 3(=e1000)
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO Could not enable P2P between dev 1(=24000) and dev 2(=81000)
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO Could not enable P2P between dev 0(=1000) and dev 1(=24000)
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO Could not enable P2P between dev 2(=81000) and dev 1(=24000)
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO Channel 00 : 2[81000] -> 1[24000] via SHM/direct/direct
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO Could not enable P2P between dev 2(=81000) and dev 1(=24000)
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO Channel 01 : 2[81000] -> 1[24000] via SHM/direct/direct
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO Could not enable P2P between dev 2(=81000) and dev 1(=24000)
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO Channel 02 : 2[81000] -> 1[24000] via SHM/direct/direct
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO Could not enable P2P between dev 2(=81000) and dev 1(=24000)
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO Could not enable P2P between dev 1(=24000) and dev 0(=1000)
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO Channel 03 : 2[81000] -> 1[24000] via SHM/direct/direct
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO Channel 00 : 1[24000] -> 0[1000] via SHM/direct/direct
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO Could not enable P2P between dev 1(=24000) and dev 0(=1000)
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO Channel 01 : 1[24000] -> 0[1000] via SHM/direct/direct
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO Could not enable P2P between dev 1(=24000) and dev 0(=1000)
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO Channel 02 : 1[24000] -> 0[1000] via SHM/direct/direct
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO Could not enable P2P between dev 1(=24000) and dev 0(=1000)
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO Channel 03 : 1[24000] -> 0[1000] via SHM/direct/direct
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO Connected all trees
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO Connected all trees
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO Connected all trees
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO Connected all trees
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
ai-platform-wlf1-ge10-1:85752:85791 [1] NCCL INFO comm 0x42db0530 rank 1 nranks 4 cudaDev 1 busId 24000 - Init COMPLETE
ai-platform-wlf1-ge10-1:85755:85790 [3] NCCL INFO comm 0x430b9890 rank 3 nranks 4 cudaDev 3 busId e1000 - Init COMPLETE
ai-platform-wlf1-ge10-1:85753:85789 [2] NCCL INFO comm 0x436e6450 rank 2 nranks 4 cudaDev 2 busId 81000 - Init COMPLETE
ai-platform-wlf1-ge10-1:85751:85788 [0] NCCL INFO comm 0x431a23f0 rank 0 nranks 4 cudaDev 0 busId 1000 - Init COMPLETE
The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. 
The tokenizer class you load from this checkpoint is 'XLMRobertaTokenizer'. 
The class this function is called from is 'LayoutLMv3Tokenizer_cn'.
The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. 
The tokenizer class you load from this checkpoint is 'XLMRobertaTokenizer'. 
The class this function is called from is 'LayoutLMv3Tokenizer_cn'.
The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. 
The tokenizer class you load from this checkpoint is 'XLMRobertaTokenizer'. 
The class this function is called from is 'LayoutLMv3Tokenizer_cn'.
The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. 
The tokenizer class you load from this checkpoint is 'XLMRobertaTokenizer'. 
The class this function is called from is 'LayoutLMv3Tokenizer_cn'.
Missing keys:  ['model.mask_token', 'HeadForMLM.bias', 'HeadForMLM.dense.weight', 'HeadForMLM.dense.bias', 'HeadForMLM.LayerNorm.weight', 'HeadForMLM.LayerNorm.bias', 'HeadForMLM.decoder.weight', 'HeadForMLM.decoder.bias', 'HeadForMIM.bias', 'HeadForMIM.dense.weight', 'HeadForMIM.dense.bias', 'HeadForMIM.LayerNorm.weight', 'HeadForMIM.LayerNorm.bias', 'HeadForMIM.decoder.weight', 'HeadForMIM.decoder.bias']
Unexpected keys:  []
Create Dataset
Create Sampler
Create Dataloader
iter:  0
Start training
/opt/conda/envs/layoutlmv3/lib/python3.7/site-packages/transformers/modeling_utils.py:831: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.
  "The `device` argument is deprecated and will be removed in v5 of Transformers.", FutureWarning
/opt/conda/envs/layoutlmv3/lib/python3.7/site-packages/transformers/modeling_utils.py:831: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.
  "The `device` argument is deprecated and will be removed in v5 of Transformers.", FutureWarning
/opt/conda/envs/layoutlmv3/lib/python3.7/site-packages/transformers/modeling_utils.py:831: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.
  "The `device` argument is deprecated and will be removed in v5 of Transformers.", FutureWarning
/opt/conda/envs/layoutlmv3/lib/python3.7/site-packages/transformers/modeling_utils.py:831: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.
  "The `device` argument is deprecated and will be removed in v5 of Transformers.", FutureWarning
[W reducer.cpp:1298] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1298] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1298] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1298] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
Train Epoch: [0]  [   0/4855]  eta: 13:22:37  lr: 0.000000  ml_loss: 12.4445  mi_loss: 9.0357  train_loss: 21.4802  time: 9.9192  data: 3.0493  max mem: 15331
Train Epoch: [0]  [  50/4855]  eta: 3:31:02  lr: 0.000000  ml_loss: 12.4289  mi_loss: 9.0388  train_loss: 21.4677  time: 2.4982  data: 0.0001  max mem: 20903
Train Epoch: [0]  [ 100/4855]  eta: 3:22:55  lr: 0.000000  ml_loss: 12.4035  mi_loss: 9.0434  train_loss: 21.4470  time: 2.4840  data: 0.0001  max mem: 20903
Train Epoch: [0]  [ 150/4855]  eta: 3:18:59  lr: 0.000000  ml_loss: 12.3879  mi_loss: 9.0252  train_loss: 21.4131  time: 2.4907  data: 0.0001  max mem: 20903
Train Epoch: [0]  [ 200/4855]  eta: 3:16:01  lr: 0.000000  ml_loss: 12.2781  mi_loss: 9.0363  train_loss: 21.3144  time: 2.4960  data: 0.0001  max mem: 20903
Train Epoch: [0]  [ 250/4855]  eta: 3:13:26  lr: 0.000001  ml_loss: 12.1930  mi_loss: 8.9868  train_loss: 21.1798  time: 2.5007  data: 0.0001  max mem: 20903
Train Epoch: [0]  [ 300/4855]  eta: 3:10:48  lr: 0.000001  ml_loss: 12.1231  mi_loss: 9.0016  train_loss: 21.1247  time: 2.4839  data: 0.0001  max mem: 20903
Train Epoch: [0]  [ 350/4855]  eta: 3:08:33  lr: 0.000001  ml_loss: 11.9300  mi_loss: 8.9230  train_loss: 20.8530  time: 2.5101  data: 0.0001  max mem: 20903
Train Epoch: [0]  [ 400/4855]  eta: 3:06:12  lr: 0.000001  ml_loss: 11.8211  mi_loss: 8.9131  train_loss: 20.7342  time: 2.4742  data: 0.0001  max mem: 20903
Train Epoch: [0]  [ 450/4855]  eta: 3:03:53  lr: 0.000001  ml_loss: 11.7350  mi_loss: 8.9083  train_loss: 20.6434  time: 2.4713  data: 0.0001  max mem: 20903
Train Epoch: [0]  [ 500/4855]  eta: 3:01:36  lr: 0.000001  ml_loss: 11.5848  mi_loss: 8.7987  train_loss: 20.3836  time: 2.4660  data: 0.0001  max mem: 20903
Train Epoch: [0]  [ 550/4855]  eta: 2:59:21  lr: 0.000001  ml_loss: 11.3826  mi_loss: 8.7547  train_loss: 20.1373  time: 2.4909  data: 0.0001  max mem: 20903
Train Epoch: [0]  [ 600/4855]  eta: 2:57:07  lr: 0.000001  ml_loss: 11.3411  mi_loss: 8.7136  train_loss: 20.0547  time: 2.4734  data: 0.0001  max mem: 20903
Train Epoch: [0]  [ 650/4855]  eta: 2:54:53  lr: 0.000001  ml_loss: 11.3099  mi_loss: 8.6421  train_loss: 19.9520  time: 2.4640  data: 0.0001  max mem: 20903
Train Epoch: [0]  [ 700/4855]  eta: 2:52:42  lr: 0.000001  ml_loss: 11.1549  mi_loss: 8.6024  train_loss: 19.7573  time: 2.4696  data: 0.0001  max mem: 20903
Train Epoch: [0]  [ 750/4855]  eta: 2:50:31  lr: 0.000002  ml_loss: 11.2846  mi_loss: 8.5700  train_loss: 19.8546  time: 2.4711  data: 0.0001  max mem: 20903
Train Epoch: [0]  [ 800/4855]  eta: 2:48:19  lr: 0.000002  ml_loss: 10.9688  mi_loss: 8.3925  train_loss: 19.3613  time: 2.4679  data: 0.0001  max mem: 20903
Train Epoch: [0]  [ 850/4855]  eta: 2:46:13  lr: 0.000002  ml_loss: 10.9441  mi_loss: 8.4338  train_loss: 19.3780  time: 2.4951  data: 0.0001  max mem: 20903
Train Epoch: [0]  [ 900/4855]  eta: 2:44:07  lr: 0.000002  ml_loss: 10.8348  mi_loss: 8.2765  train_loss: 19.1113  time: 2.4661  data: 0.0001  max mem: 20903
Train Epoch: [0]  [ 950/4855]  eta: 2:42:00  lr: 0.000002  ml_loss: 10.7306  mi_loss: 8.0453  train_loss: 18.7758  time: 2.4796  data: 0.0001  max mem: 20903
Train Epoch: [0]  [1000/4855]  eta: 2:39:57  lr: 0.000002  ml_loss: 10.7355  mi_loss: 8.1928  train_loss: 18.9283  time: 2.5031  data: 0.0001  max mem: 20903
Train Epoch: [0]  [1050/4855]  eta: 2:37:54  lr: 0.000002  ml_loss: 10.4782  mi_loss: 8.1256  train_loss: 18.6038  time: 2.4934  data: 0.0001  max mem: 20903
Train Epoch: [0]  [1100/4855]  eta: 2:35:51  lr: 0.000002  ml_loss: 10.2966  mi_loss: 8.0506  train_loss: 18.3472  time: 2.4934  data: 0.0001  max mem: 20903
Train Epoch: [0]  [1150/4855]  eta: 2:33:46  lr: 0.000002  ml_loss: 10.1903  mi_loss: 7.9745  train_loss: 18.1648  time: 2.4886  data: 0.0001  max mem: 20903
Train Epoch: [0]  [1200/4855]  eta: 2:31:41  lr: 0.000003  ml_loss: 10.0114  mi_loss: 7.8834  train_loss: 17.8948  time: 2.5009  data: 0.0001  max mem: 20903
Train Epoch: [0]  [1250/4855]  eta: 2:29:36  lr: 0.000003  ml_loss: 9.7590  mi_loss: 7.8962  train_loss: 17.6551  time: 2.4673  data: 0.0001  max mem: 20903
Train Epoch: [0]  [1300/4855]  eta: 2:27:29  lr: 0.000003  ml_loss: 9.7339  mi_loss: 7.4918  train_loss: 17.2257  time: 2.4819  data: 0.0001  max mem: 20903
Train Epoch: [0]  [1350/4855]  eta: 2:25:25  lr: 0.000003  ml_loss: 9.5642  mi_loss: 7.6786  train_loss: 17.2427  time: 2.4934  data: 0.0001  max mem: 20903
Train Epoch: [0]  [1400/4855]  eta: 2:23:20  lr: 0.000003  ml_loss: 9.1261  mi_loss: 7.5041  train_loss: 16.6302  time: 2.4896  data: 0.0001  max mem: 20903
Train Epoch: [0]  [1450/4855]  eta: 2:21:16  lr: 0.000003  ml_loss: 9.1729  mi_loss: 7.4826  train_loss: 16.6555  time: 2.4958  data: 0.0001  max mem: 20903
Train Epoch: [0]  [1500/4855]  eta: 2:19:12  lr: 0.000003  ml_loss: 9.0465  mi_loss: 7.6426  train_loss: 16.6891  time: 2.4952  data: 0.0001  max mem: 20903
Train Epoch: [0]  [1550/4855]  eta: 2:17:08  lr: 0.000003  ml_loss: 8.6195  mi_loss: 7.5066  train_loss: 16.1261  time: 2.4987  data: 0.0001  max mem: 20903
Train Epoch: [0]  [1600/4855]  eta: 2:15:04  lr: 0.000003  ml_loss: 8.5545  mi_loss: 7.1920  train_loss: 15.7466  time: 2.4847  data: 0.0001  max mem: 20903
Train Epoch: [0]  [1650/4855]  eta: 2:13:00  lr: 0.000004  ml_loss: 8.4902  mi_loss: 7.3327  train_loss: 15.8229  time: 2.4975  data: 0.0001  max mem: 20903
Train Epoch: [0]  [1700/4855]  eta: 2:10:56  lr: 0.000004  ml_loss: 8.1568  mi_loss: 7.2389  train_loss: 15.3957  time: 2.4900  data: 0.0001  max mem: 20903
Train Epoch: [0]  [1750/4855]  eta: 2:08:52  lr: 0.000004  ml_loss: 8.1201  mi_loss: 7.0833  train_loss: 15.2034  time: 2.4917  data: 0.0001  max mem: 20903
Train Epoch: [0]  [1800/4855]  eta: 2:06:49  lr: 0.000004  ml_loss: 7.8836  mi_loss: 7.1086  train_loss: 14.9922  time: 2.4994  data: 0.0001  max mem: 20903
Train Epoch: [0]  [1850/4855]  eta: 2:04:44  lr: 0.000004  ml_loss: 8.0024  mi_loss: 7.0544  train_loss: 15.0568  time: 2.4968  data: 0.0001  max mem: 20903
Train Epoch: [0]  [1900/4855]  eta: 2:02:41  lr: 0.000004  ml_loss: 7.6835  mi_loss: 6.9843  train_loss: 14.6678  time: 2.5034  data: 0.0001  max mem: 20903
Train Epoch: [0]  [1950/4855]  eta: 2:00:37  lr: 0.000004  ml_loss: 7.4965  mi_loss: 6.6827  train_loss: 14.1792  time: 2.5024  data: 0.0001  max mem: 20903
Train Epoch: [0]  [2000/4855]  eta: 1:58:33  lr: 0.000004  ml_loss: 7.4086  mi_loss: 7.1270  train_loss: 14.5356  time: 2.4946  data: 0.0001  max mem: 20903
Train Epoch: [0]  [2050/4855]  eta: 1:56:29  lr: 0.000004  ml_loss: 7.2975  mi_loss: 6.8552  train_loss: 14.1527  time: 2.4978  data: 0.0001  max mem: 20903
Train Epoch: [0]  [2100/4855]  eta: 1:54:25  lr: 0.000005  ml_loss: 6.9521  mi_loss: 7.1173  train_loss: 14.0694  time: 2.5000  data: 0.0001  max mem: 20903
Train Epoch: [0]  [2150/4855]  eta: 1:52:21  lr: 0.000005  ml_loss: 6.9444  mi_loss: 6.1140  train_loss: 13.0584  time: 2.5002  data: 0.0001  max mem: 20903
Train Epoch: [0]  [2200/4855]  eta: 1:50:16  lr: 0.000005  ml_loss: 7.0649  mi_loss: 6.7111  train_loss: 13.7760  time: 2.5010  data: 0.0001  max mem: 20903
Train Epoch: [0]  [2250/4855]  eta: 1:48:12  lr: 0.000005  ml_loss: 7.0134  mi_loss: 6.1983  train_loss: 13.2117  time: 2.4927  data: 0.0001  max mem: 20903
Train Epoch: [0]  [2300/4855]  eta: 1:46:08  lr: 0.000005  ml_loss: 6.6312  mi_loss: 6.4339  train_loss: 13.0650  time: 2.5014  data: 0.0001  max mem: 20903
Train Epoch: [0]  [2350/4855]  eta: 1:44:04  lr: 0.000005  ml_loss: 6.6444  mi_loss: 6.4997  train_loss: 13.1441  time: 2.4919  data: 0.0001  max mem: 20903
Train Epoch: [0]  [2400/4855]  eta: 1:41:59  lr: 0.000005  ml_loss: 6.5647  mi_loss: 6.6047  train_loss: 13.1694  time: 2.4889  data: 0.0001  max mem: 20903
Train Epoch: [0]  [2450/4855]  eta: 1:39:55  lr: 0.000005  ml_loss: 6.3257  mi_loss: 6.4228  train_loss: 12.7485  time: 2.4980  data: 0.0001  max mem: 20903
Train Epoch: [0]  [2500/4855]  eta: 1:37:50  lr: 0.000005  ml_loss: 6.5696  mi_loss: 6.6333  train_loss: 13.2029  time: 2.4886  data: 0.0001  max mem: 20903
Train Epoch: [0]  [2550/4855]  eta: 1:35:45  lr: 0.000005  ml_loss: 6.5546  mi_loss: 6.5510  train_loss: 13.1055  time: 2.4902  data: 0.0001  max mem: 20903
Train Epoch: [0]  [2600/4855]  eta: 1:33:41  lr: 0.000006  ml_loss: 6.4273  mi_loss: 6.2512  train_loss: 12.6785  time: 2.4919  data: 0.0001  max mem: 20903
Train Epoch: [0]  [2650/4855]  eta: 1:31:36  lr: 0.000006  ml_loss: 6.4591  mi_loss: 6.1053  train_loss: 12.5644  time: 2.4901  data: 0.0002  max mem: 20903
Train Epoch: [0]  [2700/4855]  eta: 1:29:31  lr: 0.000006  ml_loss: 6.8206  mi_loss: 6.4140  train_loss: 13.2347  time: 2.4895  data: 0.0001  max mem: 20903
Train Epoch: [0]  [2750/4855]  eta: 1:27:26  lr: 0.000006  ml_loss: 6.6787  mi_loss: 6.0812  train_loss: 12.7599  time: 2.4931  data: 0.0001  max mem: 20903
Train Epoch: [0]  [2800/4855]  eta: 1:25:21  lr: 0.000006  ml_loss: 6.2882  mi_loss: 6.1211  train_loss: 12.4094  time: 2.4873  data: 0.0001  max mem: 20903
Train Epoch: [0]  [2850/4855]  eta: 1:23:17  lr: 0.000006  ml_loss: 6.2986  mi_loss: 6.1366  train_loss: 12.4353  time: 2.4841  data: 0.0001  max mem: 20903
Train Epoch: [0]  [2900/4855]  eta: 1:21:12  lr: 0.000006  ml_loss: 6.3075  mi_loss: 6.2100  train_loss: 12.5176  time: 2.4810  data: 0.0001  max mem: 20903
Train Epoch: [0]  [2950/4855]  eta: 1:19:07  lr: 0.000006  ml_loss: 6.5435  mi_loss: 6.0186  train_loss: 12.5621  time: 2.4879  data: 0.0001  max mem: 20903
Train Epoch: [0]  [3000/4855]  eta: 1:17:03  lr: 0.000006  ml_loss: 6.4103  mi_loss: 6.1799  train_loss: 12.5902  time: 2.5043  data: 0.0001  max mem: 20903
Train Epoch: [0]  [3050/4855]  eta: 1:14:59  lr: 0.000007  ml_loss: 6.5714  mi_loss: 5.7848  train_loss: 12.3561  time: 2.5052  data: 0.0001  max mem: 20903
Train Epoch: [0]  [3100/4855]  eta: 1:12:54  lr: 0.000007  ml_loss: 6.1457  mi_loss: 6.1600  train_loss: 12.3057  time: 2.4960  data: 0.0001  max mem: 20903
Train Epoch: [0]  [3150/4855]  eta: 1:10:50  lr: 0.000007  ml_loss: 6.2316  mi_loss: 5.8906  train_loss: 12.1222  time: 2.4851  data: 0.0001  max mem: 20903
Train Epoch: [0]  [3200/4855]  eta: 1:08:45  lr: 0.000007  ml_loss: 6.2641  mi_loss: 5.8864  train_loss: 12.1505  time: 2.4975  data: 0.0001  max mem: 20903
Train Epoch: [0]  [3250/4855]  eta: 1:06:41  lr: 0.000007  ml_loss: 6.4107  mi_loss: 5.8319  train_loss: 12.2426  time: 2.4955  data: 0.0001  max mem: 20903
Train Epoch: [0]  [3300/4855]  eta: 1:04:36  lr: 0.000007  ml_loss: 6.3595  mi_loss: 6.1207  train_loss: 12.4802  time: 2.4979  data: 0.0001  max mem: 20903
Train Epoch: [0]  [3350/4855]  eta: 1:02:31  lr: 0.000007  ml_loss: 6.4551  mi_loss: 5.8263  train_loss: 12.2813  time: 2.4944  data: 0.0001  max mem: 20903
Train Epoch: [0]  [3400/4855]  eta: 1:00:27  lr: 0.000007  ml_loss: 6.3660  mi_loss: 6.0504  train_loss: 12.4165  time: 2.4932  data: 0.0001  max mem: 20903
Train Epoch: [0]  [3450/4855]  eta: 0:58:22  lr: 0.000007  ml_loss: 6.4699  mi_loss: 5.6505  train_loss: 12.1204  time: 2.4945  data: 0.0001  max mem: 20903
Train Epoch: [0]  [3500/4855]  eta: 0:56:18  lr: 0.000008  ml_loss: 6.5052  mi_loss: 5.5622  train_loss: 12.0674  time: 2.4975  data: 0.0001  max mem: 20903
Train Epoch: [0]  [3550/4855]  eta: 0:54:13  lr: 0.000008  ml_loss: 5.9725  mi_loss: 5.8628  train_loss: 11.8354  time: 2.4978  data: 0.0001  max mem: 20903
Train Epoch: [0]  [3600/4855]  eta: 0:52:08  lr: 0.000008  ml_loss: 6.1404  mi_loss: 5.5942  train_loss: 11.7347  time: 2.4961  data: 0.0001  max mem: 20903
Train Epoch: [0]  [3650/4855]  eta: 0:50:04  lr: 0.000008  ml_loss: 6.4744  mi_loss: 5.5942  train_loss: 12.0686  time: 2.4942  data: 0.0001  max mem: 20903
Train Epoch: [0]  [3700/4855]  eta: 0:47:59  lr: 0.000008  ml_loss: 5.8621  mi_loss: 6.0548  train_loss: 11.9169  time: 2.4940  data: 0.0001  max mem: 20903
Train Epoch: [0]  [3750/4855]  eta: 0:45:54  lr: 0.000008  ml_loss: 6.2576  mi_loss: 5.5367  train_loss: 11.7943  time: 2.4877  data: 0.0001  max mem: 20903
Train Epoch: [0]  [3800/4855]  eta: 0:43:50  lr: 0.000008  ml_loss: 6.0010  mi_loss: 5.7436  train_loss: 11.7446  time: 2.4902  data: 0.0001  max mem: 20903
Train Epoch: [0]  [3850/4855]  eta: 0:41:45  lr: 0.000008  ml_loss: 6.3890  mi_loss: 5.4672  train_loss: 11.8561  time: 2.4878  data: 0.0002  max mem: 20903
Train Epoch: [0]  [3900/4855]  eta: 0:39:40  lr: 0.000008  ml_loss: 6.2906  mi_loss: 5.3000  train_loss: 11.5906  time: 2.4883  data: 0.0001  max mem: 20903
Train Epoch: [0]  [3950/4855]  eta: 0:37:36  lr: 0.000008  ml_loss: 6.9281  mi_loss: 4.9109  train_loss: 11.8390  time: 2.4851  data: 0.0001  max mem: 20903
Train Epoch: [0]  [4000/4855]  eta: 0:35:31  lr: 0.000009  ml_loss: 6.1427  mi_loss: 5.8105  train_loss: 11.9532  time: 2.4934  data: 0.0001  max mem: 20903
Train Epoch: [0]  [4050/4855]  eta: 0:33:26  lr: 0.000009  ml_loss: 5.9756  mi_loss: 4.7362  train_loss: 10.7118  time: 2.4842  data: 0.0001  max mem: 20903
Train Epoch: [0]  [4100/4855]  eta: 0:31:22  lr: 0.000009  ml_loss: 6.5201  mi_loss: 4.2733  train_loss: 10.7934  time: 2.4919  data: 0.0001  max mem: 20903
Train Epoch: [0]  [4150/4855]  eta: 0:29:17  lr: 0.000009  ml_loss: 6.0811  mi_loss: 5.4224  train_loss: 11.5035  time: 2.4963  data: 0.0001  max mem: 20903
Train Epoch: [0]  [4200/4855]  eta: 0:27:12  lr: 0.000009  ml_loss: 6.1092  mi_loss: 4.7760  train_loss: 10.8852  time: 2.4951  data: 0.0001  max mem: 20903
Train Epoch: [0]  [4250/4855]  eta: 0:25:08  lr: 0.000009  ml_loss: 5.7639  mi_loss: 5.6050  train_loss: 11.3690  time: 2.4990  data: 0.0001  max mem: 20903
Train Epoch: [0]  [4300/4855]  eta: 0:23:03  lr: 0.000009  ml_loss: 6.3356  mi_loss: 5.3393  train_loss: 11.6749  time: 2.5052  data: 0.0001  max mem: 20903
Train Epoch: [0]  [4350/4855]  eta: 0:20:59  lr: 0.000009  ml_loss: 6.2759  mi_loss: 5.3053  train_loss: 11.5812  time: 2.5076  data: 0.0001  max mem: 20903
Train Epoch: [0]  [4400/4855]  eta: 0:18:54  lr: 0.000009  ml_loss: 5.9279  mi_loss: 5.3737  train_loss: 11.3016  time: 2.5037  data: 0.0001  max mem: 20903
Train Epoch: [0]  [4450/4855]  eta: 0:16:49  lr: 0.000010  ml_loss: 6.1385  mi_loss: 5.5495  train_loss: 11.6880  time: 2.5002  data: 0.0001  max mem: 20903
Train Epoch: [0]  [4500/4855]  eta: 0:14:45  lr: 0.000010  ml_loss: 6.2445  mi_loss: 5.8698  train_loss: 12.1142  time: 2.5010  data: 0.0001  max mem: 20903
Train Epoch: [0]  [4550/4855]  eta: 0:12:40  lr: 0.000010  ml_loss: 5.9367  mi_loss: 5.6425  train_loss: 11.5792  time: 2.4914  data: 0.0001  max mem: 20903
Train Epoch: [0]  [4600/4855]  eta: 0:10:35  lr: 0.000010  ml_loss: 5.9511  mi_loss: 5.3590  train_loss: 11.3101  time: 2.4938  data: 0.0001  max mem: 20903
Train Epoch: [0]  [4650/4855]  eta: 0:08:31  lr: 0.000010  ml_loss: 6.2434  mi_loss: 5.1323  train_loss: 11.3757  time: 2.4961  data: 0.0001  max mem: 20903
Train Epoch: [0]  [4700/4855]  eta: 0:06:26  lr: 0.000010  ml_loss: 6.1919  mi_loss: 5.5068  train_loss: 11.6987  time: 2.4958  data: 0.0001  max mem: 20903
Train Epoch: [0]  [4750/4855]  eta: 0:04:21  lr: 0.000010  ml_loss: 6.0695  mi_loss: 4.9619  train_loss: 11.0314  time: 2.4979  data: 0.0001  max mem: 20903
Train Epoch: [0]  [4800/4855]  eta: 0:02:17  lr: 0.000010  ml_loss: 5.9725  mi_loss: 4.3949  train_loss: 10.3675  time: 2.4973  data: 0.0001  max mem: 20903
Train Epoch: [0]  [4850/4855]  eta: 0:00:12  lr: 0.000010  ml_loss: 6.1406  mi_loss: 5.1996  train_loss: 11.3402  time: 2.4986  data: 0.0001  max mem: 20903
Train Epoch: [0]  [4854/4855]  eta: 0:00:02  lr: 0.000010  ml_loss: 6.2006  mi_loss: 5.3783  train_loss: 11.5789  time: 2.5027  data: 0.0007  max mem: 20903
Train Epoch: [0] Total time: 3:21:48 (2.4940 s / it)
Val Epoch: [0]  [  0/540]  eta: 0:23:42  ml_loss: 5.9235  mi_loss: 5.1016  val_loss: 11.0251  accML: 0.1667  accMI: 0.0730  time: 2.6346  data: 2.2866  max mem: 20903
Val Epoch: [0]  [ 50/540]  eta: 0:06:36  ml_loss: 6.0038  mi_loss: 4.9760  val_loss: 10.9798  accML: 0.1395  accMI: 0.1260  time: 0.7732  data: 0.6114  max mem: 20903
Val Epoch: [0]  [100/540]  eta: 0:05:55  ml_loss: 6.1143  mi_loss: 5.1623  val_loss: 11.2765  accML: 0.1420  accMI: 0.1173  time: 0.7689  data: 0.6073  max mem: 20903
Val Epoch: [0]  [150/540]  eta: 0:05:23  ml_loss: 6.2201  mi_loss: 5.2653  val_loss: 11.4855  accML: 0.1281  accMI: 0.0943  time: 0.9053  data: 0.7416  max mem: 20903
Val Epoch: [0]  [200/540]  eta: 0:04:42  ml_loss: 6.1697  mi_loss: 5.4621  val_loss: 11.6318  accML: 0.1354  accMI: 0.0668  time: 0.8345  data: 0.6720  max mem: 20903
Val Epoch: [0]  [250/540]  eta: 0:04:00  ml_loss: 5.8936  mi_loss: 5.0403  val_loss: 10.9339  accML: 0.1437  accMI: 0.0951  time: 0.8568  data: 0.6943  max mem: 20903
Val Epoch: [0]  [300/540]  eta: 0:03:20  ml_loss: 6.0052  mi_loss: 4.9498  val_loss: 10.9551  accML: 0.1491  accMI: 0.1129  time: 0.9496  data: 0.7867  max mem: 20903
Val Epoch: [0]  [350/540]  eta: 0:02:38  ml_loss: 6.2140  mi_loss: 4.1574  val_loss: 10.3714  accML: 0.1560  accMI: 0.2587  time: 0.8040  data: 0.6422  max mem: 20903
Val Epoch: [0]  [400/540]  eta: 0:01:56  ml_loss: 6.3253  mi_loss: 5.1939  val_loss: 11.5191  accML: 0.1386  accMI: 0.0753  time: 0.8689  data: 0.7065  max mem: 20903
Val Epoch: [0]  [450/540]  eta: 0:01:15  ml_loss: 6.0894  mi_loss: 5.0387  val_loss: 11.1281  accML: 0.1705  accMI: 0.0800  time: 0.8463  data: 0.6833  max mem: 20903
Val Epoch: [0]  [500/540]  eta: 0:00:33  ml_loss: 6.3726  mi_loss: 4.9949  val_loss: 11.3675  accML: 0.1422  accMI: 0.0703  time: 0.7767  data: 0.6142  max mem: 20903
Val Epoch: [0]  [539/540]  eta: 0:00:00  ml_loss: 6.3272  mi_loss: 4.8583  val_loss: 11.1856  accML: 0.1310  accMI: 0.1126  time: 0.7800  data: 0.6176  max mem: 20903
Val Epoch: [0] Total time: 0:07:33 (0.8406 s / it)
epoch:0, iter:4854, 4854,  train_loss: 11.578911781311035, valid_loss: 11.191823320035581, idiv_loss:(6.031069975429111, 5.160753317232485), acc:(0.15313593463765252, 0.09481901119428653)
Averaged stats: lr: 0.0000  ml_loss: 7.9600  mi_loss: 6.7890  train_loss: 14.7489
epoch 0 11.578911781311035
Train Epoch: [1]  [   0/4855]  eta: 8:41:17  lr: 0.000010  ml_loss: 6.2188  mi_loss: 5.5223  train_loss: 11.7411  time: 6.4424  data: 2.1353  max mem: 20903
Train Epoch: [1]  [  50/4855]  eta: 3:27:05  lr: 0.000010  ml_loss: 6.3064  mi_loss: 5.0093  train_loss: 11.3156  time: 2.5090  data: 0.0001  max mem: 20903
Train Epoch: [1]  [ 100/4855]  eta: 3:21:44  lr: 0.000010  ml_loss: 6.3084  mi_loss: 5.1350  train_loss: 11.4434  time: 2.5130  data: 0.0001  max mem: 20903
Train Epoch: [1]  [ 150/4855]  eta: 3:17:57  lr: 0.000010  ml_loss: 5.7565  mi_loss: 4.8038  train_loss: 10.5603  time: 2.4749  data: 0.0001  max mem: 20903
Train Epoch: [1]  [ 200/4855]  eta: 3:15:08  lr: 0.000010  ml_loss: 5.9325  mi_loss: 5.1229  train_loss: 11.0555  time: 2.4969  data: 0.0002  max mem: 20903
Train Epoch: [1]  [ 250/4855]  eta: 3:12:34  lr: 0.000010  ml_loss: 5.8304  mi_loss: 4.9382  train_loss: 10.7686  time: 2.4691  data: 0.0001  max mem: 20903
Train Epoch: [1]  [ 300/4855]  eta: 3:10:03  lr: 0.000010  ml_loss: 5.7305  mi_loss: 5.5104  train_loss: 11.2409  time: 2.4788  data: 0.0001  max mem: 20903
Train Epoch: [1]  [ 350/4855]  eta: 3:07:49  lr: 0.000010  ml_loss: 6.3007  mi_loss: 5.1240  train_loss: 11.4247  time: 2.4945  data: 0.0001  max mem: 20903
Train Epoch: [1]  [ 400/4855]  eta: 3:05:38  lr: 0.000010  ml_loss: 6.1117  mi_loss: 5.0595  train_loss: 11.1712  time: 2.5062  data: 0.0001  max mem: 20903
Train Epoch: [1]  [ 450/4855]  eta: 3:03:34  lr: 0.000010  ml_loss: 6.0525  mi_loss: 5.0831  train_loss: 11.1356  time: 2.5073  data: 0.0002  max mem: 20903
Train Epoch: [1]  [ 500/4855]  eta: 3:01:26  lr: 0.000010  ml_loss: 5.9497  mi_loss: 5.0316  train_loss: 10.9812  time: 2.4778  data: 0.0001  max mem: 20903
Train Epoch: [1]  [ 550/4855]  eta: 2:59:17  lr: 0.000010  ml_loss: 6.3786  mi_loss: 4.9140  train_loss: 11.2926  time: 2.4833  data: 0.0001  max mem: 20903
Train Epoch: [1]  [ 600/4855]  eta: 2:57:10  lr: 0.000010  ml_loss: 5.9220  mi_loss: 4.7096  train_loss: 10.6316  time: 2.5067  data: 0.0001  max mem: 20903
Train Epoch: [1]  [ 650/4855]  eta: 2:55:07  lr: 0.000010  ml_loss: 6.0927  mi_loss: 5.0912  train_loss: 11.1838  time: 2.4922  data: 0.0001  max mem: 20903
Train Epoch: [1]  [ 700/4855]  eta: 2:52:59  lr: 0.000010  ml_loss: 5.7609  mi_loss: 4.9052  train_loss: 10.6661  time: 2.4926  data: 0.0001  max mem: 20903
Train Epoch: [1]  [ 750/4855]  eta: 2:50:50  lr: 0.000010  ml_loss: 5.8617  mi_loss: 4.9014  train_loss: 10.7632  time: 2.4935  data: 0.0001  max mem: 20903
Train Epoch: [1]  [ 800/4855]  eta: 2:48:42  lr: 0.000010  ml_loss: 5.9940  mi_loss: 3.8159  train_loss: 9.8099  time: 2.4838  data: 0.0001  max mem: 20903
Train Epoch: [1]  [ 850/4855]  eta: 2:46:29  lr: 0.000010  ml_loss: 6.0509  mi_loss: 4.9085  train_loss: 10.9594  time: 2.4655  data: 0.0001  max mem: 20903
Train Epoch: [1]  [ 900/4855]  eta: 2:44:20  lr: 0.000010  ml_loss: 5.9625  mi_loss: 5.2255  train_loss: 11.1880  time: 2.4905  data: 0.0001  max mem: 20903
Train Epoch: [1]  [ 950/4855]  eta: 2:42:11  lr: 0.000010  ml_loss: 5.8793  mi_loss: 4.7285  train_loss: 10.6078  time: 2.4802  data: 0.0001  max mem: 20903
Train Epoch: [1]  [1000/4855]  eta: 2:40:05  lr: 0.000010  ml_loss: 5.5306  mi_loss: 4.7258  train_loss: 10.2565  time: 2.4814  data: 0.0001  max mem: 20903
Train Epoch: [1]  [1050/4855]  eta: 2:38:00  lr: 0.000010  ml_loss: 5.6341  mi_loss: 5.5009  train_loss: 11.1350  time: 2.5029  data: 0.0001  max mem: 20903
Train Epoch: [1]  [1100/4855]  eta: 2:35:52  lr: 0.000010  ml_loss: 5.6484  mi_loss: 4.6484  train_loss: 10.2968  time: 2.4675  data: 0.0001  max mem: 20903
Train Epoch: [1]  [1150/4855]  eta: 2:33:48  lr: 0.000010  ml_loss: 5.7582  mi_loss: 5.0883  train_loss: 10.8465  time: 2.4988  data: 0.0001  max mem: 20903
Train Epoch: [1]  [1200/4855]  eta: 2:31:42  lr: 0.000010  ml_loss: 5.8136  mi_loss: 5.3803  train_loss: 11.1939  time: 2.4890  data: 0.0001  max mem: 20903
Train Epoch: [1]  [1250/4855]  eta: 2:29:37  lr: 0.000010  ml_loss: 5.8709  mi_loss: 4.7297  train_loss: 10.6006  time: 2.4934  data: 0.0001  max mem: 20903
Train Epoch: [1]  [1300/4855]  eta: 2:27:34  lr: 0.000010  ml_loss: 6.1642  mi_loss: 4.8796  train_loss: 11.0438  time: 2.4790  data: 0.0001  max mem: 20903
Train Epoch: [1]  [1350/4855]  eta: 2:25:28  lr: 0.000010  ml_loss: 5.9045  mi_loss: 4.8311  train_loss: 10.7356  time: 2.5056  data: 0.0001  max mem: 20903
Train Epoch: [1]  [1400/4855]  eta: 2:23:22  lr: 0.000010  ml_loss: 5.7122  mi_loss: 5.1221  train_loss: 10.8343  time: 2.4683  data: 0.0001  max mem: 20903
Train Epoch: [1]  [1450/4855]  eta: 2:21:15  lr: 0.000010  ml_loss: 5.6910  mi_loss: 5.4089  train_loss: 11.0999  time: 2.4798  data: 0.0001  max mem: 20903
Train Epoch: [1]  [1500/4855]  eta: 2:19:10  lr: 0.000010  ml_loss: 5.7551  mi_loss: 5.4460  train_loss: 11.2010  time: 2.4837  data: 0.0001  max mem: 20903
Train Epoch: [1]  [1550/4855]  eta: 2:17:04  lr: 0.000010  ml_loss: 6.0394  mi_loss: 5.1258  train_loss: 11.1653  time: 2.4881  data: 0.0001  max mem: 20903
Train Epoch: [1]  [1600/4855]  eta: 2:15:00  lr: 0.000010  ml_loss: 5.5832  mi_loss: 3.6437  train_loss: 9.2268  time: 2.4782  data: 0.0001  max mem: 20903
Train Epoch: [1]  [1650/4855]  eta: 2:12:53  lr: 0.000010  ml_loss: 5.7689  mi_loss: 4.6108  train_loss: 10.3797  time: 2.4746  data: 0.0001  max mem: 20903
Train Epoch: [1]  [1700/4855]  eta: 2:10:49  lr: 0.000010  ml_loss: 5.9494  mi_loss: 5.0059  train_loss: 10.9553  time: 2.4983  data: 0.0001  max mem: 20903
Train Epoch: [1]  [1750/4855]  eta: 2:08:43  lr: 0.000010  ml_loss: 5.9262  mi_loss: 5.2002  train_loss: 11.1263  time: 2.4641  data: 0.0001  max mem: 20903
Train Epoch: [1]  [1800/4855]  eta: 2:06:39  lr: 0.000010  ml_loss: 5.7431  mi_loss: 4.9336  train_loss: 10.6767  time: 2.4849  data: 0.0001  max mem: 20903
Train Epoch: [1]  [1850/4855]  eta: 2:04:34  lr: 0.000010  ml_loss: 5.9033  mi_loss: 4.5060  train_loss: 10.4092  time: 2.4768  data: 0.0001  max mem: 20903
Train Epoch: [1]  [1900/4855]  eta: 2:02:28  lr: 0.000010  ml_loss: 5.6875  mi_loss: 5.1757  train_loss: 10.8631  time: 2.4774  data: 0.0001  max mem: 20903
Train Epoch: [1]  [1950/4855]  eta: 2:00:24  lr: 0.000010  ml_loss: 5.5900  mi_loss: 5.0482  train_loss: 10.6383  time: 2.4881  data: 0.0001  max mem: 20903
Train Epoch: [1]  [2000/4855]  eta: 1:58:18  lr: 0.000010  ml_loss: 5.4638  mi_loss: 4.6096  train_loss: 10.0734  time: 2.4706  data: 0.0001  max mem: 20903
Train Epoch: [1]  [2050/4855]  eta: 1:56:12  lr: 0.000010  ml_loss: 5.9420  mi_loss: 4.5629  train_loss: 10.5050  time: 2.4680  data: 0.0001  max mem: 20903
Train Epoch: [1]  [2100/4855]  eta: 1:54:07  lr: 0.000010  ml_loss: 6.0658  mi_loss: 4.8535  train_loss: 10.9193  time: 2.4639  data: 0.0001  max mem: 20903
Train Epoch: [1]  [2150/4855]  eta: 1:52:03  lr: 0.000010  ml_loss: 5.5326  mi_loss: 4.9304  train_loss: 10.4629  time: 2.4857  data: 0.0001  max mem: 20903
Train Epoch: [1]  [2200/4855]  eta: 1:49:58  lr: 0.000010  ml_loss: 6.1463  mi_loss: 4.7958  train_loss: 10.9421  time: 2.4811  data: 0.0001  max mem: 20903
Train Epoch: [1]  [2250/4855]  eta: 1:47:54  lr: 0.000010  ml_loss: 5.3359  mi_loss: 4.9183  train_loss: 10.2542  time: 2.4821  data: 0.0001  max mem: 20903
Train Epoch: [1]  [2300/4855]  eta: 1:45:49  lr: 0.000010  ml_loss: 5.9563  mi_loss: 5.2108  train_loss: 11.1671  time: 2.4956  data: 0.0001  max mem: 20903
Train Epoch: [1]  [2350/4855]  eta: 1:43:45  lr: 0.000010  ml_loss: 5.9057  mi_loss: 4.7271  train_loss: 10.6328  time: 2.4534  data: 0.0001  max mem: 20903
Train Epoch: [1]  [2400/4855]  eta: 1:41:40  lr: 0.000010  ml_loss: 5.7557  mi_loss: 5.7080  train_loss: 11.4637  time: 2.4733  data: 0.0001  max mem: 20903
Train Epoch: [1]  [2450/4855]  eta: 1:39:36  lr: 0.000010  ml_loss: 5.6028  mi_loss: 4.7965  train_loss: 10.3993  time: 2.4796  data: 0.0001  max mem: 20903
Train Epoch: [1]  [2500/4855]  eta: 1:37:31  lr: 0.000010  ml_loss: 5.8165  mi_loss: 4.7460  train_loss: 10.5625  time: 2.4778  data: 0.0001  max mem: 20903
Train Epoch: [1]  [2550/4855]  eta: 1:35:27  lr: 0.000010  ml_loss: 6.1611  mi_loss: 4.4993  train_loss: 10.6604  time: 2.4682  data: 0.0001  max mem: 20905
Train Epoch: [1]  [2600/4855]  eta: 1:33:22  lr: 0.000010  ml_loss: 5.8605  mi_loss: 4.9056  train_loss: 10.7660  time: 2.4710  data: 0.0001  max mem: 20905
Train Epoch: [1]  [2650/4855]  eta: 1:31:18  lr: 0.000010  ml_loss: 5.8150  mi_loss: 5.1832  train_loss: 10.9982  time: 2.4767  data: 0.0001  max mem: 20905
Train Epoch: [1]  [2700/4855]  eta: 1:29:14  lr: 0.000010  ml_loss: 6.1659  mi_loss: 5.0180  train_loss: 11.1839  time: 2.4877  data: 0.0001  max mem: 20905
Train Epoch: [1]  [2750/4855]  eta: 1:27:09  lr: 0.000010  ml_loss: 5.7484  mi_loss: 4.6677  train_loss: 10.4162  time: 2.4554  data: 0.0001  max mem: 20905
Train Epoch: [1]  [2800/4855]  eta: 1:25:05  lr: 0.000010  ml_loss: 6.0914  mi_loss: 4.4550  train_loss: 10.5464  time: 2.4936  data: 0.0001  max mem: 20905
Train Epoch: [1]  [2850/4855]  eta: 1:23:00  lr: 0.000010  ml_loss: 6.0335  mi_loss: 4.6870  train_loss: 10.7205  time: 2.4821  data: 0.0001  max mem: 20905
Train Epoch: [1]  [2900/4855]  eta: 1:20:57  lr: 0.000010  ml_loss: 6.1557  mi_loss: 4.3315  train_loss: 10.4872  time: 2.5014  data: 0.0002  max mem: 20905
Train Epoch: [1]  [2950/4855]  eta: 1:18:53  lr: 0.000010  ml_loss: 5.7802  mi_loss: 5.1067  train_loss: 10.8869  time: 2.4796  data: 0.0001  max mem: 20905
Train Epoch: [1]  [3000/4855]  eta: 1:16:48  lr: 0.000010  ml_loss: 5.8322  mi_loss: 4.8815  train_loss: 10.7138  time: 2.4739  data: 0.0001  max mem: 20905
Train Epoch: [1]  [3050/4855]  eta: 1:14:44  lr: 0.000010  ml_loss: 6.1272  mi_loss: 4.6478  train_loss: 10.7749  time: 2.4804  data: 0.0001  max mem: 20905
Train Epoch: [1]  [3100/4855]  eta: 1:12:41  lr: 0.000010  ml_loss: 5.7494  mi_loss: 4.3438  train_loss: 10.0932  time: 2.5100  data: 0.0001  max mem: 20905
Train Epoch: [1]  [3150/4855]  eta: 1:10:37  lr: 0.000010  ml_loss: 5.7113  mi_loss: 4.6931  train_loss: 10.4044  time: 2.4999  data: 0.0001  max mem: 20905
Train Epoch: [1]  [3200/4855]  eta: 1:08:33  lr: 0.000010  ml_loss: 5.4449  mi_loss: 4.8401  train_loss: 10.2850  time: 2.4948  data: 0.0001  max mem: 20905
Train Epoch: [1]  [3250/4855]  eta: 1:06:29  lr: 0.000010  ml_loss: 6.2720  mi_loss: 4.7050  train_loss: 10.9770  time: 2.5075  data: 0.0001  max mem: 20905
Train Epoch: [1]  [3300/4855]  eta: 1:04:25  lr: 0.000010  ml_loss: 5.7840  mi_loss: 4.4443  train_loss: 10.2284  time: 2.5024  data: 0.0001  max mem: 20905
Train Epoch: [1]  [3350/4855]  eta: 1:02:21  lr: 0.000010  ml_loss: 5.6934  mi_loss: 5.0440  train_loss: 10.7374  time: 2.4995  data: 0.0001  max mem: 20905
Train Epoch: [1]  [3400/4855]  eta: 1:00:17  lr: 0.000010  ml_loss: 5.9942  mi_loss: 4.9649  train_loss: 10.9591  time: 2.4914  data: 0.0001  max mem: 20905
Train Epoch: [1]  [3450/4855]  eta: 0:58:13  lr: 0.000010  ml_loss: 5.1211  mi_loss: 4.2325  train_loss: 9.3536  time: 2.4828  data: 0.0001  max mem: 20905
Train Epoch: [1]  [3500/4855]  eta: 0:56:08  lr: 0.000010  ml_loss: 5.4814  mi_loss: 5.0460  train_loss: 10.5274  time: 2.4606  data: 0.0001  max mem: 20905
Train Epoch: [1]  [3550/4855]  eta: 0:54:03  lr: 0.000010  ml_loss: 5.5612  mi_loss: 4.5044  train_loss: 10.0656  time: 2.5109  data: 0.0001  max mem: 20905
Train Epoch: [1]  [3600/4855]  eta: 0:51:59  lr: 0.000010  ml_loss: 5.5202  mi_loss: 4.4344  train_loss: 9.9546  time: 2.4872  data: 0.0001  max mem: 20905
Train Epoch: [1]  [3650/4855]  eta: 0:49:55  lr: 0.000010  ml_loss: 5.7206  mi_loss: 4.6555  train_loss: 10.3761  time: 2.4567  data: 0.0001  max mem: 20905
Train Epoch: [1]  [3700/4855]  eta: 0:47:50  lr: 0.000010  ml_loss: 5.9239  mi_loss: 4.3682  train_loss: 10.2921  time: 2.4731  data: 0.0001  max mem: 20905
Train Epoch: [1]  [3750/4855]  eta: 0:45:46  lr: 0.000010  ml_loss: 6.0893  mi_loss: 4.8877  train_loss: 10.9769  time: 2.4458  data: 0.0001  max mem: 20905
Train Epoch: [1]  [3800/4855]  eta: 0:43:41  lr: 0.000010  ml_loss: 5.8743  mi_loss: 4.6341  train_loss: 10.5085  time: 2.4925  data: 0.0001  max mem: 20905
Train Epoch: [1]  [3850/4855]  eta: 0:41:37  lr: 0.000010  ml_loss: 5.7642  mi_loss: 4.7793  train_loss: 10.5435  time: 2.4774  data: 0.0001  max mem: 20905
Train Epoch: [1]  [3900/4855]  eta: 0:39:32  lr: 0.000010  ml_loss: 5.7710  mi_loss: 4.9887  train_loss: 10.7596  time: 2.4701  data: 0.0001  max mem: 20905
Train Epoch: [1]  [3950/4855]  eta: 0:37:28  lr: 0.000010  ml_loss: 5.8725  mi_loss: 4.9886  train_loss: 10.8611  time: 2.4792  data: 0.0001  max mem: 20905
Train Epoch: [1]  [4000/4855]  eta: 0:35:24  lr: 0.000010  ml_loss: 5.4720  mi_loss: 5.1141  train_loss: 10.5861  time: 2.4658  data: 0.0001  max mem: 20905
Train Epoch: [1]  [4050/4855]  eta: 0:33:19  lr: 0.000010  ml_loss: 5.5035  mi_loss: 5.4865  train_loss: 10.9900  time: 2.4541  data: 0.0001  max mem: 20905
Train Epoch: [1]  [4100/4855]  eta: 0:31:15  lr: 0.000010  ml_loss: 5.3488  mi_loss: 4.8694  train_loss: 10.2182  time: 2.4646  data: 0.0001  max mem: 20905
Train Epoch: [1]  [4150/4855]  eta: 0:29:10  lr: 0.000010  ml_loss: 5.8510  mi_loss: 5.2463  train_loss: 11.0973  time: 2.4520  data: 0.0001  max mem: 20905
Train Epoch: [1]  [4200/4855]  eta: 0:27:06  lr: 0.000010  ml_loss: 6.0910  mi_loss: 5.0061  train_loss: 11.0970  time: 2.4418  data: 0.0001  max mem: 20905
Train Epoch: [1]  [4250/4855]  eta: 0:25:02  lr: 0.000010  ml_loss: 5.9266  mi_loss: 4.7694  train_loss: 10.6960  time: 2.4628  data: 0.0001  max mem: 20905
Train Epoch: [1]  [4300/4855]  eta: 0:22:57  lr: 0.000010  ml_loss: 5.9275  mi_loss: 4.6208  train_loss: 10.5483  time: 2.4464  data: 0.0001  max mem: 20905
Train Epoch: [1]  [4350/4855]  eta: 0:20:53  lr: 0.000010  ml_loss: 5.5676  mi_loss: 5.0407  train_loss: 10.6083  time: 2.4700  data: 0.0001  max mem: 20905
Train Epoch: [1]  [4400/4855]  eta: 0:18:49  lr: 0.000010  ml_loss: 5.3366  mi_loss: 5.4941  train_loss: 10.8308  time: 2.4240  data: 0.0001  max mem: 20905
Train Epoch: [1]  [4450/4855]  eta: 0:16:44  lr: 0.000010  ml_loss: 5.9502  mi_loss: 4.6013  train_loss: 10.5514  time: 2.4627  data: 0.0001  max mem: 20905
Train Epoch: [1]  [4500/4855]  eta: 0:14:40  lr: 0.000010  ml_loss: 5.5779  mi_loss: 5.0938  train_loss: 10.6717  time: 2.4396  data: 0.0001  max mem: 20905
Train Epoch: [1]  [4550/4855]  eta: 0:12:36  lr: 0.000010  ml_loss: 5.9129  mi_loss: 4.8678  train_loss: 10.7808  time: 2.4594  data: 0.0001  max mem: 20905
Train Epoch: [1]  [4600/4855]  eta: 0:10:32  lr: 0.000010  ml_loss: 5.8326  mi_loss: 4.5835  train_loss: 10.4161  time: 2.4800  data: 0.0001  max mem: 20905
Train Epoch: [1]  [4650/4855]  eta: 0:08:28  lr: 0.000010  ml_loss: 6.0164  mi_loss: 4.9369  train_loss: 10.9532  time: 2.4553  data: 0.0001  max mem: 20905
Train Epoch: [1]  [4700/4855]  eta: 0:06:24  lr: 0.000010  ml_loss: 5.3889  mi_loss: 4.8375  train_loss: 10.2265  time: 2.4684  data: 0.0001  max mem: 20905
Train Epoch: [1]  [4750/4855]  eta: 0:04:20  lr: 0.000010  ml_loss: 5.8910  mi_loss: 5.1093  train_loss: 11.0003  time: 2.4766  data: 0.0001  max mem: 20905
Train Epoch: [1]  [4800/4855]  eta: 0:02:16  lr: 0.000010  ml_loss: 5.8621  mi_loss: 4.7483  train_loss: 10.6104  time: 2.4869  data: 0.0001  max mem: 20905
Train Epoch: [1]  [4850/4855]  eta: 0:00:12  lr: 0.000010  ml_loss: 5.5956  mi_loss: 4.5422  train_loss: 10.1377  time: 2.4681  data: 0.0001  max mem: 20905
Train Epoch: [1]  [4854/4855]  eta: 0:00:02  lr: 0.000010  ml_loss: 6.0503  mi_loss: 3.7625  train_loss: 9.8128  time: 2.4642  data: 0.0008  max mem: 20905
Train Epoch: [1] Total time: 3:20:43 (2.4806 s / it)
Val Epoch: [1]  [  0/540]  eta: 0:22:07  ml_loss: 5.9438  mi_loss: 4.6311  val_loss: 10.5749  accML: 0.1518  accMI: 0.0838  time: 2.4578  data: 2.0983  max mem: 20905
Val Epoch: [1]  [ 50/540]  eta: 0:06:28  ml_loss: 5.5335  mi_loss: 4.3657  val_loss: 9.8992  accML: 0.2269  accMI: 0.1769  time: 0.7742  data: 0.6126  max mem: 20905
Val Epoch: [1]  [100/540]  eta: 0:05:50  ml_loss: 5.6955  mi_loss: 4.7249  val_loss: 10.4204  accML: 0.1712  accMI: 0.1227  time: 0.7786  data: 0.6167  max mem: 20905
Val Epoch: [1]  [150/540]  eta: 0:05:20  ml_loss: 5.8128  mi_loss: 4.9807  val_loss: 10.7936  accML: 0.1927  accMI: 0.1105  time: 0.9109  data: 0.7478  max mem: 20905
Val Epoch: [1]  [200/540]  eta: 0:04:44  ml_loss: 5.7976  mi_loss: 4.9885  val_loss: 10.7861  accML: 0.1780  accMI: 0.1016  time: 0.8421  data: 0.6797  max mem: 20905
Val Epoch: [1]  [250/540]  eta: 0:04:00  ml_loss: 5.4513  mi_loss: 4.5159  val_loss: 9.9672  accML: 0.2018  accMI: 0.1168  time: 0.8414  data: 0.6788  max mem: 20905
Val Epoch: [1]  [300/540]  eta: 0:03:18  ml_loss: 5.3078  mi_loss: 4.4193  val_loss: 9.7271  accML: 0.1957  accMI: 0.1452  time: 0.8660  data: 0.7028  max mem: 20905
Val Epoch: [1]  [350/540]  eta: 0:02:37  ml_loss: 5.7506  mi_loss: 3.6690  val_loss: 9.4197  accML: 0.1737  accMI: 0.2747  time: 0.8007  data: 0.6385  max mem: 20905
Val Epoch: [1]  [400/540]  eta: 0:01:56  ml_loss: 6.0826  mi_loss: 4.7337  val_loss: 10.8163  accML: 0.1677  accMI: 0.0995  time: 0.8568  data: 0.6942  max mem: 20905
Val Epoch: [1]  [450/540]  eta: 0:01:14  ml_loss: 5.9104  mi_loss: 4.5378  val_loss: 10.4482  accML: 0.1663  accMI: 0.0827  time: 0.8505  data: 0.6877  max mem: 20905
Val Epoch: [1]  [500/540]  eta: 0:00:33  ml_loss: 6.0929  mi_loss: 4.4457  val_loss: 10.5386  accML: 0.1537  accMI: 0.1135  time: 0.7639  data: 0.6017  max mem: 20905
Val Epoch: [1]  [539/540]  eta: 0:00:00  ml_loss: 5.9782  mi_loss: 4.3405  val_loss: 10.3187  accML: 0.1502  accMI: 0.1577  time: 0.7753  data: 0.6156  max mem: 20905
Val Epoch: [1] Total time: 0:07:29 (0.8319 s / it)
epoch:1, iter:9709, 4854,  train_loss: 9.812825202941895, valid_loss: 10.330189628954287, idiv_loss:(5.6667347236915875, 4.66345490305512), acc:(0.18101917218278957, 0.11825324968883284)
Averaged stats: lr: 0.0000  ml_loss: 5.8414  mi_loss: 4.8618  train_loss: 10.7032
epoch 1 9.812825202941895
Train Epoch: [2]  [   0/4855]  eta: 7:26:51  lr: 0.000010  ml_loss: 5.9500  mi_loss: 4.8702  train_loss: 10.8202  time: 5.5225  data: 2.3539  max mem: 20905
Train Epoch: [2]  [  50/4855]  eta: 3:23:23  lr: 0.000010  ml_loss: 5.1472  mi_loss: 4.6550  train_loss: 9.8022  time: 2.4830  data: 0.0001  max mem: 20905
Train Epoch: [2]  [ 100/4855]  eta: 3:18:30  lr: 0.000010  ml_loss: 5.6035  mi_loss: 4.7065  train_loss: 10.3101  time: 2.4563  data: 0.0001  max mem: 20905
Train Epoch: [2]  [ 150/4855]  eta: 3:14:12  lr: 0.000010  ml_loss: 5.7093  mi_loss: 4.6015  train_loss: 10.3108  time: 2.4080  data: 0.0001  max mem: 20905
Train Epoch: [2]  [ 200/4855]  eta: 3:11:44  lr: 0.000010  ml_loss: 5.6410  mi_loss: 5.2716  train_loss: 10.9126  time: 2.4496  data: 0.0001  max mem: 20905
Train Epoch: [2]  [ 250/4855]  eta: 3:09:11  lr: 0.000010  ml_loss: 6.0281  mi_loss: 4.7641  train_loss: 10.7922  time: 2.4204  data: 0.0001  max mem: 20905
Train Epoch: [2]  [ 300/4855]  eta: 3:06:47  lr: 0.000010  ml_loss: 5.5836  mi_loss: 4.6303  train_loss: 10.2139  time: 2.4637  data: 0.0001  max mem: 20905
Train Epoch: [2]  [ 350/4855]  eta: 3:04:35  lr: 0.000010  ml_loss: 5.1035  mi_loss: 5.4455  train_loss: 10.5490  time: 2.4416  data: 0.0001  max mem: 20905
Train Epoch: [2]  [ 400/4855]  eta: 3:02:15  lr: 0.000010  ml_loss: 5.6874  mi_loss: 4.1678  train_loss: 9.8551  time: 2.4185  data: 0.0001  max mem: 20905
Train Epoch: [2]  [ 450/4855]  eta: 2:59:57  lr: 0.000010  ml_loss: 5.7780  mi_loss: 4.5192  train_loss: 10.2973  time: 2.4167  data: 0.0001  max mem: 20905
Train Epoch: [2]  [ 500/4855]  eta: 2:57:48  lr: 0.000010  ml_loss: 5.5601  mi_loss: 4.6694  train_loss: 10.2295  time: 2.4077  data: 0.0001  max mem: 20905
Train Epoch: [2]  [ 550/4855]  eta: 2:55:48  lr: 0.000010  ml_loss: 5.4058  mi_loss: 4.5318  train_loss: 9.9377  time: 2.4592  data: 0.0001  max mem: 20905
Train Epoch: [2]  [ 600/4855]  eta: 2:53:41  lr: 0.000010  ml_loss: 5.7601  mi_loss: 4.4789  train_loss: 10.2390  time: 2.4341  data: 0.0001  max mem: 20905
Train Epoch: [2]  [ 650/4855]  eta: 2:51:40  lr: 0.000010  ml_loss: 5.8171  mi_loss: 4.8942  train_loss: 10.7113  time: 2.4507  data: 0.0001  max mem: 20905
Train Epoch: [2]  [ 700/4855]  eta: 2:49:39  lr: 0.000010  ml_loss: 5.8309  mi_loss: 4.2078  train_loss: 10.0386  time: 2.4608  data: 0.0001  max mem: 20905
Train Epoch: [2]  [ 750/4855]  eta: 2:47:32  lr: 0.000010  ml_loss: 5.7750  mi_loss: 4.7393  train_loss: 10.5143  time: 2.4183  data: 0.0001  max mem: 20905
Train Epoch: [2]  [ 800/4855]  eta: 2:45:24  lr: 0.000010  ml_loss: 5.5743  mi_loss: 4.3303  train_loss: 9.9046  time: 2.4361  data: 0.0001  max mem: 20905
Train Epoch: [2]  [ 850/4855]  eta: 2:43:22  lr: 0.000010  ml_loss: 5.6928  mi_loss: 4.5774  train_loss: 10.2702  time: 2.4493  data: 0.0001  max mem: 20905
Train Epoch: [2]  [ 900/4855]  eta: 2:41:21  lr: 0.000010  ml_loss: 5.8968  mi_loss: 4.5763  train_loss: 10.4731  time: 2.4557  data: 0.0001  max mem: 20905
Train Epoch: [2]  [ 950/4855]  eta: 2:39:19  lr: 0.000010  ml_loss: 5.5753  mi_loss: 4.6589  train_loss: 10.2342  time: 2.4362  data: 0.0001  max mem: 20905
Train Epoch: [2]  [1000/4855]  eta: 2:37:15  lr: 0.000010  ml_loss: 5.9583  mi_loss: 4.9569  train_loss: 10.9152  time: 2.4405  data: 0.0001  max mem: 20905
Train Epoch: [2]  [1050/4855]  eta: 2:35:13  lr: 0.000010  ml_loss: 5.5368  mi_loss: 4.8819  train_loss: 10.4187  time: 2.4301  data: 0.0001  max mem: 20905
Train Epoch: [2]  [1100/4855]  eta: 2:33:07  lr: 0.000010  ml_loss: 5.5926  mi_loss: 4.3295  train_loss: 9.9221  time: 2.4265  data: 0.0001  max mem: 20905
Train Epoch: [2]  [1150/4855]  eta: 2:31:05  lr: 0.000010  ml_loss: 5.8923  mi_loss: 4.9352  train_loss: 10.8275  time: 2.4340  data: 0.0001  max mem: 20905
Train Epoch: [2]  [1200/4855]  eta: 2:29:03  lr: 0.000010  ml_loss: 5.8479  mi_loss: 4.8194  train_loss: 10.6674  time: 2.4444  data: 0.0002  max mem: 20905
Train Epoch: [2]  [1250/4855]  eta: 2:27:02  lr: 0.000010  ml_loss: 5.4840  mi_loss: 5.0144  train_loss: 10.4984  time: 2.4496  data: 0.0001  max mem: 20905
Train Epoch: [2]  [1300/4855]  eta: 2:25:00  lr: 0.000010  ml_loss: 5.5395  mi_loss: 4.2789  train_loss: 9.8184  time: 2.4401  data: 0.0001  max mem: 20905
Train Epoch: [2]  [1350/4855]  eta: 2:22:58  lr: 0.000010  ml_loss: 5.5765  mi_loss: 4.2652  train_loss: 9.8417  time: 2.4525  data: 0.0001  max mem: 20905
Train Epoch: [2]  [1400/4855]  eta: 2:20:55  lr: 0.000010  ml_loss: 5.5876  mi_loss: 4.7728  train_loss: 10.3604  time: 2.4452  data: 0.0001  max mem: 20905
Train Epoch: [2]  [1450/4855]  eta: 2:18:55  lr: 0.000010  ml_loss: 5.9763  mi_loss: 4.4907  train_loss: 10.4670  time: 2.4670  data: 0.0001  max mem: 20905
Train Epoch: [2]  [1500/4855]  eta: 2:16:52  lr: 0.000010  ml_loss: 5.9155  mi_loss: 4.7258  train_loss: 10.6413  time: 2.4457  data: 0.0001  max mem: 20905
Train Epoch: [2]  [1550/4855]  eta: 2:14:51  lr: 0.000010  ml_loss: 5.5178  mi_loss: 4.8162  train_loss: 10.3341  time: 2.4707  data: 0.0001  max mem: 20905
Train Epoch: [2]  [1600/4855]  eta: 2:12:48  lr: 0.000010  ml_loss: 5.2756  mi_loss: 4.3442  train_loss: 9.6198  time: 2.4454  data: 0.0001  max mem: 20905
Train Epoch: [2]  [1650/4855]  eta: 2:10:47  lr: 0.000010  ml_loss: 6.1661  mi_loss: 4.5052  train_loss: 10.6713  time: 2.4571  data: 0.0001  max mem: 20905
Train Epoch: [2]  [1700/4855]  eta: 2:08:43  lr: 0.000010  ml_loss: 5.5617  mi_loss: 4.5053  train_loss: 10.0670  time: 2.4412  data: 0.0001  max mem: 20905
Train Epoch: [2]  [1750/4855]  eta: 2:06:41  lr: 0.000010  ml_loss: 5.6103  mi_loss: 3.1834  train_loss: 8.7937  time: 2.4390  data: 0.0001  max mem: 20905
Train Epoch: [2]  [1800/4855]  eta: 2:04:40  lr: 0.000010  ml_loss: 5.5306  mi_loss: 4.8853  train_loss: 10.4159  time: 2.4523  data: 0.0001  max mem: 20905
Train Epoch: [2]  [1850/4855]  eta: 2:02:39  lr: 0.000010  ml_loss: 6.6095  mi_loss: 4.7847  train_loss: 11.3942  time: 2.4498  data: 0.0001  max mem: 20905
Train Epoch: [2]  [1900/4855]  eta: 2:00:38  lr: 0.000010  ml_loss: 5.8084  mi_loss: 5.2556  train_loss: 11.0640  time: 2.4480  data: 0.0001  max mem: 20905
Train Epoch: [2]  [1950/4855]  eta: 1:58:35  lr: 0.000010  ml_loss: 5.5958  mi_loss: 4.4322  train_loss: 10.0279  time: 2.4273  data: 0.0001  max mem: 20905
Train Epoch: [2]  [2000/4855]  eta: 1:56:33  lr: 0.000010  ml_loss: 5.4108  mi_loss: 4.4595  train_loss: 9.8702  time: 2.4468  data: 0.0001  max mem: 20905
Train Epoch: [2]  [2050/4855]  eta: 1:54:30  lr: 0.000010  ml_loss: 5.7204  mi_loss: 4.6833  train_loss: 10.4038  time: 2.4391  data: 0.0001  max mem: 20905
Train Epoch: [2]  [2100/4855]  eta: 1:52:27  lr: 0.000010  ml_loss: 6.1565  mi_loss: 4.4256  train_loss: 10.5822  time: 2.4516  data: 0.0001  max mem: 20905
Train Epoch: [2]  [2150/4855]  eta: 1:50:27  lr: 0.000010  ml_loss: 5.9034  mi_loss: 4.6319  train_loss: 10.5353  time: 2.4901  data: 0.0001  max mem: 20905
Train Epoch: [2]  [2200/4855]  eta: 1:48:27  lr: 0.000010  ml_loss: 5.6316  mi_loss: 4.5500  train_loss: 10.1815  time: 2.4893  data: 0.0001  max mem: 20905
Train Epoch: [2]  [2250/4855]  eta: 1:46:25  lr: 0.000010  ml_loss: 5.8804  mi_loss: 4.5276  train_loss: 10.4080  time: 2.4614  data: 0.0001  max mem: 20905
Train Epoch: [2]  [2300/4855]  eta: 1:44:24  lr: 0.000010  ml_loss: 5.7734  mi_loss: 4.5713  train_loss: 10.3447  time: 2.4879  data: 0.0001  max mem: 20905
Train Epoch: [2]  [2350/4855]  eta: 1:42:23  lr: 0.000010  ml_loss: 5.8695  mi_loss: 4.4142  train_loss: 10.2837  time: 2.4853  data: 0.0001  max mem: 20905
Train Epoch: [2]  [2400/4855]  eta: 1:40:22  lr: 0.000010  ml_loss: 5.4142  mi_loss: 4.3585  train_loss: 9.7727  time: 2.4742  data: 0.0001  max mem: 20905
Train Epoch: [2]  [2450/4855]  eta: 1:38:20  lr: 0.000010  ml_loss: 5.7104  mi_loss: 4.3926  train_loss: 10.1029  time: 2.4667  data: 0.0001  max mem: 20905
Train Epoch: [2]  [2500/4855]  eta: 1:36:18  lr: 0.000010  ml_loss: 5.5800  mi_loss: 4.7305  train_loss: 10.3105  time: 2.4842  data: 0.0001  max mem: 20905
Train Epoch: [2]  [2550/4855]  eta: 1:34:17  lr: 0.000010  ml_loss: 5.6733  mi_loss: 4.3975  train_loss: 10.0708  time: 2.4873  data: 0.0001  max mem: 20905
Train Epoch: [2]  [2600/4855]  eta: 1:32:15  lr: 0.000010  ml_loss: 5.5424  mi_loss: 4.4217  train_loss: 9.9641  time: 2.4542  data: 0.0001  max mem: 20905
Train Epoch: [2]  [2650/4855]  eta: 1:30:13  lr: 0.000010  ml_loss: 5.8632  mi_loss: 4.8959  train_loss: 10.7591  time: 2.4926  data: 0.0001  max mem: 20905
Train Epoch: [2]  [2700/4855]  eta: 1:28:12  lr: 0.000010  ml_loss: 5.7913  mi_loss: 4.5796  train_loss: 10.3709  time: 2.4911  data: 0.0001  max mem: 20905
Train Epoch: [2]  [2750/4855]  eta: 1:26:10  lr: 0.000010  ml_loss: 5.9722  mi_loss: 5.0724  train_loss: 11.0447  time: 2.4878  data: 0.0001  max mem: 20905
Train Epoch: [2]  [2800/4855]  eta: 1:24:09  lr: 0.000010  ml_loss: 5.8969  mi_loss: 4.2750  train_loss: 10.1719  time: 2.4810  data: 0.0001  max mem: 20905
Train Epoch: [2]  [2850/4855]  eta: 1:22:07  lr: 0.000010  ml_loss: 5.2462  mi_loss: 4.9633  train_loss: 10.2095  time: 2.4906  data: 0.0001  max mem: 20905
Train Epoch: [2]  [2900/4855]  eta: 1:20:05  lr: 0.000010  ml_loss: 5.6397  mi_loss: 4.0393  train_loss: 9.6790  time: 2.4936  data: 0.0001  max mem: 20905
Train Epoch: [2]  [2950/4855]  eta: 1:18:03  lr: 0.000010  ml_loss: 5.7944  mi_loss: 4.4059  train_loss: 10.2002  time: 2.4869  data: 0.0002  max mem: 20905
Train Epoch: [2]  [3000/4855]  eta: 1:16:01  lr: 0.000010  ml_loss: 5.4616  mi_loss: 4.0333  train_loss: 9.4948  time: 2.4857  data: 0.0001  max mem: 20905
Train Epoch: [2]  [3050/4855]  eta: 1:13:59  lr: 0.000010  ml_loss: 5.5826  mi_loss: 5.1084  train_loss: 10.6910  time: 2.4856  data: 0.0001  max mem: 20905
Train Epoch: [2]  [3100/4855]  eta: 1:11:56  lr: 0.000010  ml_loss: 5.9911  mi_loss: 4.6031  train_loss: 10.5942  time: 2.4608  data: 0.0001  max mem: 20905
Train Epoch: [2]  [3150/4855]  eta: 1:09:54  lr: 0.000010  ml_loss: 5.7532  mi_loss: 4.8502  train_loss: 10.6034  time: 2.4899  data: 0.0002  max mem: 20905
Train Epoch: [2]  [3200/4855]  eta: 1:07:52  lr: 0.000010  ml_loss: 5.8220  mi_loss: 4.7531  train_loss: 10.5751  time: 2.4891  data: 0.0001  max mem: 20905
Train Epoch: [2]  [3250/4855]  eta: 1:05:49  lr: 0.000010  ml_loss: 5.2338  mi_loss: 4.2929  train_loss: 9.5267  time: 2.4313  data: 0.0001  max mem: 20905
Train Epoch: [2]  [3300/4855]  eta: 1:03:45  lr: 0.000010  ml_loss: 6.2348  mi_loss: 4.5456  train_loss: 10.7803  time: 2.4513  data: 0.0001  max mem: 20905
Train Epoch: [2]  [3350/4855]  eta: 1:01:42  lr: 0.000010  ml_loss: 5.4202  mi_loss: 4.4988  train_loss: 9.9190  time: 2.4600  data: 0.0001  max mem: 20905
Train Epoch: [2]  [3400/4855]  eta: 0:59:39  lr: 0.000010  ml_loss: 5.5856  mi_loss: 4.7701  train_loss: 10.3557  time: 2.4521  data: 0.0001  max mem: 20905
Train Epoch: [2]  [3450/4855]  eta: 0:57:36  lr: 0.000010  ml_loss: 5.8327  mi_loss: 4.4321  train_loss: 10.2648  time: 2.4158  data: 0.0001  max mem: 20905
Train Epoch: [2]  [3500/4855]  eta: 0:55:32  lr: 0.000010  ml_loss: 5.1026  mi_loss: 4.3909  train_loss: 9.4935  time: 2.4699  data: 0.0001  max mem: 20905
Train Epoch: [2]  [3550/4855]  eta: 0:53:30  lr: 0.000010  ml_loss: 5.5877  mi_loss: 4.1950  train_loss: 9.7827  time: 2.4714  data: 0.0001  max mem: 20905
Train Epoch: [2]  [3600/4855]  eta: 0:51:27  lr: 0.000010  ml_loss: 5.5161  mi_loss: 4.2421  train_loss: 9.7582  time: 2.4742  data: 0.0001  max mem: 20905
Train Epoch: [2]  [3650/4855]  eta: 0:49:24  lr: 0.000010  ml_loss: 4.9145  mi_loss: 4.1665  train_loss: 9.0810  time: 2.4283  data: 0.0001  max mem: 20905
Train Epoch: [2]  [3700/4855]  eta: 0:47:20  lr: 0.000010  ml_loss: 5.6866  mi_loss: 4.6154  train_loss: 10.3020  time: 2.4593  data: 0.0001  max mem: 20905
Train Epoch: [2]  [3750/4855]  eta: 0:45:17  lr: 0.000010  ml_loss: 5.6695  mi_loss: 4.6006  train_loss: 10.2701  time: 2.4489  data: 0.0001  max mem: 20905
Train Epoch: [2]  [3800/4855]  eta: 0:43:14  lr: 0.000010  ml_loss: 5.8024  mi_loss: 4.7571  train_loss: 10.5595  time: 2.4603  data: 0.0001  max mem: 20905
Train Epoch: [2]  [3850/4855]  eta: 0:41:11  lr: 0.000010  ml_loss: 5.6803  mi_loss: 4.6343  train_loss: 10.3147  time: 2.4690  data: 0.0001  max mem: 20905
Train Epoch: [2]  [3900/4855]  eta: 0:39:08  lr: 0.000010  ml_loss: 4.7333  mi_loss: 4.9627  train_loss: 9.6960  time: 2.4450  data: 0.0001  max mem: 20905
Train Epoch: [2]  [3950/4855]  eta: 0:37:05  lr: 0.000010  ml_loss: 4.9569  mi_loss: 4.7562  train_loss: 9.7131  time: 2.4765  data: 0.0001  max mem: 20905
Train Epoch: [2]  [4000/4855]  eta: 0:35:02  lr: 0.000010  ml_loss: 5.2970  mi_loss: 4.2617  train_loss: 9.5587  time: 2.4602  data: 0.0001  max mem: 20905
Train Epoch: [2]  [4050/4855]  eta: 0:32:59  lr: 0.000010  ml_loss: 5.7982  mi_loss: 4.2316  train_loss: 10.0298  time: 2.4653  data: 0.0001  max mem: 20905
Train Epoch: [2]  [4100/4855]  eta: 0:30:57  lr: 0.000010  ml_loss: 5.5211  mi_loss: 5.0569  train_loss: 10.5779  time: 2.4799  data: 0.0001  max mem: 20905
Train Epoch: [2]  [4150/4855]  eta: 0:28:53  lr: 0.000010  ml_loss: 5.6710  mi_loss: 4.4091  train_loss: 10.0802  time: 2.4366  data: 0.0001  max mem: 20905
Train Epoch: [2]  [4200/4855]  eta: 0:26:51  lr: 0.000010  ml_loss: 5.5409  mi_loss: 4.7289  train_loss: 10.2698  time: 2.4730  data: 0.0001  max mem: 20905
Train Epoch: [2]  [4250/4855]  eta: 0:24:48  lr: 0.000010  ml_loss: 5.1508  mi_loss: 4.4708  train_loss: 9.6216  time: 2.4756  data: 0.0001  max mem: 20905
Train Epoch: [2]  [4300/4855]  eta: 0:22:45  lr: 0.000010  ml_loss: 5.7189  mi_loss: 4.6729  train_loss: 10.3917  time: 2.4491  data: 0.0001  max mem: 20905
Train Epoch: [2]  [4350/4855]  eta: 0:20:42  lr: 0.000010  ml_loss: 5.6966  mi_loss: 4.2460  train_loss: 9.9426  time: 2.4470  data: 0.0001  max mem: 20905
Train Epoch: [2]  [4400/4855]  eta: 0:18:39  lr: 0.000010  ml_loss: 5.5797  mi_loss: 4.4033  train_loss: 9.9830  time: 2.4595  data: 0.0001  max mem: 20905
Train Epoch: [2]  [4450/4855]  eta: 0:16:36  lr: 0.000010  ml_loss: 4.5753  mi_loss: 4.6280  train_loss: 9.2033  time: 2.4555  data: 0.0001  max mem: 20905
Train Epoch: [2]  [4500/4855]  eta: 0:14:33  lr: 0.000010  ml_loss: 5.4035  mi_loss: 4.0396  train_loss: 9.4432  time: 2.4378  data: 0.0001  max mem: 20905
Train Epoch: [2]  [4550/4855]  eta: 0:12:30  lr: 0.000010  ml_loss: 5.4937  mi_loss: 4.2592  train_loss: 9.7529  time: 2.4465  data: 0.0001  max mem: 20905
Train Epoch: [2]  [4600/4855]  eta: 0:10:27  lr: 0.000010  ml_loss: 4.4332  mi_loss: 4.1777  train_loss: 8.6108  time: 2.4374  data: 0.0001  max mem: 20905
Train Epoch: [2]  [4650/4855]  eta: 0:08:24  lr: 0.000010  ml_loss: 5.3136  mi_loss: 4.8918  train_loss: 10.2054  time: 2.4769  data: 0.0001  max mem: 20905
Train Epoch: [2]  [4700/4855]  eta: 0:06:21  lr: 0.000010  ml_loss: 5.9979  mi_loss: 3.8914  train_loss: 9.8893  time: 2.4654  data: 0.0001  max mem: 20905
Train Epoch: [2]  [4750/4855]  eta: 0:04:18  lr: 0.000010  ml_loss: 5.3336  mi_loss: 4.5047  train_loss: 9.8383  time: 2.4759  data: 0.0001  max mem: 20905
Train Epoch: [2]  [4800/4855]  eta: 0:02:15  lr: 0.000010  ml_loss: 5.9064  mi_loss: 4.4720  train_loss: 10.3784  time: 2.4759  data: 0.0001  max mem: 20905
Train Epoch: [2]  [4850/4855]  eta: 0:00:12  lr: 0.000010  ml_loss: 5.7144  mi_loss: 4.5643  train_loss: 10.2787  time: 2.4221  data: 0.0001  max mem: 20905
Train Epoch: [2]  [4854/4855]  eta: 0:00:02  lr: 0.000010  ml_loss: 4.8411  mi_loss: 4.5725  train_loss: 9.4135  time: 2.4373  data: 0.0008  max mem: 20905
Train Epoch: [2] Total time: 3:19:02 (2.4599 s / it)
Val Epoch: [2]  [  0/540]  eta: 0:23:34  ml_loss: 5.4848  mi_loss: 4.6723  val_loss: 10.1571  accML: 0.2017  accMI: 0.0811  time: 2.6189  data: 2.2752  max mem: 20905
Val Epoch: [2]  [ 50/540]  eta: 0:06:50  ml_loss: 5.4581  mi_loss: 4.2535  val_loss: 9.7116  accML: 0.1943  accMI: 0.1743  time: 0.7754  data: 0.6143  max mem: 20905
Val Epoch: [2]  [100/540]  eta: 0:06:01  ml_loss: 5.5529  mi_loss: 4.5514  val_loss: 10.1043  accML: 0.1555  accMI: 0.1307  time: 0.7748  data: 0.6130  max mem: 20905
Val Epoch: [2]  [150/540]  eta: 0:05:28  ml_loss: 5.7969  mi_loss: 4.8201  val_loss: 10.6170  accML: 0.1779  accMI: 0.1078  time: 0.9186  data: 0.7553  max mem: 20905
Val Epoch: [2]  [200/540]  eta: 0:04:46  ml_loss: 5.7414  mi_loss: 4.8818  val_loss: 10.6231  accML: 0.1653  accMI: 0.0722  time: 0.8460  data: 0.6838  max mem: 20905
Val Epoch: [2]  [250/540]  eta: 0:04:02  ml_loss: 5.3372  mi_loss: 4.3650  val_loss: 9.7021  accML: 0.2088  accMI: 0.1332  time: 0.8322  data: 0.6696  max mem: 20905
Val Epoch: [2]  [300/540]  eta: 0:03:20  ml_loss: 5.2786  mi_loss: 4.2758  val_loss: 9.5544  accML: 0.1923  accMI: 0.1667  time: 0.8669  data: 0.7038  max mem: 20905
Val Epoch: [2]  [350/540]  eta: 0:02:38  ml_loss: 5.5548  mi_loss: 3.5864  val_loss: 9.1412  accML: 0.1923  accMI: 0.2667  time: 0.8214  data: 0.6591  max mem: 20905
Val Epoch: [2]  [400/540]  eta: 0:01:57  ml_loss: 5.8320  mi_loss: 4.5943  val_loss: 10.4262  accML: 0.1910  accMI: 0.1022  time: 0.8664  data: 0.7037  max mem: 20905
Val Epoch: [2]  [450/540]  eta: 0:01:15  ml_loss: 5.7529  mi_loss: 4.4132  val_loss: 10.1660  accML: 0.1953  accMI: 0.0960  time: 0.8340  data: 0.6710  max mem: 20905
Val Epoch: [2]  [500/540]  eta: 0:00:33  ml_loss: 5.8734  mi_loss: 4.3971  val_loss: 10.2705  accML: 0.1647  accMI: 0.1270  time: 0.7619  data: 0.5999  max mem: 20905
Val Epoch: [2]  [539/540]  eta: 0:00:00  ml_loss: 5.9082  mi_loss: 4.2237  val_loss: 10.1319  accML: 0.1651  accMI: 0.1532  time: 0.7637  data: 0.6043  max mem: 20905
Val Epoch: [2] Total time: 0:07:33 (0.8404 s / it)
epoch:2, iter:14564, 4854,  train_loss: 9.413530349731445, valid_loss: 10.066634623209636, idiv_loss:(5.546775574154324, 4.519859069365042), acc:(0.19227037075217124, 0.12669539686844306)
Averaged stats: lr: 0.0000  ml_loss: 5.6209  mi_loss: 4.5739  train_loss: 10.1948
epoch 2 9.413530349731445
Train Epoch: [3]  [   0/4855]  eta: 6:49:55  lr: 0.000010  ml_loss: 5.2584  mi_loss: 4.5274  train_loss: 9.7859  time: 5.0661  data: 2.2080  max mem: 20905
Train Epoch: [3]  [  50/4855]  eta: 3:21:54  lr: 0.000010  ml_loss: 5.2730  mi_loss: 4.6482  train_loss: 9.9211  time: 2.4639  data: 0.0001  max mem: 20905
Train Epoch: [3]  [ 100/4855]  eta: 3:16:44  lr: 0.000010  ml_loss: 5.7399  mi_loss: 4.8193  train_loss: 10.5592  time: 2.4448  data: 0.0001  max mem: 20905
Train Epoch: [3]  [ 150/4855]  eta: 3:13:40  lr: 0.000010  ml_loss: 5.8216  mi_loss: 4.4903  train_loss: 10.3119  time: 2.4641  data: 0.0002  max mem: 20905
Train Epoch: [3]  [ 200/4855]  eta: 3:11:31  lr: 0.000010  ml_loss: 5.4937  mi_loss: 4.6503  train_loss: 10.1440  time: 2.4585  data: 0.0001  max mem: 20905
Train Epoch: [3]  [ 250/4855]  eta: 3:09:06  lr: 0.000010  ml_loss: 5.9100  mi_loss: 4.4279  train_loss: 10.3379  time: 2.4268  data: 0.0001  max mem: 20905
Train Epoch: [3]  [ 300/4855]  eta: 3:06:47  lr: 0.000010  ml_loss: 5.9177  mi_loss: 4.6589  train_loss: 10.5766  time: 2.4407  data: 0.0001  max mem: 20905
Train Epoch: [3]  [ 350/4855]  eta: 3:04:52  lr: 0.000010  ml_loss: 5.2718  mi_loss: 4.4721  train_loss: 9.7439  time: 2.4735  data: 0.0001  max mem: 20905
Train Epoch: [3]  [ 400/4855]  eta: 3:02:49  lr: 0.000010  ml_loss: 5.8354  mi_loss: 4.3995  train_loss: 10.2349  time: 2.4847  data: 0.0001  max mem: 20905
Train Epoch: [3]  [ 450/4855]  eta: 3:00:47  lr: 0.000010  ml_loss: 5.5231  mi_loss: 4.6146  train_loss: 10.1377  time: 2.4522  data: 0.0001  max mem: 20905
Train Epoch: [3]  [ 500/4855]  eta: 2:58:36  lr: 0.000010  ml_loss: 5.1775  mi_loss: 4.5204  train_loss: 9.6979  time: 2.4342  data: 0.0001  max mem: 20905
Train Epoch: [3]  [ 550/4855]  eta: 2:56:33  lr: 0.000010  ml_loss: 5.2293  mi_loss: 4.5693  train_loss: 9.7986  time: 2.4729  data: 0.0001  max mem: 20905
Train Epoch: [3]  [ 600/4855]  eta: 2:54:38  lr: 0.000010  ml_loss: 5.5047  mi_loss: 4.3365  train_loss: 9.8412  time: 2.4750  data: 0.0001  max mem: 20905
Train Epoch: [3]  [ 650/4855]  eta: 2:52:37  lr: 0.000010  ml_loss: 3.6987  mi_loss: 4.7912  train_loss: 8.4899  time: 2.4722  data: 0.0001  max mem: 20905
Train Epoch: [3]  [ 700/4855]  eta: 2:50:37  lr: 0.000010  ml_loss: 5.4217  mi_loss: 4.5660  train_loss: 9.9877  time: 2.4720  data: 0.0001  max mem: 20905
Train Epoch: [3]  [ 750/4855]  eta: 2:48:36  lr: 0.000010  ml_loss: 5.4410  mi_loss: 4.6677  train_loss: 10.1087  time: 2.4600  data: 0.0001  max mem: 20905
Train Epoch: [3]  [ 800/4855]  eta: 2:46:31  lr: 0.000010  ml_loss: 6.1052  mi_loss: 4.1949  train_loss: 10.3001  time: 2.4562  data: 0.0001  max mem: 20905
Train Epoch: [3]  [ 850/4855]  eta: 2:44:26  lr: 0.000010  ml_loss: 5.2967  mi_loss: 4.1921  train_loss: 9.4888  time: 2.4384  data: 0.0001  max mem: 20905
Train Epoch: [3]  [ 900/4855]  eta: 2:42:22  lr: 0.000010  ml_loss: 5.4597  mi_loss: 4.4481  train_loss: 9.9078  time: 2.4649  data: 0.0001  max mem: 20905
Train Epoch: [3]  [ 950/4855]  eta: 2:40:15  lr: 0.000010  ml_loss: 5.4384  mi_loss: 4.6590  train_loss: 10.0974  time: 2.4539  data: 0.0001  max mem: 20905
Train Epoch: [3]  [1000/4855]  eta: 2:38:09  lr: 0.000010  ml_loss: 5.9007  mi_loss: 4.4613  train_loss: 10.3620  time: 2.4625  data: 0.0001  max mem: 20905
Train Epoch: [3]  [1050/4855]  eta: 2:36:06  lr: 0.000010  ml_loss: 5.8728  mi_loss: 4.5038  train_loss: 10.3766  time: 2.4679  data: 0.0001  max mem: 20905
Train Epoch: [3]  [1100/4855]  eta: 2:34:03  lr: 0.000010  ml_loss: 4.7866  mi_loss: 4.6210  train_loss: 9.4076  time: 2.4538  data: 0.0001  max mem: 20905
Train Epoch: [3]  [1150/4855]  eta: 2:32:00  lr: 0.000010  ml_loss: 6.1828  mi_loss: 4.0116  train_loss: 10.1944  time: 2.4580  data: 0.0001  max mem: 20905
Train Epoch: [3]  [1200/4855]  eta: 2:30:00  lr: 0.000010  ml_loss: 5.6725  mi_loss: 4.0707  train_loss: 9.7432  time: 2.4687  data: 0.0001  max mem: 20905
Train Epoch: [3]  [1250/4855]  eta: 2:27:56  lr: 0.000010  ml_loss: 5.5011  mi_loss: 4.4299  train_loss: 9.9311  time: 2.4528  data: 0.0003  max mem: 20905
Train Epoch: [3]  [1300/4855]  eta: 2:25:52  lr: 0.000010  ml_loss: 5.1818  mi_loss: 4.2376  train_loss: 9.4195  time: 2.4691  data: 0.0001  max mem: 20905
Train Epoch: [3]  [1350/4855]  eta: 2:23:50  lr: 0.000010  ml_loss: 5.8365  mi_loss: 4.4272  train_loss: 10.2637  time: 2.4560  data: 0.0001  max mem: 20905
Train Epoch: [3]  [1400/4855]  eta: 2:21:48  lr: 0.000010  ml_loss: 5.6090  mi_loss: 4.5779  train_loss: 10.1869  time: 2.4709  data: 0.0001  max mem: 20905
Train Epoch: [3]  [1450/4855]  eta: 2:19:46  lr: 0.000010  ml_loss: 5.7285  mi_loss: 3.4372  train_loss: 9.1657  time: 2.4794  data: 0.0001  max mem: 20905
Train Epoch: [3]  [1500/4855]  eta: 2:17:43  lr: 0.000010  ml_loss: 5.9605  mi_loss: 4.7293  train_loss: 10.6898  time: 2.4487  data: 0.0001  max mem: 20905
Train Epoch: [3]  [1550/4855]  eta: 2:15:40  lr: 0.000010  ml_loss: 5.3629  mi_loss: 4.9238  train_loss: 10.2867  time: 2.4435  data: 0.0001  max mem: 20905
Train Epoch: [3]  [1600/4855]  eta: 2:13:35  lr: 0.000010  ml_loss: 6.0557  mi_loss: 3.6406  train_loss: 9.6964  time: 2.4757  data: 0.0001  max mem: 20905
Train Epoch: [3]  [1650/4855]  eta: 2:11:32  lr: 0.000010  ml_loss: 5.3650  mi_loss: 4.8104  train_loss: 10.1754  time: 2.4653  data: 0.0001  max mem: 20905
Train Epoch: [3]  [1700/4855]  eta: 2:09:29  lr: 0.000010  ml_loss: 4.8178  mi_loss: 4.3603  train_loss: 9.1782  time: 2.4663  data: 0.0001  max mem: 20905
Train Epoch: [3]  [1750/4855]  eta: 2:07:27  lr: 0.000010  ml_loss: 5.8537  mi_loss: 3.9664  train_loss: 9.8202  time: 2.4695  data: 0.0001  max mem: 20905
Train Epoch: [3]  [1800/4855]  eta: 2:05:24  lr: 0.000010  ml_loss: 5.1181  mi_loss: 3.9514  train_loss: 9.0695  time: 2.4789  data: 0.0001  max mem: 20905
Train Epoch: [3]  [1850/4855]  eta: 2:03:21  lr: 0.000010  ml_loss: 5.7299  mi_loss: 3.3811  train_loss: 9.1110  time: 2.4712  data: 0.0001  max mem: 20905
Train Epoch: [3]  [1900/4855]  eta: 2:01:16  lr: 0.000010  ml_loss: 5.8545  mi_loss: 4.8830  train_loss: 10.7375  time: 2.4285  data: 0.0001  max mem: 20905
Train Epoch: [3]  [1950/4855]  eta: 1:59:11  lr: 0.000010  ml_loss: 5.5877  mi_loss: 4.5238  train_loss: 10.1115  time: 2.4574  data: 0.0001  max mem: 20905
Train Epoch: [3]  [2000/4855]  eta: 1:57:08  lr: 0.000010  ml_loss: 5.8811  mi_loss: 4.7781  train_loss: 10.6592  time: 2.4542  data: 0.0001  max mem: 20905
Train Epoch: [3]  [2050/4855]  eta: 1:55:05  lr: 0.000010  ml_loss: 5.5132  mi_loss: 4.3443  train_loss: 9.8574  time: 2.4442  data: 0.0001  max mem: 20905
Train Epoch: [3]  [2100/4855]  eta: 1:53:02  lr: 0.000010  ml_loss: 5.3451  mi_loss: 4.5709  train_loss: 9.9160  time: 2.4477  data: 0.0001  max mem: 20905
Train Epoch: [3]  [2150/4855]  eta: 1:50:58  lr: 0.000010  ml_loss: 5.4539  mi_loss: 4.1053  train_loss: 9.5592  time: 2.4364  data: 0.0001  max mem: 20905
Train Epoch: [3]  [2200/4855]  eta: 1:48:54  lr: 0.000010  ml_loss: 5.3100  mi_loss: 4.4890  train_loss: 9.7990  time: 2.4629  data: 0.0001  max mem: 20905
Train Epoch: [3]  [2250/4855]  eta: 1:46:51  lr: 0.000010  ml_loss: 5.2808  mi_loss: 4.3110  train_loss: 9.5918  time: 2.4432  data: 0.0001  max mem: 20905
Train Epoch: [3]  [2300/4855]  eta: 1:44:48  lr: 0.000010  ml_loss: 5.9919  mi_loss: 4.4718  train_loss: 10.4637  time: 2.4653  data: 0.0001  max mem: 20905
Train Epoch: [3]  [2350/4855]  eta: 1:42:45  lr: 0.000010  ml_loss: 5.6961  mi_loss: 4.2191  train_loss: 9.9151  time: 2.4656  data: 0.0001  max mem: 20905
Train Epoch: [3]  [2400/4855]  eta: 1:40:42  lr: 0.000010  ml_loss: 5.1735  mi_loss: 4.4619  train_loss: 9.6354  time: 2.4905  data: 0.0001  max mem: 20905
Train Epoch: [3]  [2450/4855]  eta: 1:38:41  lr: 0.000010  ml_loss: 5.4984  mi_loss: 4.2666  train_loss: 9.7650  time: 2.5041  data: 0.0001  max mem: 20905
Train Epoch: [3]  [2500/4855]  eta: 1:36:38  lr: 0.000010  ml_loss: 5.4275  mi_loss: 4.6487  train_loss: 10.0762  time: 2.4939  data: 0.0001  max mem: 20905
Train Epoch: [3]  [2550/4855]  eta: 1:34:36  lr: 0.000010  ml_loss: 5.4242  mi_loss: 4.5860  train_loss: 10.0101  time: 2.4695  data: 0.0001  max mem: 20905
Train Epoch: [3]  [2600/4855]  eta: 1:32:34  lr: 0.000010  ml_loss: 5.5008  mi_loss: 4.5659  train_loss: 10.0667  time: 2.4740  data: 0.0001  max mem: 20905
Train Epoch: [3]  [2650/4855]  eta: 1:30:31  lr: 0.000010  ml_loss: 5.5295  mi_loss: 4.6241  train_loss: 10.1536  time: 2.4817  data: 0.0001  max mem: 20905
Train Epoch: [3]  [2700/4855]  eta: 1:28:28  lr: 0.000010  ml_loss: 5.6093  mi_loss: 4.7774  train_loss: 10.3867  time: 2.4854  data: 0.0001  max mem: 20905
Train Epoch: [3]  [2750/4855]  eta: 1:26:26  lr: 0.000010  ml_loss: 5.6323  mi_loss: 4.5706  train_loss: 10.2029  time: 2.5023  data: 0.0001  max mem: 20905
Train Epoch: [3]  [2800/4855]  eta: 1:24:24  lr: 0.000010  ml_loss: 4.8316  mi_loss: 4.8896  train_loss: 9.7213  time: 2.4752  data: 0.0001  max mem: 20905
Train Epoch: [3]  [2850/4855]  eta: 1:22:22  lr: 0.000010  ml_loss: 5.1155  mi_loss: 4.5112  train_loss: 9.6267  time: 2.5050  data: 0.0001  max mem: 20905
Train Epoch: [3]  [2900/4855]  eta: 1:20:19  lr: 0.000010  ml_loss: 5.2692  mi_loss: 3.6992  train_loss: 8.9684  time: 2.4674  data: 0.0001  max mem: 20905
Train Epoch: [3]  [2950/4855]  eta: 1:18:16  lr: 0.000010  ml_loss: 5.4153  mi_loss: 4.5165  train_loss: 9.9318  time: 2.4905  data: 0.0001  max mem: 20905
Train Epoch: [3]  [3000/4855]  eta: 1:16:13  lr: 0.000010  ml_loss: 5.5134  mi_loss: 4.1106  train_loss: 9.6241  time: 2.4772  data: 0.0001  max mem: 20905
Train Epoch: [3]  [3050/4855]  eta: 1:14:10  lr: 0.000010  ml_loss: 5.5343  mi_loss: 4.3362  train_loss: 9.8705  time: 2.4867  data: 0.0001  max mem: 20905
Train Epoch: [3]  [3100/4855]  eta: 1:12:07  lr: 0.000010  ml_loss: 5.4975  mi_loss: 4.2858  train_loss: 9.7833  time: 2.4775  data: 0.0001  max mem: 20905
Train Epoch: [3]  [3150/4855]  eta: 1:10:05  lr: 0.000010  ml_loss: 5.2653  mi_loss: 4.1055  train_loss: 9.3708  time: 2.4957  data: 0.0001  max mem: 20905
Train Epoch: [3]  [3200/4855]  eta: 1:08:02  lr: 0.000010  ml_loss: 5.8775  mi_loss: 3.2996  train_loss: 9.1772  time: 2.4630  data: 0.0001  max mem: 20905
Train Epoch: [3]  [3250/4855]  eta: 1:05:58  lr: 0.000010  ml_loss: 4.9831  mi_loss: 4.3303  train_loss: 9.3135  time: 2.4693  data: 0.0001  max mem: 20905
Train Epoch: [3]  [3300/4855]  eta: 1:03:56  lr: 0.000010  ml_loss: 5.4851  mi_loss: 4.3972  train_loss: 9.8823  time: 2.4888  data: 0.0001  max mem: 20905
Train Epoch: [3]  [3350/4855]  eta: 1:01:53  lr: 0.000010  ml_loss: 5.7566  mi_loss: 4.1395  train_loss: 9.8962  time: 2.4883  data: 0.0001  max mem: 20905
Train Epoch: [3]  [3400/4855]  eta: 0:59:50  lr: 0.000010  ml_loss: 5.3798  mi_loss: 4.4957  train_loss: 9.8755  time: 2.4807  data: 0.0001  max mem: 20905
Train Epoch: [3]  [3450/4855]  eta: 0:57:47  lr: 0.000010  ml_loss: 5.3160  mi_loss: 4.1931  train_loss: 9.5091  time: 2.4879  data: 0.0001  max mem: 20905
Train Epoch: [3]  [3500/4855]  eta: 0:55:44  lr: 0.000010  ml_loss: 5.8764  mi_loss: 4.1569  train_loss: 10.0333  time: 2.4891  data: 0.0002  max mem: 20905
Train Epoch: [3]  [3550/4855]  eta: 0:53:40  lr: 0.000010  ml_loss: 5.5457  mi_loss: 4.5129  train_loss: 10.0586  time: 2.4708  data: 0.0002  max mem: 20905
Train Epoch: [3]  [3600/4855]  eta: 0:51:37  lr: 0.000010  ml_loss: 5.9391  mi_loss: 4.1218  train_loss: 10.0610  time: 2.4806  data: 0.0001  max mem: 20905
Train Epoch: [3]  [3650/4855]  eta: 0:49:34  lr: 0.000010  ml_loss: 5.0455  mi_loss: 4.4509  train_loss: 9.4965  time: 2.4899  data: 0.0001  max mem: 20905
Train Epoch: [3]  [3700/4855]  eta: 0:47:30  lr: 0.000010  ml_loss: 5.3594  mi_loss: 3.8568  train_loss: 9.2162  time: 2.4549  data: 0.0001  max mem: 20905
Train Epoch: [3]  [3750/4855]  eta: 0:45:27  lr: 0.000010  ml_loss: 4.8807  mi_loss: 4.5478  train_loss: 9.4285  time: 2.4769  data: 0.0001  max mem: 20905
Train Epoch: [3]  [3800/4855]  eta: 0:43:24  lr: 0.000010  ml_loss: 5.3837  mi_loss: 4.4321  train_loss: 9.8158  time: 2.4864  data: 0.0001  max mem: 20905
Train Epoch: [3]  [3850/4855]  eta: 0:41:21  lr: 0.000010  ml_loss: 5.0099  mi_loss: 3.7358  train_loss: 8.7457  time: 2.4629  data: 0.0001  max mem: 20905
Train Epoch: [3]  [3900/4855]  eta: 0:39:17  lr: 0.000010  ml_loss: 5.9947  mi_loss: 4.1853  train_loss: 10.1800  time: 2.5021  data: 0.0001  max mem: 20905
Train Epoch: [3]  [3950/4855]  eta: 0:37:14  lr: 0.000010  ml_loss: 5.4600  mi_loss: 4.8567  train_loss: 10.3168  time: 2.4781  data: 0.0001  max mem: 20905
Train Epoch: [3]  [4000/4855]  eta: 0:35:11  lr: 0.000010  ml_loss: 5.8190  mi_loss: 4.3042  train_loss: 10.1232  time: 2.4860  data: 0.0001  max mem: 20905
Train Epoch: [3]  [4050/4855]  eta: 0:33:07  lr: 0.000010  ml_loss: 5.4148  mi_loss: 4.4626  train_loss: 9.8774  time: 2.4853  data: 0.0001  max mem: 20905
Train Epoch: [3]  [4100/4855]  eta: 0:31:04  lr: 0.000010  ml_loss: 5.2000  mi_loss: 4.3584  train_loss: 9.5585  time: 2.4819  data: 0.0001  max mem: 20905
Train Epoch: [3]  [4150/4855]  eta: 0:29:01  lr: 0.000010  ml_loss: 5.1829  mi_loss: 4.8349  train_loss: 10.0178  time: 2.4652  data: 0.0001  max mem: 20905
Train Epoch: [3]  [4200/4855]  eta: 0:26:57  lr: 0.000010  ml_loss: 5.5714  mi_loss: 4.3231  train_loss: 9.8945  time: 2.4428  data: 0.0001  max mem: 20905
Train Epoch: [3]  [4250/4855]  eta: 0:24:53  lr: 0.000010  ml_loss: 5.7145  mi_loss: 4.5161  train_loss: 10.2306  time: 2.4459  data: 0.0001  max mem: 20905
Train Epoch: [3]  [4300/4855]  eta: 0:22:50  lr: 0.000010  ml_loss: 5.7298  mi_loss: 3.8045  train_loss: 9.5343  time: 2.4125  data: 0.0001  max mem: 20905
Train Epoch: [3]  [4350/4855]  eta: 0:20:46  lr: 0.000010  ml_loss: 5.0750  mi_loss: 4.8079  train_loss: 9.8829  time: 2.4462  data: 0.0001  max mem: 20905
Train Epoch: [3]  [4400/4855]  eta: 0:18:42  lr: 0.000010  ml_loss: 5.3784  mi_loss: 4.1788  train_loss: 9.5572  time: 2.4247  data: 0.0001  max mem: 20905
Train Epoch: [3]  [4450/4855]  eta: 0:16:39  lr: 0.000010  ml_loss: 5.5465  mi_loss: 4.4007  train_loss: 9.9472  time: 2.4261  data: 0.0001  max mem: 20905
Train Epoch: [3]  [4500/4855]  eta: 0:14:35  lr: 0.000010  ml_loss: 5.7725  mi_loss: 4.4058  train_loss: 10.1783  time: 2.4655  data: 0.0001  max mem: 20905
Train Epoch: [3]  [4550/4855]  eta: 0:12:32  lr: 0.000010  ml_loss: 5.8416  mi_loss: 4.3696  train_loss: 10.2112  time: 2.4484  data: 0.0001  max mem: 20905
Train Epoch: [3]  [4600/4855]  eta: 0:10:29  lr: 0.000010  ml_loss: 5.2909  mi_loss: 3.8817  train_loss: 9.1726  time: 2.4477  data: 0.0001  max mem: 20905
Train Epoch: [3]  [4650/4855]  eta: 0:08:25  lr: 0.000010  ml_loss: 5.2909  mi_loss: 4.2683  train_loss: 9.5592  time: 2.4628  data: 0.0001  max mem: 20905
Train Epoch: [3]  [4700/4855]  eta: 0:06:22  lr: 0.000010  ml_loss: 5.1823  mi_loss: 4.2582  train_loss: 9.4405  time: 2.4698  data: 0.0001  max mem: 20905
Train Epoch: [3]  [4750/4855]  eta: 0:04:19  lr: 0.000010  ml_loss: 5.8851  mi_loss: 4.1162  train_loss: 10.0013  time: 2.4526  data: 0.0001  max mem: 20905
Train Epoch: [3]  [4800/4855]  eta: 0:02:15  lr: 0.000010  ml_loss: 5.3852  mi_loss: 4.3386  train_loss: 9.7238  time: 2.4672  data: 0.0001  max mem: 20905
Train Epoch: [3]  [4850/4855]  eta: 0:00:12  lr: 0.000010  ml_loss: 5.2923  mi_loss: 4.3464  train_loss: 9.6387  time: 2.4557  data: 0.0001  max mem: 20905
Train Epoch: [3]  [4854/4855]  eta: 0:00:02  lr: 0.000010  ml_loss: 5.6234  mi_loss: 4.2418  train_loss: 9.8653  time: 2.4581  data: 0.0008  max mem: 20905
Train Epoch: [3] Total time: 3:19:37 (2.4669 s / it)
Val Epoch: [3]  [  0/540]  eta: 0:23:58  ml_loss: 5.5556  mi_loss: 4.3863  val_loss: 9.9418  accML: 0.1913  accMI: 0.1054  time: 2.6636  data: 2.2687  max mem: 20905
Val Epoch: [3]  [ 50/540]  eta: 0:06:35  ml_loss: 5.1360  mi_loss: 4.0382  val_loss: 9.1742  accML: 0.2348  accMI: 0.1823  time: 0.7844  data: 0.6231  max mem: 20905
Val Epoch: [3]  [100/540]  eta: 0:05:53  ml_loss: 5.3272  mi_loss: 4.4338  val_loss: 9.7610  accML: 0.1949  accMI: 0.1413  time: 0.7648  data: 0.6035  max mem: 20905
Val Epoch: [3]  [150/540]  eta: 0:05:23  ml_loss: 5.4633  mi_loss: 4.6983  val_loss: 10.1616  accML: 0.1982  accMI: 0.1213  time: 0.9170  data: 0.7539  max mem: 20905
Val Epoch: [3]  [200/540]  eta: 0:04:42  ml_loss: 5.5956  mi_loss: 4.7370  val_loss: 10.3326  accML: 0.1912  accMI: 0.0856  time: 0.8406  data: 0.6785  max mem: 20905
Val Epoch: [3]  [250/540]  eta: 0:03:59  ml_loss: 4.9973  mi_loss: 4.1058  val_loss: 9.1031  accML: 0.2439  accMI: 0.1386  time: 0.8379  data: 0.6759  max mem: 20905
Val Epoch: [3]  [300/540]  eta: 0:03:18  ml_loss: 4.9802  mi_loss: 4.0857  val_loss: 9.0659  accML: 0.2364  accMI: 0.1559  time: 0.8631  data: 0.7003  max mem: 20905
Val Epoch: [3]  [350/540]  eta: 0:02:36  ml_loss: 5.2248  mi_loss: 3.3742  val_loss: 8.5990  accML: 0.2000  accMI: 0.2773  time: 0.7959  data: 0.6342  max mem: 20905
Val Epoch: [3]  [400/540]  eta: 0:01:56  ml_loss: 5.9609  mi_loss: 4.4487  val_loss: 10.4096  accML: 0.1795  accMI: 0.0968  time: 0.8615  data: 0.6988  max mem: 20905
Val Epoch: [3]  [450/540]  eta: 0:01:14  ml_loss: 5.5326  mi_loss: 4.2531  val_loss: 9.7857  accML: 0.1959  accMI: 0.1040  time: 0.8305  data: 0.6675  max mem: 20905
Val Epoch: [3]  [500/540]  eta: 0:00:33  ml_loss: 5.4960  mi_loss: 4.1738  val_loss: 9.6698  accML: 0.2188  accMI: 0.1459  time: 0.7620  data: 0.5992  max mem: 20905
Val Epoch: [3]  [539/540]  eta: 0:00:00  ml_loss: 5.6348  mi_loss: 4.0558  val_loss: 9.6906  accML: 0.1901  accMI: 0.1847  time: 0.7774  data: 0.6176  max mem: 20905
Val Epoch: [3] Total time: 0:07:30 (0.8334 s / it)
epoch:3, iter:19419, 4854,  train_loss: 9.86526107788086, valid_loss: 9.674481709798178, idiv_loss:(5.364648887846205, 4.309832819302877), acc:(0.20345056575757486, 0.13966709798270904)
Averaged stats: lr: 0.0000  ml_loss: 5.4686  mi_loss: 4.3834  train_loss: 9.8520
epoch 3 9.86526107788086
Train Epoch: [4]  [   0/4855]  eta: 7:19:52  lr: 0.000010  ml_loss: 5.3033  mi_loss: 4.5633  train_loss: 9.8666  time: 5.4361  data: 2.5834  max mem: 20905
Train Epoch: [4]  [  50/4855]  eta: 3:23:08  lr: 0.000010  ml_loss: 5.5156  mi_loss: 4.3445  train_loss: 9.8601  time: 2.4801  data: 0.0001  max mem: 20905
Train Epoch: [4]  [ 100/4855]  eta: 3:18:04  lr: 0.000010  ml_loss: 5.7328  mi_loss: 4.7742  train_loss: 10.5070  time: 2.4683  data: 0.0001  max mem: 20905
Train Epoch: [4]  [ 150/4855]  eta: 3:15:14  lr: 0.000010  ml_loss: 5.3724  mi_loss: 4.5487  train_loss: 9.9211  time: 2.4853  data: 0.0001  max mem: 20905
Train Epoch: [4]  [ 200/4855]  eta: 3:13:11  lr: 0.000010  ml_loss: 4.8632  mi_loss: 4.4914  train_loss: 9.3546  time: 2.4884  data: 0.0001  max mem: 20905
Train Epoch: [4]  [ 250/4855]  eta: 3:10:42  lr: 0.000010  ml_loss: 5.0784  mi_loss: 4.7891  train_loss: 9.8675  time: 2.4403  data: 0.0001  max mem: 20905
Train Epoch: [4]  [ 300/4855]  eta: 3:08:33  lr: 0.000010  ml_loss: 5.7284  mi_loss: 3.8979  train_loss: 9.6263  time: 2.4817  data: 0.0001  max mem: 20905
Train Epoch: [4]  [ 350/4855]  eta: 3:06:29  lr: 0.000010  ml_loss: 5.5615  mi_loss: 4.2726  train_loss: 9.8341  time: 2.4838  data: 0.0001  max mem: 20905
Train Epoch: [4]  [ 400/4855]  eta: 3:04:15  lr: 0.000010  ml_loss: 5.7676  mi_loss: 4.1934  train_loss: 9.9610  time: 2.4623  data: 0.0001  max mem: 20905
Train Epoch: [4]  [ 450/4855]  eta: 3:02:04  lr: 0.000010  ml_loss: 5.3926  mi_loss: 4.1748  train_loss: 9.5674  time: 2.4607  data: 0.0001  max mem: 20905
Train Epoch: [4]  [ 500/4855]  eta: 3:00:04  lr: 0.000010  ml_loss: 5.1231  mi_loss: 4.1829  train_loss: 9.3061  time: 2.4967  data: 0.0001  max mem: 20905
Train Epoch: [4]  [ 550/4855]  eta: 2:57:59  lr: 0.000010  ml_loss: 5.4588  mi_loss: 4.0056  train_loss: 9.4644  time: 2.4562  data: 0.0001  max mem: 20905
Train Epoch: [4]  [ 600/4855]  eta: 2:55:44  lr: 0.000010  ml_loss: 5.4552  mi_loss: 4.3487  train_loss: 9.8039  time: 2.4572  data: 0.0002  max mem: 20905
Train Epoch: [4]  [ 650/4855]  eta: 2:53:42  lr: 0.000010  ml_loss: 5.3627  mi_loss: 4.2757  train_loss: 9.6385  time: 2.4850  data: 0.0001  max mem: 20905
Train Epoch: [4]  [ 700/4855]  eta: 2:51:37  lr: 0.000010  ml_loss: 5.2450  mi_loss: 4.2756  train_loss: 9.5206  time: 2.4675  data: 0.0002  max mem: 20905
Train Epoch: [4]  [ 750/4855]  eta: 2:49:25  lr: 0.000010  ml_loss: 5.0796  mi_loss: 4.2952  train_loss: 9.3748  time: 2.4338  data: 0.0001  max mem: 20905
Train Epoch: [4]  [ 800/4855]  eta: 2:47:22  lr: 0.000010  ml_loss: 5.4397  mi_loss: 4.5380  train_loss: 9.9777  time: 2.4954  data: 0.0001  max mem: 20905
Train Epoch: [4]  [ 850/4855]  eta: 2:45:16  lr: 0.000010  ml_loss: 5.7353  mi_loss: 4.3580  train_loss: 10.0933  time: 2.4736  data: 0.0001  max mem: 20905
Train Epoch: [4]  [ 900/4855]  eta: 2:43:13  lr: 0.000010  ml_loss: 5.7186  mi_loss: 4.4987  train_loss: 10.2173  time: 2.4843  data: 0.0001  max mem: 20905
Train Epoch: [4]  [ 950/4855]  eta: 2:41:05  lr: 0.000010  ml_loss: 5.0699  mi_loss: 4.2805  train_loss: 9.3504  time: 2.4491  data: 0.0001  max mem: 20905
Train Epoch: [4]  [1000/4855]  eta: 2:39:00  lr: 0.000010  ml_loss: 5.2806  mi_loss: 4.0169  train_loss: 9.2975  time: 2.4488  data: 0.0002  max mem: 20905
Train Epoch: [4]  [1050/4855]  eta: 2:36:54  lr: 0.000010  ml_loss: 5.3644  mi_loss: 4.4209  train_loss: 9.7854  time: 2.4776  data: 0.0002  max mem: 20905
Train Epoch: [4]  [1100/4855]  eta: 2:34:53  lr: 0.000010  ml_loss: 5.4166  mi_loss: 4.5670  train_loss: 9.9836  time: 2.4906  data: 0.0002  max mem: 20905
Train Epoch: [4]  [1150/4855]  eta: 2:32:52  lr: 0.000010  ml_loss: 5.4145  mi_loss: 4.2705  train_loss: 9.6850  time: 2.4851  data: 0.0004  max mem: 20905
Train Epoch: [4]  [1200/4855]  eta: 2:30:47  lr: 0.000010  ml_loss: 5.5034  mi_loss: 3.8825  train_loss: 9.3859  time: 2.4770  data: 0.0001  max mem: 20905
Train Epoch: [4]  [1250/4855]  eta: 2:28:45  lr: 0.000010  ml_loss: 5.0222  mi_loss: 4.8917  train_loss: 9.9140  time: 2.4948  data: 0.0001  max mem: 20905
Train Epoch: [4]  [1300/4855]  eta: 2:26:41  lr: 0.000010  ml_loss: 5.5472  mi_loss: 4.3819  train_loss: 9.9291  time: 2.4627  data: 0.0002  max mem: 20905
Train Epoch: [4]  [1350/4855]  eta: 2:24:39  lr: 0.000010  ml_loss: 5.4641  mi_loss: 4.7810  train_loss: 10.2451  time: 2.5021  data: 0.0001  max mem: 20905
Train Epoch: [4]  [1400/4855]  eta: 2:22:38  lr: 0.000010  ml_loss: 5.3263  mi_loss: 4.2915  train_loss: 9.6178  time: 2.4940  data: 0.0002  max mem: 20905
Train Epoch: [4]  [1450/4855]  eta: 2:20:29  lr: 0.000010  ml_loss: 5.9220  mi_loss: 4.5286  train_loss: 10.4506  time: 2.4397  data: 0.0002  max mem: 20905
Train Epoch: [4]  [1500/4855]  eta: 2:18:21  lr: 0.000010  ml_loss: 5.7299  mi_loss: 3.2070  train_loss: 8.9369  time: 2.4332  data: 0.0001  max mem: 20905
Train Epoch: [4]  [1550/4855]  eta: 2:16:17  lr: 0.000010  ml_loss: 5.2414  mi_loss: 4.2858  train_loss: 9.5272  time: 2.4747  data: 0.0001  max mem: 20905
Train Epoch: [4]  [1600/4855]  eta: 2:14:11  lr: 0.000010  ml_loss: 5.8255  mi_loss: 4.1529  train_loss: 9.9783  time: 2.4623  data: 0.0001  max mem: 20905
Train Epoch: [4]  [1650/4855]  eta: 2:12:04  lr: 0.000010  ml_loss: 5.6387  mi_loss: 4.2740  train_loss: 9.9127  time: 2.4281  data: 0.0001  max mem: 20905
Train Epoch: [4]  [1700/4855]  eta: 2:09:59  lr: 0.000010  ml_loss: 5.5903  mi_loss: 4.4881  train_loss: 10.0784  time: 2.4378  data: 0.0001  max mem: 20905
Train Epoch: [4]  [1750/4855]  eta: 2:07:54  lr: 0.000010  ml_loss: 5.3167  mi_loss: 4.4491  train_loss: 9.7658  time: 2.4665  data: 0.0001  max mem: 20905
Train Epoch: [4]  [1800/4855]  eta: 2:05:50  lr: 0.000010  ml_loss: 5.7275  mi_loss: 4.2537  train_loss: 9.9812  time: 2.4592  data: 0.0001  max mem: 20905
Train Epoch: [4]  [1850/4855]  eta: 2:03:44  lr: 0.000010  ml_loss: 5.3555  mi_loss: 4.6620  train_loss: 10.0176  time: 2.4303  data: 0.0001  max mem: 20905
Train Epoch: [4]  [1900/4855]  eta: 2:01:37  lr: 0.000010  ml_loss: 5.8838  mi_loss: 4.2629  train_loss: 10.1467  time: 2.4089  data: 0.0001  max mem: 20905
Train Epoch: [4]  [1950/4855]  eta: 1:59:31  lr: 0.000010  ml_loss: 5.3194  mi_loss: 4.5506  train_loss: 9.8700  time: 2.4428  data: 0.0002  max mem: 20905
Train Epoch: [4]  [2000/4855]  eta: 1:57:26  lr: 0.000010  ml_loss: 5.1288  mi_loss: 4.7340  train_loss: 9.8628  time: 2.4512  data: 0.0002  max mem: 20905
Train Epoch: [4]  [2050/4855]  eta: 1:55:20  lr: 0.000010  ml_loss: 5.5660  mi_loss: 4.6477  train_loss: 10.2137  time: 2.4248  data: 0.0002  max mem: 20905
Train Epoch: [4]  [2100/4855]  eta: 1:53:15  lr: 0.000010  ml_loss: 5.2248  mi_loss: 4.2116  train_loss: 9.4364  time: 2.4484  data: 0.0002  max mem: 20905
Train Epoch: [4]  [2150/4855]  eta: 1:51:10  lr: 0.000010  ml_loss: 5.1395  mi_loss: 4.3975  train_loss: 9.5370  time: 2.4480  data: 0.0001  max mem: 20905
Train Epoch: [4]  [2200/4855]  eta: 1:49:05  lr: 0.000010  ml_loss: 5.3508  mi_loss: 4.0560  train_loss: 9.4067  time: 2.4483  data: 0.0002  max mem: 20905
Train Epoch: [4]  [2250/4855]  eta: 1:47:00  lr: 0.000010  ml_loss: 5.4316  mi_loss: 4.1675  train_loss: 9.5991  time: 2.4301  data: 0.0004  max mem: 20905
Train Epoch: [4]  [2300/4855]  eta: 1:44:55  lr: 0.000010  ml_loss: 5.4006  mi_loss: 4.1217  train_loss: 9.5223  time: 2.4445  data: 0.0002  max mem: 20905
Train Epoch: [4]  [2350/4855]  eta: 1:42:51  lr: 0.000010  ml_loss: 5.0265  mi_loss: 4.3307  train_loss: 9.3572  time: 2.4312  data: 0.0001  max mem: 20905
Train Epoch: [4]  [2400/4855]  eta: 1:40:46  lr: 0.000010  ml_loss: 4.7628  mi_loss: 3.9346  train_loss: 8.6974  time: 2.4378  data: 0.0001  max mem: 20905
Train Epoch: [4]  [2450/4855]  eta: 1:38:43  lr: 0.000010  ml_loss: 5.3620  mi_loss: 5.0541  train_loss: 10.4161  time: 2.4584  data: 0.0001  max mem: 20905
Train Epoch: [4]  [2500/4855]  eta: 1:36:39  lr: 0.000010  ml_loss: 5.7494  mi_loss: 4.1531  train_loss: 9.9026  time: 2.4544  data: 0.0005  max mem: 20905
Train Epoch: [4]  [2550/4855]  eta: 1:34:34  lr: 0.000010  ml_loss: 5.2146  mi_loss: 4.3294  train_loss: 9.5439  time: 2.4066  data: 0.0002  max mem: 20905
Train Epoch: [4]  [2600/4855]  eta: 1:32:30  lr: 0.000010  ml_loss: 6.0188  mi_loss: 4.1841  train_loss: 10.2028  time: 2.4507  data: 0.0001  max mem: 20905
Train Epoch: [4]  [2650/4855]  eta: 1:30:26  lr: 0.000010  ml_loss: 5.3019  mi_loss: 4.4124  train_loss: 9.7143  time: 2.4206  data: 0.0002  max mem: 20905
Train Epoch: [4]  [2700/4855]  eta: 1:28:22  lr: 0.000010  ml_loss: 4.4745  mi_loss: 5.0493  train_loss: 9.5238  time: 2.4516  data: 0.0001  max mem: 20905
Train Epoch: [4]  [2750/4855]  eta: 1:26:19  lr: 0.000010  ml_loss: 5.6864  mi_loss: 4.2771  train_loss: 9.9635  time: 2.4571  data: 0.0002  max mem: 20905
Train Epoch: [4]  [2800/4855]  eta: 1:24:15  lr: 0.000010  ml_loss: 5.6172  mi_loss: 4.1700  train_loss: 9.7872  time: 2.4119  data: 0.0002  max mem: 20905
Train Epoch: [4]  [2850/4855]  eta: 1:22:11  lr: 0.000010  ml_loss: 5.3468  mi_loss: 4.2783  train_loss: 9.6251  time: 2.4640  data: 0.0001  max mem: 20905
Train Epoch: [4]  [2900/4855]  eta: 1:20:08  lr: 0.000010  ml_loss: 5.6434  mi_loss: 4.7580  train_loss: 10.4015  time: 2.4326  data: 0.0001  max mem: 20905
Train Epoch: [4]  [2950/4855]  eta: 1:18:05  lr: 0.000010  ml_loss: 5.6533  mi_loss: 4.2385  train_loss: 9.8918  time: 2.4557  data: 0.0002  max mem: 20905
Train Epoch: [4]  [3000/4855]  eta: 1:16:02  lr: 0.000010  ml_loss: 5.3304  mi_loss: 4.3351  train_loss: 9.6655  time: 2.4624  data: 0.0002  max mem: 20905
Train Epoch: [4]  [3050/4855]  eta: 1:13:58  lr: 0.000010  ml_loss: 5.3587  mi_loss: 4.3085  train_loss: 9.6671  time: 2.4329  data: 0.0002  max mem: 20905
Train Epoch: [4]  [3100/4855]  eta: 1:11:54  lr: 0.000010  ml_loss: 4.6625  mi_loss: 4.5078  train_loss: 9.1703  time: 2.4587  data: 0.0002  max mem: 20905
Train Epoch: [4]  [3150/4855]  eta: 1:09:51  lr: 0.000010  ml_loss: 5.6602  mi_loss: 4.7270  train_loss: 10.3872  time: 2.4713  data: 0.0002  max mem: 20905
Train Epoch: [4]  [3200/4855]  eta: 1:07:48  lr: 0.000010  ml_loss: 5.2069  mi_loss: 4.2566  train_loss: 9.4635  time: 2.4516  data: 0.0002  max mem: 20905
Train Epoch: [4]  [3250/4855]  eta: 1:05:45  lr: 0.000010  ml_loss: 5.1483  mi_loss: 4.1517  train_loss: 9.3000  time: 2.4366  data: 0.0002  max mem: 20905
Train Epoch: [4]  [3300/4855]  eta: 1:03:42  lr: 0.000010  ml_loss: 5.2879  mi_loss: 4.5229  train_loss: 9.8108  time: 2.4543  data: 0.0002  max mem: 20905
Train Epoch: [4]  [3350/4855]  eta: 1:01:39  lr: 0.000010  ml_loss: 5.1596  mi_loss: 4.6570  train_loss: 9.8166  time: 2.4484  data: 0.0002  max mem: 20905
Train Epoch: [4]  [3400/4855]  eta: 0:59:36  lr: 0.000010  ml_loss: 5.3070  mi_loss: 4.0604  train_loss: 9.3674  time: 2.4257  data: 0.0002  max mem: 20905
Train Epoch: [4]  [3450/4855]  eta: 0:57:33  lr: 0.000010  ml_loss: 5.5076  mi_loss: 4.6094  train_loss: 10.1170  time: 2.4541  data: 0.0001  max mem: 20905
Train Epoch: [4]  [3500/4855]  eta: 0:55:30  lr: 0.000010  ml_loss: 5.6727  mi_loss: 4.2180  train_loss: 9.8908  time: 2.4099  data: 0.0001  max mem: 20905
Train Epoch: [4]  [3550/4855]  eta: 0:53:27  lr: 0.000010  ml_loss: 5.4760  mi_loss: 3.5256  train_loss: 9.0017  time: 2.4564  data: 0.0001  max mem: 20905
Train Epoch: [4]  [3600/4855]  eta: 0:51:23  lr: 0.000010  ml_loss: 5.1317  mi_loss: 4.5301  train_loss: 9.6618  time: 2.4395  data: 0.0001  max mem: 20905
Train Epoch: [4]  [3650/4855]  eta: 0:49:20  lr: 0.000010  ml_loss: 5.5267  mi_loss: 4.4761  train_loss: 10.0028  time: 2.4083  data: 0.0001  max mem: 20905
Train Epoch: [4]  [3700/4855]  eta: 0:47:17  lr: 0.000010  ml_loss: 5.5823  mi_loss: 4.3667  train_loss: 9.9491  time: 2.4232  data: 0.0001  max mem: 20905
Train Epoch: [4]  [3750/4855]  eta: 0:45:14  lr: 0.000010  ml_loss: 5.8519  mi_loss: 4.3534  train_loss: 10.2053  time: 2.4698  data: 0.0001  max mem: 20905
Train Epoch: [4]  [3800/4855]  eta: 0:43:11  lr: 0.000010  ml_loss: 5.4681  mi_loss: 3.5471  train_loss: 9.0152  time: 2.4264  data: 0.0002  max mem: 20905
Train Epoch: [4]  [3850/4855]  eta: 0:41:08  lr: 0.000010  ml_loss: 5.1774  mi_loss: 4.4881  train_loss: 9.6655  time: 2.4971  data: 0.0001  max mem: 20905
Train Epoch: [4]  [3900/4855]  eta: 0:39:05  lr: 0.000010  ml_loss: 5.0667  mi_loss: 4.7051  train_loss: 9.7717  time: 2.4890  data: 0.0002  max mem: 20905
Train Epoch: [4]  [3950/4855]  eta: 0:37:03  lr: 0.000010  ml_loss: 5.2182  mi_loss: 4.7058  train_loss: 9.9240  time: 2.4962  data: 0.0001  max mem: 20905
Train Epoch: [4]  [4000/4855]  eta: 0:35:01  lr: 0.000010  ml_loss: 5.4327  mi_loss: 5.0357  train_loss: 10.4684  time: 2.5019  data: 0.0001  max mem: 20905
Train Epoch: [4]  [4050/4855]  eta: 0:32:58  lr: 0.000010  ml_loss: 5.1943  mi_loss: 4.4206  train_loss: 9.6150  time: 2.4636  data: 0.0001  max mem: 20905
Train Epoch: [4]  [4100/4855]  eta: 0:30:55  lr: 0.000010  ml_loss: 5.4023  mi_loss: 4.1633  train_loss: 9.5656  time: 2.4967  data: 0.0002  max mem: 20905
Train Epoch: [4]  [4150/4855]  eta: 0:28:52  lr: 0.000010  ml_loss: 5.3028  mi_loss: 4.5263  train_loss: 9.8291  time: 2.4619  data: 0.0001  max mem: 20905
Train Epoch: [4]  [4200/4855]  eta: 0:26:50  lr: 0.000010  ml_loss: 5.7320  mi_loss: 4.0834  train_loss: 9.8154  time: 2.4785  data: 0.0002  max mem: 20905
Train Epoch: [4]  [4250/4855]  eta: 0:24:47  lr: 0.000010  ml_loss: 5.3068  mi_loss: 4.3125  train_loss: 9.6194  time: 2.4718  data: 0.0001  max mem: 20905
Train Epoch: [4]  [4300/4855]  eta: 0:22:44  lr: 0.000010  ml_loss: 5.0906  mi_loss: 4.6982  train_loss: 9.7888  time: 2.4569  data: 0.0001  max mem: 20905
Train Epoch: [4]  [4350/4855]  eta: 0:20:41  lr: 0.000010  ml_loss: 5.2662  mi_loss: 4.3263  train_loss: 9.5926  time: 2.4445  data: 0.0001  max mem: 20905
Train Epoch: [4]  [4400/4855]  eta: 0:18:38  lr: 0.000010  ml_loss: 5.3754  mi_loss: 4.1791  train_loss: 9.5545  time: 2.4991  data: 0.0001  max mem: 20905
Train Epoch: [4]  [4450/4855]  eta: 0:16:35  lr: 0.000010  ml_loss: 5.1359  mi_loss: 4.2110  train_loss: 9.3469  time: 2.4362  data: 0.0001  max mem: 20905
Train Epoch: [4]  [4500/4855]  eta: 0:14:32  lr: 0.000010  ml_loss: 4.9493  mi_loss: 3.9944  train_loss: 8.9437  time: 2.4569  data: 0.0001  max mem: 20905
Train Epoch: [4]  [4550/4855]  eta: 0:12:29  lr: 0.000010  ml_loss: 4.6583  mi_loss: 4.8070  train_loss: 9.4653  time: 2.4744  data: 0.0001  max mem: 20905
Train Epoch: [4]  [4600/4855]  eta: 0:10:26  lr: 0.000010  ml_loss: 5.7621  mi_loss: 3.9822  train_loss: 9.7443  time: 2.4039  data: 0.0001  max mem: 20905
Train Epoch: [4]  [4650/4855]  eta: 0:08:24  lr: 0.000010  ml_loss: 5.4383  mi_loss: 4.3136  train_loss: 9.7519  time: 2.4445  data: 0.0001  max mem: 20905
Train Epoch: [4]  [4700/4855]  eta: 0:06:21  lr: 0.000010  ml_loss: 5.3499  mi_loss: 4.0810  train_loss: 9.4309  time: 2.4475  data: 0.0001  max mem: 20905
Train Epoch: [4]  [4750/4855]  eta: 0:04:18  lr: 0.000010  ml_loss: 5.5938  mi_loss: 4.8681  train_loss: 10.4619  time: 2.4679  data: 0.0002  max mem: 20905
Train Epoch: [4]  [4800/4855]  eta: 0:02:15  lr: 0.000010  ml_loss: 5.1037  mi_loss: 4.4169  train_loss: 9.5206  time: 2.4391  data: 0.0001  max mem: 20905
Train Epoch: [4]  [4850/4855]  eta: 0:00:12  lr: 0.000010  ml_loss: 4.8396  mi_loss: 4.5475  train_loss: 9.3871  time: 2.4316  data: 0.0001  max mem: 20905
Train Epoch: [4]  [4854/4855]  eta: 0:00:02  lr: 0.000010  ml_loss: 6.1574  mi_loss: 4.1401  train_loss: 10.2974  time: 2.4434  data: 0.0007  max mem: 20905
Train Epoch: [4] Total time: 3:18:55 (2.4584 s / it)
Val Epoch: [4]  [  0/540]  eta: 0:25:45  ml_loss: 5.2159  mi_loss: 4.4226  val_loss: 9.6385  accML: 0.2149  accMI: 0.1000  time: 2.8617  data: 2.4881  max mem: 20905
Val Epoch: [4]  [ 50/540]  eta: 0:06:40  ml_loss: 4.8594  mi_loss: 4.0363  val_loss: 8.8957  accML: 0.2776  accMI: 0.1877  time: 0.7825  data: 0.6214  max mem: 20905
Val Epoch: [4]  [100/540]  eta: 0:05:58  ml_loss: 5.3515  mi_loss: 4.4445  val_loss: 9.7960  accML: 0.2132  accMI: 0.1493  time: 0.7797  data: 0.6186  max mem: 20905
Val Epoch: [4]  [150/540]  eta: 0:05:27  ml_loss: 5.6678  mi_loss: 4.7818  val_loss: 10.4496  accML: 0.1717  accMI: 0.1159  time: 0.9230  data: 0.7603  max mem: 20905
Val Epoch: [4]  [200/540]  eta: 0:04:46  ml_loss: 5.2641  mi_loss: 4.6654  val_loss: 9.9295  accML: 0.2328  accMI: 0.0909  time: 0.8438  data: 0.6816  max mem: 20905
Val Epoch: [4]  [250/540]  eta: 0:04:02  ml_loss: 4.8151  mi_loss: 4.1895  val_loss: 9.0046  accML: 0.2603  accMI: 0.1223  time: 0.8490  data: 0.6867  max mem: 20905
Val Epoch: [4]  [300/540]  eta: 0:03:20  ml_loss: 5.0529  mi_loss: 4.0865  val_loss: 9.1394  accML: 0.2155  accMI: 0.1613  time: 0.8624  data: 0.6994  max mem: 20905
Val Epoch: [4]  [350/540]  eta: 0:02:38  ml_loss: 5.4263  mi_loss: 3.4075  val_loss: 8.8337  accML: 0.1987  accMI: 0.2827  time: 0.8074  data: 0.6456  max mem: 20905
Val Epoch: [4]  [400/540]  eta: 0:01:57  ml_loss: 5.7043  mi_loss: 4.4976  val_loss: 10.2019  accML: 0.1802  accMI: 0.1102  time: 0.8721  data: 0.7091  max mem: 20905
Val Epoch: [4]  [450/540]  eta: 0:01:15  ml_loss: 5.5061  mi_loss: 4.2369  val_loss: 9.7430  accML: 0.1896  accMI: 0.1253  time: 0.8377  data: 0.6747  max mem: 20905
Val Epoch: [4]  [500/540]  eta: 0:00:33  ml_loss: 5.4818  mi_loss: 4.1641  val_loss: 9.6459  accML: 0.2000  accMI: 0.1486  time: 0.7539  data: 0.5920  max mem: 20905
Val Epoch: [4]  [539/540]  eta: 0:00:00  ml_loss: 5.8283  mi_loss: 4.0926  val_loss: 9.9209  accML: 0.1462  accMI: 0.1802  time: 0.7650  data: 0.6055  max mem: 20905
Val Epoch: [4] Total time: 0:07:33 (0.8405 s / it)
epoch:4, iter:24274, 4854,  train_loss: 10.297422409057617, valid_loss: 9.57929979606911, idiv_loss:(5.26377299008546, 4.315526793179688), acc:(0.21235458158232548, 0.13992594810271705)
Averaged stats: lr: 0.0000  ml_loss: 5.3485  mi_loss: 4.3605  train_loss: 9.7090
epoch 4 10.297422409057617
Train Epoch: [5]  [   0/4855]  eta: 7:14:02  lr: 0.000010  ml_loss: 5.6161  mi_loss: 4.1707  train_loss: 9.7869  time: 5.3641  data: 2.8856  max mem: 20905
Train Epoch: [5]  [  50/4855]  eta: 3:21:02  lr: 0.000010  ml_loss: 5.6005  mi_loss: 4.0562  train_loss: 9.6567  time: 2.4525  data: 0.0001  max mem: 20905
Train Epoch: [5]  [ 100/4855]  eta: 3:15:57  lr: 0.000010  ml_loss: 5.7318  mi_loss: 4.5682  train_loss: 10.3000  time: 2.4379  data: 0.0001  max mem: 20905
Train Epoch: [5]  [ 150/4855]  eta: 3:12:33  lr: 0.000010  ml_loss: 5.3867  mi_loss: 4.3034  train_loss: 9.6902  time: 2.4026  data: 0.0001  max mem: 20905
Train Epoch: [5]  [ 200/4855]  eta: 3:10:02  lr: 0.000010  ml_loss: 5.4250  mi_loss: 4.4917  train_loss: 9.9167  time: 2.4161  data: 0.0001  max mem: 20905
Train Epoch: [5]  [ 250/4855]  eta: 3:08:09  lr: 0.000010  ml_loss: 4.7246  mi_loss: 4.6073  train_loss: 9.3319  time: 2.4588  data: 0.0001  max mem: 20905
Train Epoch: [5]  [ 300/4855]  eta: 3:05:51  lr: 0.000010  ml_loss: 5.2331  mi_loss: 4.2009  train_loss: 9.4340  time: 2.4305  data: 0.0001  max mem: 20905
Train Epoch: [5]  [ 350/4855]  eta: 3:03:33  lr: 0.000010  ml_loss: 4.2390  mi_loss: 4.4146  train_loss: 8.6536  time: 2.4234  data: 0.0001  max mem: 20905
Train Epoch: [5]  [ 400/4855]  eta: 3:01:30  lr: 0.000010  ml_loss: 5.3814  mi_loss: 4.1831  train_loss: 9.5645  time: 2.4635  data: 0.0001  max mem: 20905
Train Epoch: [5]  [ 450/4855]  eta: 2:59:35  lr: 0.000010  ml_loss: 5.5225  mi_loss: 4.6231  train_loss: 10.1456  time: 2.4635  data: 0.0001  max mem: 20905
Train Epoch: [5]  [ 500/4855]  eta: 2:57:30  lr: 0.000010  ml_loss: 4.9649  mi_loss: 4.6830  train_loss: 9.6479  time: 2.4173  data: 0.0001  max mem: 20905
Train Epoch: [5]  [ 550/4855]  eta: 2:55:15  lr: 0.000010  ml_loss: 4.9805  mi_loss: 4.5934  train_loss: 9.5739  time: 2.4107  data: 0.0001  max mem: 20905
Train Epoch: [5]  [ 600/4855]  eta: 2:53:22  lr: 0.000010  ml_loss: 5.4868  mi_loss: 4.4345  train_loss: 9.9212  time: 2.4691  data: 0.0001  max mem: 20905
Train Epoch: [5]  [ 650/4855]  eta: 2:51:17  lr: 0.000010  ml_loss: 4.5998  mi_loss: 4.2902  train_loss: 8.8900  time: 2.4434  data: 0.0001  max mem: 20905
Train Epoch: [5]  [ 700/4855]  eta: 2:49:10  lr: 0.000010  ml_loss: 5.4118  mi_loss: 3.9464  train_loss: 9.3582  time: 2.4032  data: 0.0001  max mem: 20905
Train Epoch: [5]  [ 750/4855]  eta: 2:47:06  lr: 0.000010  ml_loss: 4.8835  mi_loss: 4.6749  train_loss: 9.5583  time: 2.4373  data: 0.0001  max mem: 20905
Train Epoch: [5]  [ 800/4855]  eta: 2:45:00  lr: 0.000010  ml_loss: 5.4141  mi_loss: 4.1298  train_loss: 9.5440  time: 2.4215  data: 0.0001  max mem: 20905
Train Epoch: [5]  [ 850/4855]  eta: 2:42:53  lr: 0.000010  ml_loss: 5.3183  mi_loss: 4.1699  train_loss: 9.4883  time: 2.4272  data: 0.0001  max mem: 20905
Train Epoch: [5]  [ 900/4855]  eta: 2:40:51  lr: 0.000010  ml_loss: 4.8952  mi_loss: 4.0540  train_loss: 8.9492  time: 2.4542  data: 0.0001  max mem: 20905
Train Epoch: [5]  [ 950/4855]  eta: 2:38:49  lr: 0.000010  ml_loss: 5.6299  mi_loss: 4.1763  train_loss: 9.8062  time: 2.4086  data: 0.0001  max mem: 20905
Train Epoch: [5]  [1000/4855]  eta: 2:36:47  lr: 0.000010  ml_loss: 5.9194  mi_loss: 4.8451  train_loss: 10.7645  time: 2.4209  data: 0.0001  max mem: 20905
Train Epoch: [5]  [1050/4855]  eta: 2:34:49  lr: 0.000010  ml_loss: 5.3143  mi_loss: 4.2497  train_loss: 9.5640  time: 2.4676  data: 0.0001  max mem: 20905
Train Epoch: [5]  [1100/4855]  eta: 2:32:45  lr: 0.000010  ml_loss: 5.1810  mi_loss: 4.0782  train_loss: 9.2592  time: 2.4185  data: 0.0001  max mem: 20905
Train Epoch: [5]  [1150/4855]  eta: 2:30:46  lr: 0.000010  ml_loss: 5.5951  mi_loss: 4.9047  train_loss: 10.4999  time: 2.4670  data: 0.0001  max mem: 20905
Train Epoch: [5]  [1200/4855]  eta: 2:28:47  lr: 0.000010  ml_loss: 5.4260  mi_loss: 4.5017  train_loss: 9.9276  time: 2.4515  data: 0.0001  max mem: 20905
Train Epoch: [5]  [1250/4855]  eta: 2:26:48  lr: 0.000010  ml_loss: 5.1360  mi_loss: 4.5829  train_loss: 9.7189  time: 2.4669  data: 0.0001  max mem: 20905
Train Epoch: [5]  [1300/4855]  eta: 2:24:43  lr: 0.000010  ml_loss: 5.5153  mi_loss: 4.5398  train_loss: 10.0551  time: 2.4538  data: 0.0001  max mem: 20905
Train Epoch: [5]  [1350/4855]  eta: 2:22:43  lr: 0.000010  ml_loss: 5.6743  mi_loss: 4.5155  train_loss: 10.1899  time: 2.4324  data: 0.0001  max mem: 20905
Train Epoch: [5]  [1400/4855]  eta: 2:20:39  lr: 0.000010  ml_loss: 5.2902  mi_loss: 4.8468  train_loss: 10.1370  time: 2.4244  data: 0.0001  max mem: 20905
Train Epoch: [5]  [1450/4855]  eta: 2:18:37  lr: 0.000010  ml_loss: 5.4659  mi_loss: 4.1421  train_loss: 9.6080  time: 2.4182  data: 0.0001  max mem: 20905
Train Epoch: [5]  [1500/4855]  eta: 2:16:38  lr: 0.000010  ml_loss: 4.5029  mi_loss: 4.2002  train_loss: 8.7032  time: 2.4648  data: 0.0001  max mem: 20905
Train Epoch: [5]  [1550/4855]  eta: 2:14:35  lr: 0.000010  ml_loss: 5.7409  mi_loss: 4.3353  train_loss: 10.0762  time: 2.4569  data: 0.0001  max mem: 20905
Train Epoch: [5]  [1600/4855]  eta: 2:12:34  lr: 0.000010  ml_loss: 5.6898  mi_loss: 3.2688  train_loss: 8.9586  time: 2.4674  data: 0.0001  max mem: 20905
Train Epoch: [5]  [1650/4855]  eta: 2:10:34  lr: 0.000010  ml_loss: 5.2271  mi_loss: 4.9199  train_loss: 10.1469  time: 2.4598  data: 0.0001  max mem: 20905
Train Epoch: [5]  [1700/4855]  eta: 2:08:33  lr: 0.000010  ml_loss: 5.0926  mi_loss: 4.5233  train_loss: 9.6159  time: 2.4623  data: 0.0001  max mem: 20905
Train Epoch: [5]  [1750/4855]  eta: 2:06:34  lr: 0.000010  ml_loss: 5.3569  mi_loss: 4.3349  train_loss: 9.6918  time: 2.4799  data: 0.0001  max mem: 20905
Train Epoch: [5]  [1800/4855]  eta: 2:04:33  lr: 0.000010  ml_loss: 5.4330  mi_loss: 4.2327  train_loss: 9.6657  time: 2.4563  data: 0.0001  max mem: 20905
Train Epoch: [5]  [1850/4855]  eta: 2:02:33  lr: 0.000010  ml_loss: 5.3739  mi_loss: 4.5378  train_loss: 9.9118  time: 2.5017  data: 0.0001  max mem: 20905
Train Epoch: [5]  [1900/4855]  eta: 2:00:35  lr: 0.000010  ml_loss: 4.9156  mi_loss: 4.6476  train_loss: 9.5632  time: 2.5019  data: 0.0001  max mem: 20905
Train Epoch: [5]  [1950/4855]  eta: 1:58:32  lr: 0.000010  ml_loss: 4.6794  mi_loss: 4.2141  train_loss: 8.8936  time: 2.4503  data: 0.0001  max mem: 20905
Train Epoch: [5]  [2000/4855]  eta: 1:56:33  lr: 0.000010  ml_loss: 4.9553  mi_loss: 4.6976  train_loss: 9.6528  time: 2.4984  data: 0.0001  max mem: 20905
Train Epoch: [5]  [2050/4855]  eta: 1:54:33  lr: 0.000010  ml_loss: 5.2985  mi_loss: 4.2273  train_loss: 9.5258  time: 2.4665  data: 0.0001  max mem: 20905
Train Epoch: [5]  [2100/4855]  eta: 1:52:33  lr: 0.000010  ml_loss: 5.8698  mi_loss: 3.9790  train_loss: 9.8487  time: 2.4897  data: 0.0001  max mem: 20905
Train Epoch: [5]  [2150/4855]  eta: 1:50:33  lr: 0.000010  ml_loss: 5.5498  mi_loss: 4.4935  train_loss: 10.0433  time: 2.4777  data: 0.0001  max mem: 20905
Train Epoch: [5]  [2200/4855]  eta: 1:48:32  lr: 0.000010  ml_loss: 5.1149  mi_loss: 4.5198  train_loss: 9.6347  time: 2.4603  data: 0.0001  max mem: 20905
Train Epoch: [5]  [2250/4855]  eta: 1:46:30  lr: 0.000010  ml_loss: 5.4493  mi_loss: 3.8366  train_loss: 9.2859  time: 2.4506  data: 0.0001  max mem: 20905
Train Epoch: [5]  [2300/4855]  eta: 1:44:29  lr: 0.000010  ml_loss: 4.7797  mi_loss: 3.0110  train_loss: 7.7907  time: 2.4789  data: 0.0001  max mem: 20905
Train Epoch: [5]  [2350/4855]  eta: 1:42:28  lr: 0.000010  ml_loss: 4.7102  mi_loss: 4.5326  train_loss: 9.2427  time: 2.4980  data: 0.0001  max mem: 20905
Train Epoch: [5]  [2400/4855]  eta: 1:40:26  lr: 0.000010  ml_loss: 4.9089  mi_loss: 4.9316  train_loss: 9.8406  time: 2.4409  data: 0.0001  max mem: 20905
Train Epoch: [5]  [2450/4855]  eta: 1:38:23  lr: 0.000010  ml_loss: 4.5580  mi_loss: 4.8011  train_loss: 9.3590  time: 2.4451  data: 0.0002  max mem: 20905
Train Epoch: [5]  [2500/4855]  eta: 1:36:22  lr: 0.000010  ml_loss: 5.1620  mi_loss: 3.7897  train_loss: 8.9518  time: 2.4927  data: 0.0001  max mem: 20905
Train Epoch: [5]  [2550/4855]  eta: 1:34:21  lr: 0.000010  ml_loss: 5.2770  mi_loss: 4.0686  train_loss: 9.3457  time: 2.4930  data: 0.0001  max mem: 20905
Train Epoch: [5]  [2600/4855]  eta: 1:32:20  lr: 0.000010  ml_loss: 5.6271  mi_loss: 4.2800  train_loss: 9.9071  time: 2.5001  data: 0.0001  max mem: 20905
Train Epoch: [5]  [2650/4855]  eta: 1:30:18  lr: 0.000010  ml_loss: 4.8119  mi_loss: 4.4899  train_loss: 9.3017  time: 2.4807  data: 0.0001  max mem: 20905
Train Epoch: [5]  [2700/4855]  eta: 1:28:16  lr: 0.000010  ml_loss: 4.7568  mi_loss: 4.5873  train_loss: 9.3441  time: 2.4919  data: 0.0001  max mem: 20905
Train Epoch: [5]  [2750/4855]  eta: 1:26:15  lr: 0.000010  ml_loss: 4.4692  mi_loss: 4.4283  train_loss: 8.8975  time: 2.4936  data: 0.0001  max mem: 20905
Train Epoch: [5]  [2800/4855]  eta: 1:24:12  lr: 0.000010  ml_loss: 5.2208  mi_loss: 4.4821  train_loss: 9.7029  time: 2.4328  data: 0.0001  max mem: 20905
Train Epoch: [5]  [2850/4855]  eta: 1:22:10  lr: 0.000010  ml_loss: 5.0215  mi_loss: 4.8640  train_loss: 9.8855  time: 2.4967  data: 0.0001  max mem: 20905
Train Epoch: [5]  [2900/4855]  eta: 1:20:08  lr: 0.000010  ml_loss: 5.1841  mi_loss: 4.4272  train_loss: 9.6113  time: 2.4874  data: 0.0001  max mem: 20905
Train Epoch: [5]  [2950/4855]  eta: 1:18:05  lr: 0.000010  ml_loss: 5.4547  mi_loss: 4.8400  train_loss: 10.2947  time: 2.4526  data: 0.0001  max mem: 20905
Train Epoch: [5]  [3000/4855]  eta: 1:16:03  lr: 0.000010  ml_loss: 4.8704  mi_loss: 4.3875  train_loss: 9.2579  time: 2.4761  data: 0.0001  max mem: 20905
Train Epoch: [5]  [3050/4855]  eta: 1:14:00  lr: 0.000010  ml_loss: 5.2241  mi_loss: 4.6926  train_loss: 9.9167  time: 2.4437  data: 0.0001  max mem: 20905
Train Epoch: [5]  [3100/4855]  eta: 1:11:57  lr: 0.000010  ml_loss: 5.4292  mi_loss: 4.6183  train_loss: 10.0475  time: 2.4619  data: 0.0001  max mem: 20905
Train Epoch: [5]  [3150/4855]  eta: 1:09:54  lr: 0.000010  ml_loss: 5.2441  mi_loss: 4.5141  train_loss: 9.7582  time: 2.4662  data: 0.0001  max mem: 20905
Train Epoch: [5]  [3200/4855]  eta: 1:07:51  lr: 0.000010  ml_loss: 4.9218  mi_loss: 3.1785  train_loss: 8.1003  time: 2.4404  data: 0.0001  max mem: 20905
Train Epoch: [5]  [3250/4855]  eta: 1:05:48  lr: 0.000010  ml_loss: 5.4067  mi_loss: 4.4001  train_loss: 9.8068  time: 2.4869  data: 0.0001  max mem: 20905
Train Epoch: [5]  [3300/4855]  eta: 1:03:45  lr: 0.000010  ml_loss: 4.9840  mi_loss: 4.3496  train_loss: 9.3335  time: 2.4396  data: 0.0001  max mem: 20905
Train Epoch: [5]  [3350/4855]  eta: 1:01:42  lr: 0.000010  ml_loss: 4.8735  mi_loss: 4.5230  train_loss: 9.3965  time: 2.4449  data: 0.0001  max mem: 20905
Train Epoch: [5]  [3400/4855]  eta: 0:59:39  lr: 0.000010  ml_loss: 4.9915  mi_loss: 4.2174  train_loss: 9.2089  time: 2.4511  data: 0.0001  max mem: 20905
Train Epoch: [5]  [3450/4855]  eta: 0:57:36  lr: 0.000010  ml_loss: 5.3525  mi_loss: 4.4948  train_loss: 9.8472  time: 2.4881  data: 0.0001  max mem: 20905
Train Epoch: [5]  [3500/4855]  eta: 0:55:34  lr: 0.000010  ml_loss: 5.0489  mi_loss: 4.3709  train_loss: 9.4198  time: 2.4751  data: 0.0001  max mem: 20905
Train Epoch: [5]  [3550/4855]  eta: 0:53:31  lr: 0.000010  ml_loss: 5.3187  mi_loss: 4.4787  train_loss: 9.7974  time: 2.4919  data: 0.0001  max mem: 20905
Train Epoch: [5]  [3600/4855]  eta: 0:51:28  lr: 0.000010  ml_loss: 5.4253  mi_loss: 4.7476  train_loss: 10.1729  time: 2.4600  data: 0.0001  max mem: 20905
Train Epoch: [5]  [3650/4855]  eta: 0:49:26  lr: 0.000010  ml_loss: 4.7282  mi_loss: 4.3756  train_loss: 9.1038  time: 2.5065  data: 0.0001  max mem: 20905
Train Epoch: [5]  [3700/4855]  eta: 0:47:23  lr: 0.000010  ml_loss: 5.5567  mi_loss: 4.2181  train_loss: 9.7748  time: 2.4535  data: 0.0001  max mem: 20905
Train Epoch: [5]  [3750/4855]  eta: 0:45:20  lr: 0.000010  ml_loss: 5.2558  mi_loss: 3.9543  train_loss: 9.2102  time: 2.4604  data: 0.0001  max mem: 20905
Train Epoch: [5]  [3800/4855]  eta: 0:43:17  lr: 0.000010  ml_loss: 5.2164  mi_loss: 4.0164  train_loss: 9.2328  time: 2.4765  data: 0.0001  max mem: 20905
Train Epoch: [5]  [3850/4855]  eta: 0:41:14  lr: 0.000010  ml_loss: 5.8124  mi_loss: 4.4511  train_loss: 10.2635  time: 2.4558  data: 0.0001  max mem: 20905
Train Epoch: [5]  [3900/4855]  eta: 0:39:11  lr: 0.000010  ml_loss: 5.2826  mi_loss: 4.5893  train_loss: 9.8719  time: 2.4620  data: 0.0001  max mem: 20905
Train Epoch: [5]  [3950/4855]  eta: 0:37:08  lr: 0.000010  ml_loss: 5.3300  mi_loss: 4.5252  train_loss: 9.8552  time: 2.4800  data: 0.0001  max mem: 20905
Train Epoch: [5]  [4000/4855]  eta: 0:35:05  lr: 0.000010  ml_loss: 5.0368  mi_loss: 4.3652  train_loss: 9.4020  time: 2.4618  data: 0.0001  max mem: 20905
Train Epoch: [5]  [4050/4855]  eta: 0:33:02  lr: 0.000010  ml_loss: 5.4919  mi_loss: 3.9601  train_loss: 9.4520  time: 2.4895  data: 0.0001  max mem: 20905
Train Epoch: [5]  [4100/4855]  eta: 0:30:59  lr: 0.000010  ml_loss: 5.3345  mi_loss: 4.4111  train_loss: 9.7456  time: 2.4811  data: 0.0001  max mem: 20905
Train Epoch: [5]  [4150/4855]  eta: 0:28:56  lr: 0.000010  ml_loss: 5.3028  mi_loss: 3.9893  train_loss: 9.2922  time: 2.4759  data: 0.0001  max mem: 20905
Train Epoch: [5]  [4200/4855]  eta: 0:26:53  lr: 0.000010  ml_loss: 5.0432  mi_loss: 4.5703  train_loss: 9.6135  time: 2.5087  data: 0.0001  max mem: 20905
Train Epoch: [5]  [4250/4855]  eta: 0:24:50  lr: 0.000010  ml_loss: 5.1067  mi_loss: 4.8272  train_loss: 9.9340  time: 2.4943  data: 0.0001  max mem: 20905
Train Epoch: [5]  [4300/4855]  eta: 0:22:47  lr: 0.000010  ml_loss: 5.1537  mi_loss: 4.0507  train_loss: 9.2044  time: 2.4470  data: 0.0001  max mem: 20905
Train Epoch: [5]  [4350/4855]  eta: 0:20:44  lr: 0.000010  ml_loss: 4.3114  mi_loss: 4.2417  train_loss: 8.5532  time: 2.4989  data: 0.0001  max mem: 20905
Train Epoch: [5]  [4400/4855]  eta: 0:18:41  lr: 0.000010  ml_loss: 5.4701  mi_loss: 4.1648  train_loss: 9.6349  time: 2.5053  data: 0.0001  max mem: 20905
Train Epoch: [5]  [4450/4855]  eta: 0:16:38  lr: 0.000010  ml_loss: 5.4170  mi_loss: 4.4299  train_loss: 9.8469  time: 2.4970  data: 0.0001  max mem: 20905
Train Epoch: [5]  [4500/4855]  eta: 0:14:35  lr: 0.000010  ml_loss: 5.5374  mi_loss: 4.0273  train_loss: 9.5647  time: 2.4597  data: 0.0001  max mem: 20905
Train Epoch: [5]  [4550/4855]  eta: 0:12:31  lr: 0.000010  ml_loss: 4.7630  mi_loss: 4.2532  train_loss: 9.0162  time: 2.4584  data: 0.0001  max mem: 20905
Train Epoch: [5]  [4600/4855]  eta: 0:10:28  lr: 0.000010  ml_loss: 5.3766  mi_loss: 4.3636  train_loss: 9.7402  time: 2.4520  data: 0.0001  max mem: 20905
Train Epoch: [5]  [4650/4855]  eta: 0:08:25  lr: 0.000010  ml_loss: 5.4675  mi_loss: 4.3393  train_loss: 9.8068  time: 2.4920  data: 0.0001  max mem: 20905
Train Epoch: [5]  [4700/4855]  eta: 0:06:22  lr: 0.000010  ml_loss: 5.3529  mi_loss: 4.3680  train_loss: 9.7210  time: 2.4692  data: 0.0001  max mem: 20905
Train Epoch: [5]  [4750/4855]  eta: 0:04:18  lr: 0.000010  ml_loss: 5.1610  mi_loss: 4.6321  train_loss: 9.7931  time: 2.4875  data: 0.0001  max mem: 20905
Train Epoch: [5]  [4800/4855]  eta: 0:02:15  lr: 0.000010  ml_loss: 5.2622  mi_loss: 4.2519  train_loss: 9.5141  time: 2.4870  data: 0.0001  max mem: 20905
Train Epoch: [5]  [4850/4855]  eta: 0:00:12  lr: 0.000010  ml_loss: 5.5017  mi_loss: 3.9061  train_loss: 9.4078  time: 2.4939  data: 0.0348  max mem: 20905
Train Epoch: [5]  [4854/4855]  eta: 0:00:02  lr: 0.000010  ml_loss: 5.1828  mi_loss: 4.0863  train_loss: 9.2692  time: 2.4942  data: 0.0355  max mem: 20905
Train Epoch: [5] Total time: 3:19:34 (2.4665 s / it)
Val Epoch: [5]  [  0/540]  eta: 0:23:02  ml_loss: 5.5226  mi_loss: 4.3494  val_loss: 9.8719  accML: 0.1989  accMI: 0.1108  time: 2.5605  data: 2.1896  max mem: 20905
Val Epoch: [5]  [ 50/540]  eta: 0:06:34  ml_loss: 5.0677  mi_loss: 3.9972  val_loss: 9.0649  accML: 0.2403  accMI: 0.1930  time: 0.7776  data: 0.6160  max mem: 20905
Val Epoch: [5]  [100/540]  eta: 0:05:53  ml_loss: 5.2794  mi_loss: 4.4574  val_loss: 9.7368  accML: 0.1995  accMI: 0.1333  time: 0.7803  data: 0.6186  max mem: 20905
Val Epoch: [5]  [150/540]  eta: 0:05:24  ml_loss: 5.4221  mi_loss: 4.6756  val_loss: 10.0977  accML: 0.2086  accMI: 0.1078  time: 0.9382  data: 0.7745  max mem: 20905
Val Epoch: [5]  [200/540]  eta: 0:04:46  ml_loss: 5.3057  mi_loss: 4.6302  val_loss: 9.9358  accML: 0.2016  accMI: 0.0989  time: 0.8925  data: 0.7300  max mem: 20905
Val Epoch: [5]  [250/540]  eta: 0:04:14  ml_loss: 5.0404  mi_loss: 4.0459  val_loss: 9.0863  accML: 0.2340  accMI: 0.1522  time: 1.0653  data: 0.9029  max mem: 20905
Val Epoch: [5]  [300/540]  eta: 0:03:31  ml_loss: 4.8398  mi_loss: 4.0637  val_loss: 8.9035  accML: 0.2353  accMI: 0.1747  time: 0.8636  data: 0.7007  max mem: 20905
Val Epoch: [5]  [350/540]  eta: 0:02:46  ml_loss: 4.9789  mi_loss: 3.3282  val_loss: 8.3071  accML: 0.2167  accMI: 0.2907  time: 0.7892  data: 0.6274  max mem: 20905
Val Epoch: [5]  [400/540]  eta: 0:02:02  ml_loss: 5.7078  mi_loss: 4.4710  val_loss: 10.1788  accML: 0.1750  accMI: 0.1022  time: 0.8646  data: 0.7020  max mem: 20905
Val Epoch: [5]  [450/540]  eta: 0:01:18  ml_loss: 5.4074  mi_loss: 4.1723  val_loss: 9.5798  accML: 0.2031  accMI: 0.1280  time: 0.8522  data: 0.6895  max mem: 20905
Val Epoch: [5]  [500/540]  eta: 0:00:34  ml_loss: 5.0919  mi_loss: 4.1315  val_loss: 9.2234  accML: 0.2424  accMI: 0.1324  time: 0.7821  data: 0.6200  max mem: 20905
Val Epoch: [5]  [539/540]  eta: 0:00:00  ml_loss: 5.5168  mi_loss: 4.0523  val_loss: 9.5691  accML: 0.1633  accMI: 0.1802  time: 0.7562  data: 0.5964  max mem: 20905
Val Epoch: [5] Total time: 0:07:47 (0.8662 s / it)
epoch:5, iter:29129, 4854,  train_loss: 9.2691650390625, valid_loss: 9.42188201657048, idiv_loss:(5.156613207746435, 4.265268802642822), acc:(0.21956946681495065, 0.1426095241818715)
Averaged stats: lr: 0.0000  ml_loss: 5.2496  mi_loss: 4.3523  train_loss: 9.6018
epoch 5 9.2691650390625
Train Epoch: [6]  [   0/4855]  eta: 7:42:34  lr: 0.000010  ml_loss: 5.7301  mi_loss: 4.5369  train_loss: 10.2670  time: 5.7167  data: 3.2392  max mem: 20905
Train Epoch: [6]  [  50/4855]  eta: 3:23:08  lr: 0.000010  ml_loss: 5.2824  mi_loss: 4.3805  train_loss: 9.6629  time: 2.4829  data: 0.0001  max mem: 20905
Train Epoch: [6]  [ 100/4855]  eta: 3:18:59  lr: 0.000010  ml_loss: 5.0792  mi_loss: 3.3945  train_loss: 8.4737  time: 2.4815  data: 0.0001  max mem: 20905
Train Epoch: [6]  [ 150/4855]  eta: 3:15:42  lr: 0.000010  ml_loss: 5.2283  mi_loss: 4.4478  train_loss: 9.6760  time: 2.4629  data: 0.0001  max mem: 20905
Train Epoch: [6]  [ 200/4855]  eta: 3:13:05  lr: 0.000010  ml_loss: 5.2456  mi_loss: 4.4321  train_loss: 9.6778  time: 2.4660  data: 0.0001  max mem: 20905
Train Epoch: [6]  [ 250/4855]  eta: 3:10:43  lr: 0.000010  ml_loss: 4.8024  mi_loss: 4.0571  train_loss: 8.8594  time: 2.4664  data: 0.0001  max mem: 20905
Train Epoch: [6]  [ 300/4855]  eta: 3:08:37  lr: 0.000010  ml_loss: 5.4037  mi_loss: 4.1456  train_loss: 9.5493  time: 2.4782  data: 0.0001  max mem: 20905
Train Epoch: [6]  [ 350/4855]  eta: 3:06:29  lr: 0.000010  ml_loss: 5.6271  mi_loss: 4.4289  train_loss: 10.0560  time: 2.4588  data: 0.0001  max mem: 20905
Train Epoch: [6]  [ 400/4855]  eta: 3:04:25  lr: 0.000010  ml_loss: 4.8667  mi_loss: 4.0062  train_loss: 8.8728  time: 2.4785  data: 0.0001  max mem: 20905
Train Epoch: [6]  [ 450/4855]  eta: 3:02:19  lr: 0.000010  ml_loss: 5.4975  mi_loss: 4.3248  train_loss: 9.8223  time: 2.4874  data: 0.0001  max mem: 20905
Train Epoch: [6]  [ 500/4855]  eta: 3:00:08  lr: 0.000010  ml_loss: 4.9221  mi_loss: 4.0201  train_loss: 8.9421  time: 2.4756  data: 0.0001  max mem: 20906
Train Epoch: [6]  [ 550/4855]  eta: 2:57:58  lr: 0.000010  ml_loss: 4.8591  mi_loss: 4.7946  train_loss: 9.6537  time: 2.4490  data: 0.0001  max mem: 20906
Train Epoch: [6]  [ 600/4855]  eta: 2:55:45  lr: 0.000010  ml_loss: 5.6630  mi_loss: 3.6744  train_loss: 9.3374  time: 2.4464  data: 0.0001  max mem: 20906
Train Epoch: [6]  [ 650/4855]  eta: 2:53:39  lr: 0.000010  ml_loss: 4.5866  mi_loss: 3.7325  train_loss: 8.3191  time: 2.4686  data: 0.0001  max mem: 20906
Train Epoch: [6]  [ 700/4855]  eta: 2:51:30  lr: 0.000010  ml_loss: 5.1385  mi_loss: 4.3320  train_loss: 9.4706  time: 2.4660  data: 0.0001  max mem: 20906
Train Epoch: [6]  [ 750/4855]  eta: 2:49:26  lr: 0.000010  ml_loss: 5.3721  mi_loss: 4.3170  train_loss: 9.6892  time: 2.4855  data: 0.0001  max mem: 20906
Train Epoch: [6]  [ 800/4855]  eta: 2:47:20  lr: 0.000010  ml_loss: 5.1782  mi_loss: 4.1344  train_loss: 9.3127  time: 2.4600  data: 0.0001  max mem: 20906
Train Epoch: [6]  [ 850/4855]  eta: 2:45:16  lr: 0.000010  ml_loss: 5.3482  mi_loss: 4.3703  train_loss: 9.7185  time: 2.4835  data: 0.0001  max mem: 20906
Train Epoch: [6]  [ 900/4855]  eta: 2:43:15  lr: 0.000010  ml_loss: 5.7414  mi_loss: 3.5279  train_loss: 9.2693  time: 2.4899  data: 0.0001  max mem: 20906
Train Epoch: [6]  [ 950/4855]  eta: 2:41:14  lr: 0.000010  ml_loss: 4.9724  mi_loss: 4.6199  train_loss: 9.5923  time: 2.4932  data: 0.0001  max mem: 20906
Train Epoch: [6]  [1000/4855]  eta: 2:39:12  lr: 0.000010  ml_loss: 4.6787  mi_loss: 4.3943  train_loss: 9.0730  time: 2.4826  data: 0.0001  max mem: 20906
Train Epoch: [6]  [1050/4855]  eta: 2:37:10  lr: 0.000010  ml_loss: 5.3143  mi_loss: 4.3731  train_loss: 9.6874  time: 2.4891  data: 0.0001  max mem: 20906
Train Epoch: [6]  [1100/4855]  eta: 2:35:06  lr: 0.000010  ml_loss: 5.4482  mi_loss: 4.2322  train_loss: 9.6804  time: 2.4620  data: 0.0001  max mem: 20906
Train Epoch: [6]  [1150/4855]  eta: 2:33:01  lr: 0.000010  ml_loss: 5.5504  mi_loss: 4.1990  train_loss: 9.7494  time: 2.4727  data: 0.0001  max mem: 20906
Train Epoch: [6]  [1200/4855]  eta: 2:30:55  lr: 0.000010  ml_loss: 5.3323  mi_loss: 4.2050  train_loss: 9.5372  time: 2.4644  data: 0.0001  max mem: 20906
Train Epoch: [6]  [1250/4855]  eta: 2:28:50  lr: 0.000010  ml_loss: 4.9987  mi_loss: 4.7718  train_loss: 9.7706  time: 2.4765  data: 0.0001  max mem: 20906
Train Epoch: [6]  [1300/4855]  eta: 2:26:44  lr: 0.000010  ml_loss: 5.2550  mi_loss: 4.4727  train_loss: 9.7278  time: 2.4568  data: 0.0002  max mem: 20906
Train Epoch: [6]  [1350/4855]  eta: 2:24:40  lr: 0.000010  ml_loss: 5.3217  mi_loss: 4.2565  train_loss: 9.5781  time: 2.4819  data: 0.0001  max mem: 20906
Train Epoch: [6]  [1400/4855]  eta: 2:22:37  lr: 0.000010  ml_loss: 5.7345  mi_loss: 3.8320  train_loss: 9.5664  time: 2.4772  data: 0.0002  max mem: 20906
Train Epoch: [6]  [1450/4855]  eta: 2:20:31  lr: 0.000010  ml_loss: 4.7689  mi_loss: 4.4193  train_loss: 9.1882  time: 2.4778  data: 0.0002  max mem: 20906
Train Epoch: [6]  [1500/4855]  eta: 2:18:25  lr: 0.000010  ml_loss: 5.7179  mi_loss: 4.2243  train_loss: 9.9422  time: 2.4534  data: 0.0002  max mem: 20906
Train Epoch: [6]  [1550/4855]  eta: 2:16:20  lr: 0.000010  ml_loss: 5.0683  mi_loss: 4.2974  train_loss: 9.3657  time: 2.4769  data: 0.0002  max mem: 20906
Train Epoch: [6]  [1600/4855]  eta: 2:14:16  lr: 0.000010  ml_loss: 4.4233  mi_loss: 4.6114  train_loss: 9.0347  time: 2.4509  data: 0.0001  max mem: 20906
Train Epoch: [6]  [1650/4855]  eta: 2:12:10  lr: 0.000010  ml_loss: 5.4789  mi_loss: 4.4439  train_loss: 9.9228  time: 2.4521  data: 0.0001  max mem: 20906
Train Epoch: [6]  [1700/4855]  eta: 2:10:07  lr: 0.000010  ml_loss: 4.9964  mi_loss: 4.2595  train_loss: 9.2559  time: 2.4800  data: 0.0001  max mem: 20906
Train Epoch: [6]  [1750/4855]  eta: 2:08:03  lr: 0.000010  ml_loss: 5.0517  mi_loss: 4.2784  train_loss: 9.3301  time: 2.4817  data: 0.0001  max mem: 20906
Train Epoch: [6]  [1800/4855]  eta: 2:06:00  lr: 0.000010  ml_loss: 5.1729  mi_loss: 4.2394  train_loss: 9.4123  time: 2.4832  data: 0.0001  max mem: 20906
Train Epoch: [6]  [1850/4855]  eta: 2:03:57  lr: 0.000010  ml_loss: 5.5707  mi_loss: 4.0105  train_loss: 9.5812  time: 2.4718  data: 0.0001  max mem: 20906
Train Epoch: [6]  [1900/4855]  eta: 2:01:54  lr: 0.000010  ml_loss: 4.8862  mi_loss: 4.7463  train_loss: 9.6325  time: 2.4865  data: 0.0001  max mem: 20906
Train Epoch: [6]  [1950/4855]  eta: 1:59:51  lr: 0.000010  ml_loss: 4.8166  mi_loss: 3.9781  train_loss: 8.7947  time: 2.4815  data: 0.0001  max mem: 20906
Train Epoch: [6]  [2000/4855]  eta: 1:57:47  lr: 0.000010  ml_loss: 5.1988  mi_loss: 4.3568  train_loss: 9.5557  time: 2.4635  data: 0.0001  max mem: 20906
Train Epoch: [6]  [2050/4855]  eta: 1:55:43  lr: 0.000010  ml_loss: 4.8349  mi_loss: 4.5240  train_loss: 9.3589  time: 2.4725  data: 0.0002  max mem: 20906
Train Epoch: [6]  [2100/4855]  eta: 1:53:39  lr: 0.000010  ml_loss: 5.4606  mi_loss: 4.7817  train_loss: 10.2424  time: 2.4683  data: 0.0001  max mem: 20906
Train Epoch: [6]  [2150/4855]  eta: 1:51:35  lr: 0.000010  ml_loss: 4.8336  mi_loss: 3.9462  train_loss: 8.7798  time: 2.4561  data: 0.0001  max mem: 20906
Train Epoch: [6]  [2200/4855]  eta: 1:49:31  lr: 0.000010  ml_loss: 5.4822  mi_loss: 4.5092  train_loss: 9.9914  time: 2.4800  data: 0.0001  max mem: 20906
Train Epoch: [6]  [2250/4855]  eta: 1:47:27  lr: 0.000010  ml_loss: 5.4571  mi_loss: 4.0184  train_loss: 9.4755  time: 2.4688  data: 0.0001  max mem: 20906
Train Epoch: [6]  [2300/4855]  eta: 1:45:24  lr: 0.000010  ml_loss: 5.1368  mi_loss: 4.3366  train_loss: 9.4734  time: 2.4690  data: 0.0001  max mem: 20906
Train Epoch: [6]  [2350/4855]  eta: 1:43:21  lr: 0.000010  ml_loss: 5.0094  mi_loss: 4.2105  train_loss: 9.2199  time: 2.4913  data: 0.0001  max mem: 20906
Train Epoch: [6]  [2400/4855]  eta: 1:41:19  lr: 0.000010  ml_loss: 5.1245  mi_loss: 4.2631  train_loss: 9.3876  time: 2.4979  data: 0.0001  max mem: 20906
Train Epoch: [6]  [2450/4855]  eta: 1:39:16  lr: 0.000010  ml_loss: 5.0452  mi_loss: 4.1575  train_loss: 9.2027  time: 2.5031  data: 0.0001  max mem: 20906
Train Epoch: [6]  [2500/4855]  eta: 1:37:13  lr: 0.000010  ml_loss: 5.1633  mi_loss: 3.4665  train_loss: 8.6298  time: 2.4866  data: 0.0001  max mem: 20906
Train Epoch: [6]  [2550/4855]  eta: 1:35:11  lr: 0.000010  ml_loss: 5.4818  mi_loss: 4.0973  train_loss: 9.5791  time: 2.5017  data: 0.0001  max mem: 20906
Train Epoch: [6]  [2600/4855]  eta: 1:33:06  lr: 0.000010  ml_loss: 5.4087  mi_loss: 3.9931  train_loss: 9.4018  time: 2.4669  data: 0.0001  max mem: 20906
Train Epoch: [6]  [2650/4855]  eta: 1:31:03  lr: 0.000010  ml_loss: 5.1426  mi_loss: 4.3225  train_loss: 9.4651  time: 2.4741  data: 0.0001  max mem: 20906
Train Epoch: [6]  [2700/4855]  eta: 1:29:00  lr: 0.000010  ml_loss: 4.8350  mi_loss: 4.0834  train_loss: 8.9184  time: 2.4986  data: 0.0001  max mem: 20906
Train Epoch: [6]  [2750/4855]  eta: 1:26:55  lr: 0.000010  ml_loss: 5.0564  mi_loss: 4.2048  train_loss: 9.2612  time: 2.4726  data: 0.0001  max mem: 20906
Train Epoch: [6]  [2800/4855]  eta: 1:24:52  lr: 0.000010  ml_loss: 5.1399  mi_loss: 4.3641  train_loss: 9.5040  time: 2.5031  data: 0.0001  max mem: 20906
Train Epoch: [6]  [2850/4855]  eta: 1:22:48  lr: 0.000010  ml_loss: 5.3634  mi_loss: 3.3068  train_loss: 8.6701  time: 2.4598  data: 0.0001  max mem: 20906
Train Epoch: [6]  [2900/4855]  eta: 1:20:45  lr: 0.000010  ml_loss: 5.5513  mi_loss: 4.2625  train_loss: 9.8138  time: 2.5078  data: 0.0001  max mem: 20906
Train Epoch: [6]  [2950/4855]  eta: 1:18:42  lr: 0.000010  ml_loss: 5.1323  mi_loss: 4.0991  train_loss: 9.2314  time: 2.4912  data: 0.0001  max mem: 20906
Train Epoch: [6]  [3000/4855]  eta: 1:16:37  lr: 0.000010  ml_loss: 5.4392  mi_loss: 3.3382  train_loss: 8.7774  time: 2.4647  data: 0.0001  max mem: 20906
Train Epoch: [6]  [3050/4855]  eta: 1:14:33  lr: 0.000010  ml_loss: 5.6213  mi_loss: 4.0044  train_loss: 9.6257  time: 2.4861  data: 0.0001  max mem: 20906
Train Epoch: [6]  [3100/4855]  eta: 1:12:28  lr: 0.000010  ml_loss: 4.8451  mi_loss: 4.0254  train_loss: 8.8705  time: 2.4205  data: 0.0001  max mem: 20906
Train Epoch: [6]  [3150/4855]  eta: 1:10:23  lr: 0.000010  ml_loss: 4.9970  mi_loss: 4.4962  train_loss: 9.4932  time: 2.4569  data: 0.0001  max mem: 20906
Train Epoch: [6]  [3200/4855]  eta: 1:08:19  lr: 0.000010  ml_loss: 4.6757  mi_loss: 4.1331  train_loss: 8.8088  time: 2.4588  data: 0.0002  max mem: 20906
Train Epoch: [6]  [3250/4855]  eta: 1:06:14  lr: 0.000010  ml_loss: 4.5371  mi_loss: 4.3171  train_loss: 8.8542  time: 2.4414  data: 0.0002  max mem: 20906
Train Epoch: [6]  [3300/4855]  eta: 1:04:10  lr: 0.000010  ml_loss: 5.2723  mi_loss: 4.5093  train_loss: 9.7816  time: 2.4493  data: 0.0001  max mem: 20906
Train Epoch: [6]  [3350/4855]  eta: 1:02:06  lr: 0.000010  ml_loss: 5.5408  mi_loss: 4.3169  train_loss: 9.8577  time: 2.4682  data: 0.0001  max mem: 20906
Train Epoch: [6]  [3400/4855]  eta: 1:00:01  lr: 0.000010  ml_loss: 4.7199  mi_loss: 4.1805  train_loss: 8.9003  time: 2.4566  data: 0.0002  max mem: 20906
Train Epoch: [6]  [3450/4855]  eta: 0:57:58  lr: 0.000010  ml_loss: 4.8487  mi_loss: 4.8163  train_loss: 9.6650  time: 2.4717  data: 0.0002  max mem: 20906
Train Epoch: [6]  [3500/4855]  eta: 0:55:53  lr: 0.000010  ml_loss: 5.7497  mi_loss: 4.3548  train_loss: 10.1045  time: 2.4445  data: 0.0002  max mem: 20906
Train Epoch: [6]  [3550/4855]  eta: 0:53:49  lr: 0.000010  ml_loss: 5.6051  mi_loss: 3.5220  train_loss: 9.1271  time: 2.4379  data: 0.0001  max mem: 20906
Train Epoch: [6]  [3600/4855]  eta: 0:51:45  lr: 0.000010  ml_loss: 5.5585  mi_loss: 4.5439  train_loss: 10.1024  time: 2.4599  data: 0.0002  max mem: 20906
Train Epoch: [6]  [3650/4855]  eta: 0:49:41  lr: 0.000010  ml_loss: 4.5771  mi_loss: 3.0721  train_loss: 7.6492  time: 2.4614  data: 0.0001  max mem: 20906
Train Epoch: [6]  [3700/4855]  eta: 0:47:37  lr: 0.000010  ml_loss: 5.4240  mi_loss: 3.9146  train_loss: 9.3385  time: 2.4615  data: 0.0001  max mem: 20906
Train Epoch: [6]  [3750/4855]  eta: 0:45:33  lr: 0.000010  ml_loss: 5.3374  mi_loss: 4.5447  train_loss: 9.8821  time: 2.4695  data: 0.0002  max mem: 20906
Train Epoch: [6]  [3800/4855]  eta: 0:43:29  lr: 0.000010  ml_loss: 5.1974  mi_loss: 4.2467  train_loss: 9.4442  time: 2.4640  data: 0.0002  max mem: 20906
Train Epoch: [6]  [3850/4855]  eta: 0:41:25  lr: 0.000010  ml_loss: 4.9861  mi_loss: 3.9174  train_loss: 8.9035  time: 2.4746  data: 0.0001  max mem: 20906
Train Epoch: [6]  [3900/4855]  eta: 0:39:21  lr: 0.000010  ml_loss: 4.8533  mi_loss: 4.3917  train_loss: 9.2450  time: 2.4332  data: 0.0002  max mem: 20906
Train Epoch: [6]  [3950/4855]  eta: 0:37:17  lr: 0.000010  ml_loss: 4.8743  mi_loss: 5.0322  train_loss: 9.9065  time: 2.4271  data: 0.0001  max mem: 20906
Train Epoch: [6]  [4000/4855]  eta: 0:35:13  lr: 0.000010  ml_loss: 5.1703  mi_loss: 4.0869  train_loss: 9.2572  time: 2.4043  data: 0.0001  max mem: 20906
Train Epoch: [6]  [4050/4855]  eta: 0:33:09  lr: 0.000010  ml_loss: 5.4567  mi_loss: 4.4852  train_loss: 9.9418  time: 2.4361  data: 0.0002  max mem: 20906
Train Epoch: [6]  [4100/4855]  eta: 0:31:05  lr: 0.000010  ml_loss: 4.7799  mi_loss: 4.4315  train_loss: 9.2115  time: 2.4166  data: 0.0001  max mem: 20906
Train Epoch: [6]  [4150/4855]  eta: 0:29:01  lr: 0.000010  ml_loss: 4.9095  mi_loss: 3.7601  train_loss: 8.6696  time: 2.4433  data: 0.0002  max mem: 20906
Train Epoch: [6]  [4200/4855]  eta: 0:26:57  lr: 0.000010  ml_loss: 5.2925  mi_loss: 4.1545  train_loss: 9.4470  time: 2.4347  data: 0.0002  max mem: 20906
Train Epoch: [6]  [4250/4855]  eta: 0:24:53  lr: 0.000010  ml_loss: 5.5884  mi_loss: 3.7540  train_loss: 9.3424  time: 2.4399  data: 0.0001  max mem: 20908
Train Epoch: [6]  [4300/4855]  eta: 0:22:50  lr: 0.000010  ml_loss: 5.3496  mi_loss: 4.4069  train_loss: 9.7565  time: 2.4231  data: 0.0001  max mem: 20908
Train Epoch: [6]  [4350/4855]  eta: 0:20:46  lr: 0.000010  ml_loss: 5.6873  mi_loss: 4.2966  train_loss: 9.9839  time: 2.4344  data: 0.0002  max mem: 20908
Train Epoch: [6]  [4400/4855]  eta: 0:18:42  lr: 0.000010  ml_loss: 5.3766  mi_loss: 3.9048  train_loss: 9.2814  time: 2.4341  data: 0.0001  max mem: 20908
Train Epoch: [6]  [4450/4855]  eta: 0:16:39  lr: 0.000010  ml_loss: 5.4425  mi_loss: 4.0920  train_loss: 9.5345  time: 2.4402  data: 0.0002  max mem: 20908
Train Epoch: [6]  [4500/4855]  eta: 0:14:35  lr: 0.000010  ml_loss: 5.2815  mi_loss: 4.4434  train_loss: 9.7249  time: 2.4191  data: 0.0002  max mem: 20908
Train Epoch: [6]  [4550/4855]  eta: 0:12:32  lr: 0.000010  ml_loss: 5.1621  mi_loss: 3.9064  train_loss: 9.0685  time: 2.4479  data: 0.0001  max mem: 20908
Train Epoch: [6]  [4600/4855]  eta: 0:10:28  lr: 0.000010  ml_loss: 5.1496  mi_loss: 4.5013  train_loss: 9.6509  time: 2.4246  data: 0.0001  max mem: 20908
Train Epoch: [6]  [4650/4855]  eta: 0:08:25  lr: 0.000010  ml_loss: 5.4423  mi_loss: 4.1245  train_loss: 9.5669  time: 2.4560  data: 0.0001  max mem: 20908
Train Epoch: [6]  [4700/4855]  eta: 0:06:22  lr: 0.000010  ml_loss: 5.3629  mi_loss: 4.0054  train_loss: 9.3683  time: 2.4618  data: 0.0001  max mem: 20908
Train Epoch: [6]  [4750/4855]  eta: 0:04:18  lr: 0.000010  ml_loss: 5.2118  mi_loss: 4.0169  train_loss: 9.2286  time: 2.4211  data: 0.0001  max mem: 20908
Train Epoch: [6]  [4800/4855]  eta: 0:02:15  lr: 0.000010  ml_loss: 5.5312  mi_loss: 3.9639  train_loss: 9.4951  time: 2.4452  data: 0.0002  max mem: 20908
Train Epoch: [6]  [4850/4855]  eta: 0:00:12  lr: 0.000010  ml_loss: 5.0928  mi_loss: 4.5116  train_loss: 9.6044  time: 2.4221  data: 0.0001  max mem: 20908
Train Epoch: [6]  [4854/4855]  eta: 0:00:02  lr: 0.000010  ml_loss: 5.4284  mi_loss: 4.3544  train_loss: 9.7828  time: 2.4387  data: 0.0007  max mem: 20908
Train Epoch: [6] Total time: 3:19:29 (2.4655 s / it)
Val Epoch: [6]  [  0/540]  eta: 0:22:59  ml_loss: 5.1595  mi_loss: 4.2138  val_loss: 9.3734  accML: 0.2183  accMI: 0.1108  time: 2.5551  data: 2.2033  max mem: 20908
Val Epoch: [6]  [ 50/540]  eta: 0:06:37  ml_loss: 4.8112  mi_loss: 3.9237  val_loss: 8.7350  accML: 0.2863  accMI: 0.1984  time: 0.7957  data: 0.6344  max mem: 20908
Val Epoch: [6]  [100/540]  eta: 0:05:56  ml_loss: 4.9077  mi_loss: 4.3771  val_loss: 9.2849  accML: 0.2565  accMI: 0.1467  time: 0.7854  data: 0.6233  max mem: 20908
Val Epoch: [6]  [150/540]  eta: 0:05:27  ml_loss: 5.0123  mi_loss: 4.6355  val_loss: 9.6477  accML: 0.2294  accMI: 0.1159  time: 0.9409  data: 0.7775  max mem: 20908
Val Epoch: [6]  [200/540]  eta: 0:04:46  ml_loss: 5.1270  mi_loss: 4.5762  val_loss: 9.7032  accML: 0.2322  accMI: 0.1096  time: 0.8599  data: 0.6969  max mem: 20908
Val Epoch: [6]  [250/540]  eta: 0:04:02  ml_loss: 4.7704  mi_loss: 3.9506  val_loss: 8.7210  accML: 0.2843  accMI: 0.1658  time: 0.8278  data: 0.6656  max mem: 20908
Val Epoch: [6]  [300/540]  eta: 0:03:20  ml_loss: 4.4988  mi_loss: 3.9520  val_loss: 8.4508  accML: 0.2854  accMI: 0.1909  time: 0.8666  data: 0.7036  max mem: 20908
Val Epoch: [6]  [350/540]  eta: 0:02:38  ml_loss: 5.1028  mi_loss: 3.2379  val_loss: 8.3407  accML: 0.2339  accMI: 0.2960  time: 0.8106  data: 0.6481  max mem: 20908
Val Epoch: [6]  [400/540]  eta: 0:01:57  ml_loss: 5.4271  mi_loss: 4.4223  val_loss: 9.8494  accML: 0.2103  accMI: 0.1102  time: 0.8681  data: 0.7050  max mem: 20908
Val Epoch: [6]  [450/540]  eta: 0:01:15  ml_loss: 5.3822  mi_loss: 4.1251  val_loss: 9.5073  accML: 0.2096  accMI: 0.1280  time: 0.8490  data: 0.6860  max mem: 20908
Val Epoch: [6]  [500/540]  eta: 0:00:33  ml_loss: 5.1943  mi_loss: 4.0520  val_loss: 9.2463  accML: 0.2443  accMI: 0.1432  time: 0.7645  data: 0.6025  max mem: 20908
Val Epoch: [6]  [539/540]  eta: 0:00:00  ml_loss: 5.3412  mi_loss: 4.1277  val_loss: 9.4689  accML: 0.1745  accMI: 0.1577  time: 0.7733  data: 0.6133  max mem: 20908
Val Epoch: [6] Total time: 0:07:35 (0.8444 s / it)
epoch:6, iter:33984, 4854,  train_loss: 9.782794952392578, valid_loss: 9.27206609690631, idiv_loss:(5.080624634248239, 4.191441444114402), acc:(0.22824197444650862, 0.1481974481984421)
Averaged stats: lr: 0.0000  ml_loss: 5.1502  mi_loss: 4.2452  train_loss: 9.3955
epoch 6 9.782794952392578
Train Epoch: [7]  [   0/4855]  eta: 7:45:54  lr: 0.000010  ml_loss: 5.1045  mi_loss: 3.9039  train_loss: 9.0084  time: 5.7578  data: 3.3331  max mem: 20908
Train Epoch: [7]  [  50/4855]  eta: 3:20:44  lr: 0.000010  ml_loss: 4.8195  mi_loss: 4.4834  train_loss: 9.3029  time: 2.4507  data: 0.0001  max mem: 20908
Train Epoch: [7]  [ 100/4855]  eta: 3:15:23  lr: 0.000010  ml_loss: 4.7349  mi_loss: 3.7891  train_loss: 8.5240  time: 2.4091  data: 0.0001  max mem: 20908
Train Epoch: [7]  [ 150/4855]  eta: 3:12:37  lr: 0.000010  ml_loss: 5.4863  mi_loss: 4.3385  train_loss: 9.8248  time: 2.4259  data: 0.0001  max mem: 20908
Train Epoch: [7]  [ 200/4855]  eta: 3:09:53  lr: 0.000010  ml_loss: 5.3528  mi_loss: 4.4009  train_loss: 9.7537  time: 2.4349  data: 0.0001  max mem: 20908
Train Epoch: [7]  [ 250/4855]  eta: 3:07:48  lr: 0.000010  ml_loss: 5.0800  mi_loss: 4.3869  train_loss: 9.4669  time: 2.4421  data: 0.0001  max mem: 20908
Train Epoch: [7]  [ 300/4855]  eta: 3:05:15  lr: 0.000010  ml_loss: 5.4847  mi_loss: 4.0716  train_loss: 9.5563  time: 2.4133  data: 0.0001  max mem: 20908
Train Epoch: [7]  [ 350/4855]  eta: 3:03:03  lr: 0.000010  ml_loss: 5.4832  mi_loss: 4.5707  train_loss: 10.0539  time: 2.4493  data: 0.0002  max mem: 20908
Train Epoch: [7]  [ 400/4855]  eta: 3:01:08  lr: 0.000010  ml_loss: 5.2859  mi_loss: 3.7956  train_loss: 9.0814  time: 2.4496  data: 0.0001  max mem: 20908
Train Epoch: [7]  [ 450/4855]  eta: 2:59:01  lr: 0.000010  ml_loss: 4.9037  mi_loss: 3.3987  train_loss: 8.3025  time: 2.4373  data: 0.0001  max mem: 20908
Train Epoch: [7]  [ 500/4855]  eta: 2:56:55  lr: 0.000010  ml_loss: 5.3108  mi_loss: 4.5625  train_loss: 9.8733  time: 2.4412  data: 0.0001  max mem: 20908
Train Epoch: [7]  [ 550/4855]  eta: 2:54:48  lr: 0.000010  ml_loss: 4.8574  mi_loss: 4.3025  train_loss: 9.1599  time: 2.4178  data: 0.0001  max mem: 20908
Train Epoch: [7]  [ 600/4855]  eta: 2:52:45  lr: 0.000010  ml_loss: 5.2890  mi_loss: 4.1897  train_loss: 9.4787  time: 2.4336  data: 0.0001  max mem: 20908
Train Epoch: [7]  [ 650/4855]  eta: 2:50:40  lr: 0.000010  ml_loss: 5.1646  mi_loss: 4.4150  train_loss: 9.5797  time: 2.4235  data: 0.0001  max mem: 20908
Train Epoch: [7]  [ 700/4855]  eta: 2:48:38  lr: 0.000010  ml_loss: 5.3348  mi_loss: 3.5747  train_loss: 8.9095  time: 2.4284  data: 0.0001  max mem: 20908
Train Epoch: [7]  [ 750/4855]  eta: 2:46:38  lr: 0.000010  ml_loss: 4.8796  mi_loss: 4.6225  train_loss: 9.5021  time: 2.4154  data: 0.0001  max mem: 20908
Train Epoch: [7]  [ 800/4855]  eta: 2:44:37  lr: 0.000010  ml_loss: 5.4668  mi_loss: 4.5834  train_loss: 10.0502  time: 2.4490  data: 0.0001  max mem: 20908
Train Epoch: [7]  [ 850/4855]  eta: 2:42:37  lr: 0.000010  ml_loss: 4.2994  mi_loss: 3.9255  train_loss: 8.2250  time: 2.4397  data: 0.0001  max mem: 20908
Train Epoch: [7]  [ 900/4855]  eta: 2:40:37  lr: 0.000010  ml_loss: 5.1646  mi_loss: 4.1071  train_loss: 9.2717  time: 2.4323  data: 0.0001  max mem: 20908
Train Epoch: [7]  [ 950/4855]  eta: 2:38:33  lr: 0.000010  ml_loss: 4.8710  mi_loss: 4.1832  train_loss: 9.0542  time: 2.4230  data: 0.0001  max mem: 20908
Train Epoch: [7]  [1000/4855]  eta: 2:36:35  lr: 0.000010  ml_loss: 5.1251  mi_loss: 4.1934  train_loss: 9.3185  time: 2.4527  data: 0.0002  max mem: 20908
Train Epoch: [7]  [1050/4855]  eta: 2:34:38  lr: 0.000010  ml_loss: 5.2548  mi_loss: 4.2667  train_loss: 9.5215  time: 2.4906  data: 0.0001  max mem: 20908
Train Epoch: [7]  [1100/4855]  eta: 2:32:44  lr: 0.000010  ml_loss: 5.1530  mi_loss: 4.0195  train_loss: 9.1725  time: 2.4797  data: 0.0001  max mem: 20908
Train Epoch: [7]  [1150/4855]  eta: 2:30:48  lr: 0.000010  ml_loss: 5.3359  mi_loss: 3.7943  train_loss: 9.1301  time: 2.4650  data: 0.0001  max mem: 20908
Train Epoch: [7]  [1200/4855]  eta: 2:28:52  lr: 0.000010  ml_loss: 5.1362  mi_loss: 4.0430  train_loss: 9.1792  time: 2.4835  data: 0.0001  max mem: 20908
Train Epoch: [7]  [1250/4855]  eta: 2:26:52  lr: 0.000010  ml_loss: 4.9083  mi_loss: 3.9093  train_loss: 8.8177  time: 2.4442  data: 0.0001  max mem: 20908
Train Epoch: [7]  [1300/4855]  eta: 2:24:51  lr: 0.000010  ml_loss: 5.1871  mi_loss: 4.3651  train_loss: 9.5522  time: 2.4643  data: 0.0001  max mem: 20908
Train Epoch: [7]  [1350/4855]  eta: 2:22:53  lr: 0.000010  ml_loss: 4.4661  mi_loss: 4.2770  train_loss: 8.7430  time: 2.4596  data: 0.0001  max mem: 20908
Train Epoch: [7]  [1400/4855]  eta: 2:20:55  lr: 0.000010  ml_loss: 5.3076  mi_loss: 4.0632  train_loss: 9.3708  time: 2.4792  data: 0.0001  max mem: 20908
Train Epoch: [7]  [1450/4855]  eta: 2:18:56  lr: 0.000010  ml_loss: 4.8694  mi_loss: 4.5509  train_loss: 9.4203  time: 2.4816  data: 0.0001  max mem: 20908
Train Epoch: [7]  [1500/4855]  eta: 2:16:56  lr: 0.000010  ml_loss: 5.0956  mi_loss: 3.9240  train_loss: 9.0197  time: 2.4637  data: 0.0001  max mem: 20908
Train Epoch: [7]  [1550/4855]  eta: 2:14:55  lr: 0.000010  ml_loss: 5.2370  mi_loss: 4.3715  train_loss: 9.6084  time: 2.4891  data: 0.0001  max mem: 20908
Train Epoch: [7]  [1600/4855]  eta: 2:12:55  lr: 0.000010  ml_loss: 4.9773  mi_loss: 3.0731  train_loss: 8.0504  time: 2.4690  data: 0.0001  max mem: 20908
Train Epoch: [7]  [1650/4855]  eta: 2:10:54  lr: 0.000010  ml_loss: 3.7252  mi_loss: 3.6122  train_loss: 7.3375  time: 2.4818  data: 0.0001  max mem: 20908
Train Epoch: [7]  [1700/4855]  eta: 2:08:53  lr: 0.000010  ml_loss: 4.5845  mi_loss: 3.6450  train_loss: 8.2294  time: 2.4813  data: 0.0001  max mem: 20908
Train Epoch: [7]  [1750/4855]  eta: 2:06:50  lr: 0.000010  ml_loss: 5.4025  mi_loss: 4.5703  train_loss: 9.9728  time: 2.4522  data: 0.0001  max mem: 20908
Train Epoch: [7]  [1800/4855]  eta: 2:04:47  lr: 0.000010  ml_loss: 5.6797  mi_loss: 4.2849  train_loss: 9.9646  time: 2.4455  data: 0.0001  max mem: 20908
Train Epoch: [7]  [1850/4855]  eta: 2:02:45  lr: 0.000010  ml_loss: 5.2251  mi_loss: 3.7050  train_loss: 8.9301  time: 2.4446  data: 0.0001  max mem: 20908
Train Epoch: [7]  [1900/4855]  eta: 2:00:41  lr: 0.000010  ml_loss: 5.1628  mi_loss: 4.5632  train_loss: 9.7260  time: 2.4475  data: 0.0001  max mem: 20908
Train Epoch: [7]  [1950/4855]  eta: 1:58:40  lr: 0.000010  ml_loss: 5.6075  mi_loss: 4.0451  train_loss: 9.6526  time: 2.4675  data: 0.0001  max mem: 20908
Train Epoch: [7]  [2000/4855]  eta: 1:56:39  lr: 0.000010  ml_loss: 4.7565  mi_loss: 3.6896  train_loss: 8.4461  time: 2.4598  data: 0.0001  max mem: 20908
Train Epoch: [7]  [2050/4855]  eta: 1:54:37  lr: 0.000010  ml_loss: 5.4573  mi_loss: 4.5499  train_loss: 10.0072  time: 2.4775  data: 0.0001  max mem: 20908
Train Epoch: [7]  [2100/4855]  eta: 1:52:34  lr: 0.000010  ml_loss: 4.6097  mi_loss: 4.4877  train_loss: 9.0974  time: 2.4810  data: 0.0001  max mem: 20908
Train Epoch: [7]  [2150/4855]  eta: 1:50:33  lr: 0.000010  ml_loss: 5.1430  mi_loss: 4.4077  train_loss: 9.5507  time: 2.4710  data: 0.0001  max mem: 20908
Train Epoch: [7]  [2200/4855]  eta: 1:48:30  lr: 0.000010  ml_loss: 4.4774  mi_loss: 4.5046  train_loss: 8.9820  time: 2.4670  data: 0.0001  max mem: 20908
Train Epoch: [7]  [2250/4855]  eta: 1:46:29  lr: 0.000010  ml_loss: 4.7824  mi_loss: 4.2729  train_loss: 9.0553  time: 2.4783  data: 0.0001  max mem: 20908
Train Epoch: [7]  [2300/4855]  eta: 1:44:28  lr: 0.000010  ml_loss: 5.3074  mi_loss: 4.7339  train_loss: 10.0413  time: 2.4890  data: 0.0001  max mem: 20908
Train Epoch: [7]  [2350/4855]  eta: 1:42:25  lr: 0.000010  ml_loss: 5.0344  mi_loss: 4.9321  train_loss: 9.9666  time: 2.4185  data: 0.0001  max mem: 20908
Train Epoch: [7]  [2400/4855]  eta: 1:40:22  lr: 0.000010  ml_loss: 4.1669  mi_loss: 4.0983  train_loss: 8.2652  time: 2.4652  data: 0.0001  max mem: 20908
Train Epoch: [7]  [2450/4855]  eta: 1:38:21  lr: 0.000010  ml_loss: 5.5839  mi_loss: 4.4558  train_loss: 10.0397  time: 2.4863  data: 0.0001  max mem: 20908
Train Epoch: [7]  [2500/4855]  eta: 1:36:18  lr: 0.000010  ml_loss: 5.1705  mi_loss: 4.4974  train_loss: 9.6679  time: 2.4482  data: 0.0001  max mem: 20908
Train Epoch: [7]  [2550/4855]  eta: 1:34:17  lr: 0.000010  ml_loss: 4.4975  mi_loss: 4.0780  train_loss: 8.5755  time: 2.4902  data: 0.0001  max mem: 20908
Train Epoch: [7]  [2600/4855]  eta: 1:32:15  lr: 0.000010  ml_loss: 5.1125  mi_loss: 4.8803  train_loss: 9.9928  time: 2.4879  data: 0.0001  max mem: 20908
Train Epoch: [7]  [2650/4855]  eta: 1:30:14  lr: 0.000010  ml_loss: 4.9088  mi_loss: 4.1057  train_loss: 9.0145  time: 2.4684  data: 0.0001  max mem: 20908
Train Epoch: [7]  [2700/4855]  eta: 1:28:11  lr: 0.000010  ml_loss: 4.9636  mi_loss: 5.2397  train_loss: 10.2033  time: 2.4374  data: 0.0001  max mem: 20908
Train Epoch: [7]  [2750/4855]  eta: 1:26:08  lr: 0.000010  ml_loss: 5.1030  mi_loss: 3.9577  train_loss: 9.0606  time: 2.4640  data: 0.0001  max mem: 20908
Train Epoch: [7]  [2800/4855]  eta: 1:24:06  lr: 0.000010  ml_loss: 5.4763  mi_loss: 4.4182  train_loss: 9.8946  time: 2.4846  data: 0.0001  max mem: 20908
Train Epoch: [7]  [2850/4855]  eta: 1:22:04  lr: 0.000010  ml_loss: 5.1635  mi_loss: 4.2821  train_loss: 9.4456  time: 2.4522  data: 0.0001  max mem: 20908
Train Epoch: [7]  [2900/4855]  eta: 1:20:01  lr: 0.000010  ml_loss: 5.4322  mi_loss: 4.1898  train_loss: 9.6220  time: 2.4527  data: 0.0001  max mem: 20908
Train Epoch: [7]  [2950/4855]  eta: 1:17:59  lr: 0.000010  ml_loss: 4.7624  mi_loss: 4.1109  train_loss: 8.8733  time: 2.4613  data: 0.0001  max mem: 20908
Train Epoch: [7]  [3000/4855]  eta: 1:15:57  lr: 0.000010  ml_loss: 5.1629  mi_loss: 3.8857  train_loss: 9.0486  time: 2.4795  data: 0.0001  max mem: 20908
Train Epoch: [7]  [3050/4855]  eta: 1:13:55  lr: 0.000010  ml_loss: 4.8342  mi_loss: 4.0453  train_loss: 8.8796  time: 2.5120  data: 0.0001  max mem: 20908
Train Epoch: [7]  [3100/4855]  eta: 1:11:53  lr: 0.000010  ml_loss: 5.1589  mi_loss: 4.8450  train_loss: 10.0039  time: 2.4660  data: 0.0001  max mem: 20908
Train Epoch: [7]  [3150/4855]  eta: 1:09:50  lr: 0.000010  ml_loss: 5.1791  mi_loss: 3.9367  train_loss: 9.1158  time: 2.4593  data: 0.0001  max mem: 20908
Train Epoch: [7]  [3200/4855]  eta: 1:07:48  lr: 0.000010  ml_loss: 5.5192  mi_loss: 4.4098  train_loss: 9.9290  time: 2.5016  data: 0.0001  max mem: 20908
Train Epoch: [7]  [3250/4855]  eta: 1:05:46  lr: 0.000010  ml_loss: 4.2687  mi_loss: 4.2690  train_loss: 8.5377  time: 2.5051  data: 0.0001  max mem: 20908
Train Epoch: [7]  [3300/4855]  eta: 1:03:44  lr: 0.000010  ml_loss: 5.4118  mi_loss: 4.8679  train_loss: 10.2797  time: 2.4717  data: 0.0001  max mem: 20908
Train Epoch: [7]  [3350/4855]  eta: 1:01:42  lr: 0.000010  ml_loss: 4.4216  mi_loss: 4.0585  train_loss: 8.4801  time: 2.4979  data: 0.0001  max mem: 20908
Train Epoch: [7]  [3400/4855]  eta: 0:59:39  lr: 0.000010  ml_loss: 5.1033  mi_loss: 4.1713  train_loss: 9.2746  time: 2.5032  data: 0.0001  max mem: 20908
Train Epoch: [7]  [3450/4855]  eta: 0:57:37  lr: 0.000010  ml_loss: 5.0209  mi_loss: 3.9122  train_loss: 8.9331  time: 2.5078  data: 0.0001  max mem: 20908
Train Epoch: [7]  [3500/4855]  eta: 0:55:35  lr: 0.000010  ml_loss: 5.5320  mi_loss: 3.3102  train_loss: 8.8422  time: 2.4998  data: 0.0001  max mem: 20908
Train Epoch: [7]  [3550/4855]  eta: 0:53:33  lr: 0.000010  ml_loss: 5.0138  mi_loss: 3.8559  train_loss: 8.8697  time: 2.5079  data: 0.0001  max mem: 20908
Train Epoch: [7]  [3600/4855]  eta: 0:51:30  lr: 0.000010  ml_loss: 4.7877  mi_loss: 4.2516  train_loss: 9.0392  time: 2.4917  data: 0.0001  max mem: 20908
Train Epoch: [7]  [3650/4855]  eta: 0:49:28  lr: 0.000010  ml_loss: 5.2621  mi_loss: 4.4224  train_loss: 9.6845  time: 2.4953  data: 0.0001  max mem: 20908
Train Epoch: [7]  [3700/4855]  eta: 0:47:25  lr: 0.000010  ml_loss: 5.1610  mi_loss: 4.5128  train_loss: 9.6738  time: 2.4881  data: 0.0001  max mem: 20908
Train Epoch: [7]  [3750/4855]  eta: 0:45:22  lr: 0.000010  ml_loss: 4.7862  mi_loss: 4.5231  train_loss: 9.3093  time: 2.4878  data: 0.0001  max mem: 20908
Train Epoch: [7]  [3800/4855]  eta: 0:43:19  lr: 0.000010  ml_loss: 5.3585  mi_loss: 4.0739  train_loss: 9.4324  time: 2.4569  data: 0.0001  max mem: 20908
Train Epoch: [7]  [3850/4855]  eta: 0:41:16  lr: 0.000010  ml_loss: 5.1497  mi_loss: 4.1438  train_loss: 9.2935  time: 2.5053  data: 0.0001  max mem: 20908
Train Epoch: [7]  [3900/4855]  eta: 0:39:13  lr: 0.000010  ml_loss: 4.1473  mi_loss: 4.3348  train_loss: 8.4820  time: 2.5007  data: 0.0001  max mem: 20908
Train Epoch: [7]  [3950/4855]  eta: 0:37:10  lr: 0.000010  ml_loss: 5.3458  mi_loss: 4.1041  train_loss: 9.4498  time: 2.4972  data: 0.0001  max mem: 20908
Train Epoch: [7]  [4000/4855]  eta: 0:35:07  lr: 0.000010  ml_loss: 5.5160  mi_loss: 3.9568  train_loss: 9.4727  time: 2.4654  data: 0.0001  max mem: 20908
Train Epoch: [7]  [4050/4855]  eta: 0:33:04  lr: 0.000010  ml_loss: 4.7586  mi_loss: 4.6319  train_loss: 9.3904  time: 2.4816  data: 0.0001  max mem: 20908
Train Epoch: [7]  [4100/4855]  eta: 0:31:01  lr: 0.000010  ml_loss: 4.8705  mi_loss: 3.8882  train_loss: 8.7586  time: 2.4619  data: 0.0001  max mem: 20908
Train Epoch: [7]  [4150/4855]  eta: 0:28:58  lr: 0.000010  ml_loss: 4.7256  mi_loss: 4.2919  train_loss: 9.0175  time: 2.4977  data: 0.0001  max mem: 20908
Train Epoch: [7]  [4200/4855]  eta: 0:26:55  lr: 0.000010  ml_loss: 5.0058  mi_loss: 4.0054  train_loss: 9.0112  time: 2.4828  data: 0.0001  max mem: 20908
Train Epoch: [7]  [4250/4855]  eta: 0:24:52  lr: 0.000010  ml_loss: 5.0175  mi_loss: 4.0912  train_loss: 9.1088  time: 2.4613  data: 0.0001  max mem: 20908
Train Epoch: [7]  [4300/4855]  eta: 0:22:48  lr: 0.000010  ml_loss: 4.8646  mi_loss: 4.0538  train_loss: 8.9185  time: 2.4773  data: 0.0001  max mem: 20908
Train Epoch: [7]  [4350/4855]  eta: 0:20:45  lr: 0.000010  ml_loss: 5.5798  mi_loss: 4.2238  train_loss: 9.8035  time: 2.4673  data: 0.0001  max mem: 20908
Train Epoch: [7]  [4400/4855]  eta: 0:18:42  lr: 0.000010  ml_loss: 4.8287  mi_loss: 4.1933  train_loss: 9.0220  time: 2.4890  data: 0.0001  max mem: 20908
Train Epoch: [7]  [4450/4855]  eta: 0:16:38  lr: 0.000010  ml_loss: 4.7894  mi_loss: 4.0611  train_loss: 8.8505  time: 2.4869  data: 0.0001  max mem: 20908
Train Epoch: [7]  [4500/4855]  eta: 0:14:35  lr: 0.000010  ml_loss: 5.3282  mi_loss: 4.1720  train_loss: 9.5001  time: 2.4926  data: 0.0001  max mem: 20908
Train Epoch: [7]  [4550/4855]  eta: 0:12:32  lr: 0.000010  ml_loss: 5.5672  mi_loss: 3.9687  train_loss: 9.5359  time: 2.4559  data: 0.0001  max mem: 20908
Train Epoch: [7]  [4600/4855]  eta: 0:10:28  lr: 0.000010  ml_loss: 4.8022  mi_loss: 4.3715  train_loss: 9.1737  time: 2.4766  data: 0.0001  max mem: 20908
Train Epoch: [7]  [4650/4855]  eta: 0:08:25  lr: 0.000010  ml_loss: 4.7835  mi_loss: 3.8190  train_loss: 8.6024  time: 2.4837  data: 0.0001  max mem: 20908
Train Epoch: [7]  [4700/4855]  eta: 0:06:22  lr: 0.000010  ml_loss: 4.9856  mi_loss: 4.1582  train_loss: 9.1438  time: 2.4817  data: 0.0001  max mem: 20908
Train Epoch: [7]  [4750/4855]  eta: 0:04:19  lr: 0.000010  ml_loss: 4.6105  mi_loss: 4.6937  train_loss: 9.3041  time: 2.4663  data: 0.0001  max mem: 20908
Train Epoch: [7]  [4800/4855]  eta: 0:02:15  lr: 0.000010  ml_loss: 5.2774  mi_loss: 4.3687  train_loss: 9.6461  time: 2.4744  data: 0.0001  max mem: 20908
Train Epoch: [7]  [4850/4855]  eta: 0:00:12  lr: 0.000010  ml_loss: 5.0507  mi_loss: 4.9558  train_loss: 10.0065  time: 2.4789  data: 0.0001  max mem: 20908
Train Epoch: [7]  [4854/4855]  eta: 0:00:02  lr: 0.000010  ml_loss: 5.0049  mi_loss: 4.1172  train_loss: 9.1221  time: 2.4853  data: 0.0007  max mem: 20908
Train Epoch: [7] Total time: 3:19:40 (2.4676 s / it)
Val Epoch: [7]  [  0/540]  eta: 0:22:43  ml_loss: 5.3243  mi_loss: 4.2928  val_loss: 9.6171  accML: 0.2080  accMI: 0.1108  time: 2.5250  data: 2.1361  max mem: 20908
Val Epoch: [7]  [ 50/540]  eta: 0:06:28  ml_loss: 5.0085  mi_loss: 3.9369  val_loss: 8.9454  accML: 0.2267  accMI: 0.2011  time: 0.7828  data: 0.6212  max mem: 20908
Val Epoch: [7]  [100/540]  eta: 0:05:51  ml_loss: 4.8459  mi_loss: 4.4751  val_loss: 9.3210  accML: 0.2417  accMI: 0.1280  time: 0.7744  data: 0.6128  max mem: 20908
Val Epoch: [7]  [150/540]  eta: 0:05:22  ml_loss: 5.0684  mi_loss: 4.7185  val_loss: 9.7868  accML: 0.2246  accMI: 0.0997  time: 0.9339  data: 0.7703  max mem: 20908
Val Epoch: [7]  [200/540]  eta: 0:04:43  ml_loss: 5.1791  mi_loss: 4.5700  val_loss: 9.7491  accML: 0.2270  accMI: 0.0963  time: 0.8582  data: 0.6950  max mem: 20908
Val Epoch: [7]  [250/540]  eta: 0:04:00  ml_loss: 4.6221  mi_loss: 4.0224  val_loss: 8.6444  accML: 0.2998  accMI: 0.1495  time: 0.8591  data: 0.6967  max mem: 20908
Val Epoch: [7]  [300/540]  eta: 0:03:18  ml_loss: 4.6199  mi_loss: 4.0262  val_loss: 8.6461  accML: 0.2738  accMI: 0.1855  time: 0.8566  data: 0.6934  max mem: 20908
Val Epoch: [7]  [350/540]  eta: 0:02:37  ml_loss: 4.8149  mi_loss: 3.2875  val_loss: 8.1024  accML: 0.2511  accMI: 0.2907  time: 0.7986  data: 0.6364  max mem: 20908
Val Epoch: [7]  [400/540]  eta: 0:01:56  ml_loss: 5.5902  mi_loss: 4.4250  val_loss: 10.0152  accML: 0.1824  accMI: 0.1075  time: 0.8625  data: 0.6994  max mem: 20908
Val Epoch: [7]  [450/540]  eta: 0:01:15  ml_loss: 5.1369  mi_loss: 4.1258  val_loss: 9.2627  accML: 0.2063  accMI: 0.1067  time: 0.8581  data: 0.6952  max mem: 20908
Val Epoch: [7]  [500/540]  eta: 0:00:33  ml_loss: 5.1779  mi_loss: 4.0064  val_loss: 9.1843  accML: 0.2145  accMI: 0.1514  time: 0.7698  data: 0.6076  max mem: 20908
Val Epoch: [7]  [539/540]  eta: 0:00:00  ml_loss: 5.2120  mi_loss: 4.0265  val_loss: 9.2385  accML: 0.2095  accMI: 0.1622  time: 0.7713  data: 0.6116  max mem: 20908
Val Epoch: [7] Total time: 0:07:31 (0.8366 s / it)
epoch:7, iter:38839, 4854,  train_loss: 9.12209701538086, valid_loss: 9.20614586494587, idiv_loss:(4.9970583372645905, 4.209087524590669), acc:(0.2346312860923785, 0.14666220388478704)
Averaged stats: lr: 0.0000  ml_loss: 5.0869  mi_loss: 4.2085  train_loss: 9.2954
epoch 7 9.12209701538086
Train Epoch: [8]  [   0/4855]  eta: 7:39:44  lr: 0.000010  ml_loss: 4.9600  mi_loss: 4.4193  train_loss: 9.3793  time: 5.6816  data: 2.2697  max mem: 20908
Train Epoch: [8]  [  50/4855]  eta: 3:25:19  lr: 0.000010  ml_loss: 4.4665  mi_loss: 3.9806  train_loss: 8.4471  time: 2.5032  data: 0.0001  max mem: 20908
Train Epoch: [8]  [ 100/4855]  eta: 3:20:09  lr: 0.000010  ml_loss: 4.7614  mi_loss: 4.4743  train_loss: 9.2357  time: 2.4868  data: 0.0001  max mem: 20908
Train Epoch: [8]  [ 150/4855]  eta: 3:16:52  lr: 0.000010  ml_loss: 5.3701  mi_loss: 4.4122  train_loss: 9.7823  time: 2.4934  data: 0.0001  max mem: 20908
Train Epoch: [8]  [ 200/4855]  eta: 3:14:17  lr: 0.000010  ml_loss: 4.9325  mi_loss: 3.8427  train_loss: 8.7753  time: 2.4840  data: 0.0001  max mem: 20908
Train Epoch: [8]  [ 250/4855]  eta: 3:11:43  lr: 0.000010  ml_loss: 4.9797  mi_loss: 3.8171  train_loss: 8.7968  time: 2.4875  data: 0.0001  max mem: 20908
Train Epoch: [8]  [ 300/4855]  eta: 3:09:26  lr: 0.000010  ml_loss: 5.1903  mi_loss: 3.6663  train_loss: 8.8566  time: 2.4823  data: 0.0001  max mem: 20908
Train Epoch: [8]  [ 350/4855]  eta: 3:07:07  lr: 0.000010  ml_loss: 5.0234  mi_loss: 4.3541  train_loss: 9.3776  time: 2.4460  data: 0.0001  max mem: 20908
Train Epoch: [8]  [ 400/4855]  eta: 3:04:32  lr: 0.000010  ml_loss: 5.2786  mi_loss: 4.2888  train_loss: 9.5674  time: 2.4385  data: 0.0001  max mem: 20908
Train Epoch: [8]  [ 450/4855]  eta: 3:02:06  lr: 0.000010  ml_loss: 4.8469  mi_loss: 3.9829  train_loss: 8.8298  time: 2.4337  data: 0.0001  max mem: 20908
Train Epoch: [8]  [ 500/4855]  eta: 2:59:41  lr: 0.000010  ml_loss: 5.5027  mi_loss: 4.3040  train_loss: 9.8068  time: 2.4361  data: 0.0001  max mem: 20908
Train Epoch: [8]  [ 550/4855]  eta: 2:57:19  lr: 0.000010  ml_loss: 4.7466  mi_loss: 4.0893  train_loss: 8.8359  time: 2.4150  data: 0.0001  max mem: 20908
Train Epoch: [8]  [ 600/4855]  eta: 2:55:12  lr: 0.000010  ml_loss: 5.2876  mi_loss: 4.0836  train_loss: 9.3712  time: 2.4648  data: 0.0001  max mem: 20908
Train Epoch: [8]  [ 650/4855]  eta: 2:53:04  lr: 0.000010  ml_loss: 4.9204  mi_loss: 4.1399  train_loss: 9.0602  time: 2.4613  data: 0.0001  max mem: 20908
Train Epoch: [8]  [ 700/4855]  eta: 2:51:01  lr: 0.000010  ml_loss: 5.4715  mi_loss: 4.3041  train_loss: 9.7757  time: 2.4791  data: 0.0001  max mem: 20908
Train Epoch: [8]  [ 750/4855]  eta: 2:48:55  lr: 0.000010  ml_loss: 5.1595  mi_loss: 3.4764  train_loss: 8.6360  time: 2.4544  data: 0.0002  max mem: 20908
Train Epoch: [8]  [ 800/4855]  eta: 2:46:48  lr: 0.000010  ml_loss: 4.3223  mi_loss: 3.9426  train_loss: 8.2648  time: 2.4561  data: 0.0001  max mem: 20908
Train Epoch: [8]  [ 850/4855]  eta: 2:44:43  lr: 0.000010  ml_loss: 5.1797  mi_loss: 4.1606  train_loss: 9.3403  time: 2.4626  data: 0.0001  max mem: 20908
Train Epoch: [8]  [ 900/4855]  eta: 2:42:38  lr: 0.000010  ml_loss: 5.2662  mi_loss: 4.3680  train_loss: 9.6342  time: 2.4542  data: 0.0002  max mem: 20908
Train Epoch: [8]  [ 950/4855]  eta: 2:40:31  lr: 0.000010  ml_loss: 5.2346  mi_loss: 4.3758  train_loss: 9.6104  time: 2.4503  data: 0.0001  max mem: 20908
Train Epoch: [8]  [1000/4855]  eta: 2:38:27  lr: 0.000010  ml_loss: 4.7035  mi_loss: 4.8111  train_loss: 9.5147  time: 2.4683  data: 0.0001  max mem: 20908
Train Epoch: [8]  [1050/4855]  eta: 2:36:22  lr: 0.000010  ml_loss: 4.9986  mi_loss: 4.6708  train_loss: 9.6694  time: 2.4586  data: 0.0001  max mem: 20908
Train Epoch: [8]  [1100/4855]  eta: 2:34:18  lr: 0.000010  ml_loss: 5.1077  mi_loss: 4.3408  train_loss: 9.4485  time: 2.4482  data: 0.0001  max mem: 20908
Train Epoch: [8]  [1150/4855]  eta: 2:32:13  lr: 0.000010  ml_loss: 5.5793  mi_loss: 4.3681  train_loss: 9.9474  time: 2.4478  data: 0.0003  max mem: 20908
Train Epoch: [8]  [1200/4855]  eta: 2:30:07  lr: 0.000010  ml_loss: 4.3465  mi_loss: 4.4154  train_loss: 8.7619  time: 2.4458  data: 0.0001  max mem: 20908
Train Epoch: [8]  [1250/4855]  eta: 2:27:59  lr: 0.000010  ml_loss: 4.9750  mi_loss: 4.0449  train_loss: 9.0199  time: 2.4317  data: 0.0001  max mem: 20908
Train Epoch: [8]  [1300/4855]  eta: 2:25:54  lr: 0.000010  ml_loss: 5.4252  mi_loss: 4.0927  train_loss: 9.5180  time: 2.4419  data: 0.0001  max mem: 20908
Train Epoch: [8]  [1350/4855]  eta: 2:23:51  lr: 0.000010  ml_loss: 5.6240  mi_loss: 4.2829  train_loss: 9.9069  time: 2.4555  data: 0.0001  max mem: 20908
Train Epoch: [8]  [1400/4855]  eta: 2:21:45  lr: 0.000010  ml_loss: 5.1434  mi_loss: 3.9400  train_loss: 9.0834  time: 2.4452  data: 0.0001  max mem: 20908
Train Epoch: [8]  [1450/4855]  eta: 2:19:41  lr: 0.000010  ml_loss: 4.8521  mi_loss: 4.4631  train_loss: 9.3152  time: 2.4555  data: 0.0001  max mem: 20908
Train Epoch: [8]  [1500/4855]  eta: 2:17:36  lr: 0.000010  ml_loss: 5.2264  mi_loss: 4.2950  train_loss: 9.5214  time: 2.4571  data: 0.0001  max mem: 20908
Train Epoch: [8]  [1550/4855]  eta: 2:15:32  lr: 0.000010  ml_loss: 4.8505  mi_loss: 4.0664  train_loss: 8.9169  time: 2.4435  data: 0.0003  max mem: 20908
Train Epoch: [8]  [1600/4855]  eta: 2:13:26  lr: 0.000010  ml_loss: 4.5764  mi_loss: 3.3148  train_loss: 7.8912  time: 2.4353  data: 0.0001  max mem: 20908
Train Epoch: [8]  [1650/4855]  eta: 2:11:21  lr: 0.000010  ml_loss: 4.9679  mi_loss: 4.7330  train_loss: 9.7009  time: 2.4489  data: 0.0001  max mem: 20908
Train Epoch: [8]  [1700/4855]  eta: 2:09:19  lr: 0.000010  ml_loss: 4.7369  mi_loss: 4.3547  train_loss: 9.0916  time: 2.4544  data: 0.0002  max mem: 20908
Train Epoch: [8]  [1750/4855]  eta: 2:07:15  lr: 0.000010  ml_loss: 4.6658  mi_loss: 4.3507  train_loss: 9.0165  time: 2.4292  data: 0.0001  max mem: 20908
Train Epoch: [8]  [1800/4855]  eta: 2:05:11  lr: 0.000010  ml_loss: 4.6497  mi_loss: 4.3073  train_loss: 8.9570  time: 2.4566  data: 0.0002  max mem: 20908
Train Epoch: [8]  [1850/4855]  eta: 2:03:08  lr: 0.000010  ml_loss: 4.7859  mi_loss: 4.1118  train_loss: 8.8977  time: 2.4712  data: 0.0001  max mem: 20908
Train Epoch: [8]  [1900/4855]  eta: 2:01:04  lr: 0.000010  ml_loss: 5.4888  mi_loss: 4.0369  train_loss: 9.5257  time: 2.4437  data: 0.0001  max mem: 20908
Train Epoch: [8]  [1950/4855]  eta: 1:59:01  lr: 0.000010  ml_loss: 4.9565  mi_loss: 4.2901  train_loss: 9.2467  time: 2.4610  data: 0.0001  max mem: 20908
Train Epoch: [8]  [2000/4855]  eta: 1:56:57  lr: 0.000010  ml_loss: 5.3855  mi_loss: 4.4637  train_loss: 9.8492  time: 2.4514  data: 0.0001  max mem: 20908
Train Epoch: [8]  [2050/4855]  eta: 1:54:54  lr: 0.000010  ml_loss: 5.2223  mi_loss: 4.5871  train_loss: 9.8094  time: 2.4457  data: 0.0001  max mem: 20908
Train Epoch: [8]  [2100/4855]  eta: 1:52:51  lr: 0.000010  ml_loss: 5.1699  mi_loss: 4.3589  train_loss: 9.5288  time: 2.4395  data: 0.0001  max mem: 20908
Train Epoch: [8]  [2150/4855]  eta: 1:50:48  lr: 0.000010  ml_loss: 5.0750  mi_loss: 3.9110  train_loss: 8.9861  time: 2.4686  data: 0.0003  max mem: 20908
Train Epoch: [8]  [2200/4855]  eta: 1:48:46  lr: 0.000010  ml_loss: 4.8873  mi_loss: 3.8138  train_loss: 8.7011  time: 2.4747  data: 0.0001  max mem: 20908
Train Epoch: [8]  [2250/4855]  eta: 1:46:43  lr: 0.000010  ml_loss: 5.1207  mi_loss: 4.3228  train_loss: 9.4435  time: 2.4593  data: 0.0001  max mem: 20908
Train Epoch: [8]  [2300/4855]  eta: 1:44:40  lr: 0.000010  ml_loss: 4.6873  mi_loss: 4.2003  train_loss: 8.8876  time: 2.4685  data: 0.0001  max mem: 20908
Train Epoch: [8]  [2350/4855]  eta: 1:42:36  lr: 0.000010  ml_loss: 4.5956  mi_loss: 4.3144  train_loss: 8.9100  time: 2.4591  data: 0.0001  max mem: 20908
Train Epoch: [8]  [2400/4855]  eta: 1:40:35  lr: 0.000010  ml_loss: 4.2495  mi_loss: 3.9969  train_loss: 8.2464  time: 2.4984  data: 0.0001  max mem: 20908
Train Epoch: [8]  [2450/4855]  eta: 1:38:34  lr: 0.000010  ml_loss: 5.1937  mi_loss: 4.1056  train_loss: 9.2994  time: 2.4949  data: 0.0001  max mem: 20908
Train Epoch: [8]  [2500/4855]  eta: 1:36:33  lr: 0.000010  ml_loss: 4.9400  mi_loss: 3.9593  train_loss: 8.8993  time: 2.4987  data: 0.0001  max mem: 20908
Train Epoch: [8]  [2550/4855]  eta: 1:34:31  lr: 0.000010  ml_loss: 4.4363  mi_loss: 4.5027  train_loss: 8.9389  time: 2.4941  data: 0.0001  max mem: 20908
Train Epoch: [8]  [2600/4855]  eta: 1:32:29  lr: 0.000010  ml_loss: 4.6166  mi_loss: 4.0197  train_loss: 8.6363  time: 2.4780  data: 0.0001  max mem: 20908
Train Epoch: [8]  [2650/4855]  eta: 1:30:27  lr: 0.000010  ml_loss: 4.3634  mi_loss: 4.1681  train_loss: 8.5315  time: 2.4886  data: 0.0002  max mem: 20908
Train Epoch: [8]  [2700/4855]  eta: 1:28:25  lr: 0.000010  ml_loss: 5.0587  mi_loss: 3.7046  train_loss: 8.7632  time: 2.4903  data: 0.0001  max mem: 20908
Train Epoch: [8]  [2750/4855]  eta: 1:26:23  lr: 0.000010  ml_loss: 5.3174  mi_loss: 4.1244  train_loss: 9.4418  time: 2.4990  data: 0.0001  max mem: 20908
Train Epoch: [8]  [2800/4855]  eta: 1:24:20  lr: 0.000010  ml_loss: 5.0870  mi_loss: 3.4878  train_loss: 8.5748  time: 2.4580  data: 0.0001  max mem: 20908
Train Epoch: [8]  [2850/4855]  eta: 1:22:18  lr: 0.000010  ml_loss: 5.3500  mi_loss: 4.5520  train_loss: 9.9020  time: 2.4914  data: 0.0001  max mem: 20908
Train Epoch: [8]  [2900/4855]  eta: 1:20:15  lr: 0.000010  ml_loss: 4.8125  mi_loss: 4.3345  train_loss: 9.1470  time: 2.4743  data: 0.0001  max mem: 20908
Train Epoch: [8]  [2950/4855]  eta: 1:18:12  lr: 0.000010  ml_loss: 5.1805  mi_loss: 3.9437  train_loss: 9.1242  time: 2.4464  data: 0.0001  max mem: 20908
Train Epoch: [8]  [3000/4855]  eta: 1:16:09  lr: 0.000010  ml_loss: 5.1211  mi_loss: 4.2713  train_loss: 9.3924  time: 2.4959  data: 0.0001  max mem: 20908
Train Epoch: [8]  [3050/4855]  eta: 1:14:07  lr: 0.000010  ml_loss: 4.7841  mi_loss: 4.1044  train_loss: 8.8886  time: 2.4958  data: 0.0001  max mem: 20908
Train Epoch: [8]  [3100/4855]  eta: 1:12:04  lr: 0.000010  ml_loss: 4.7508  mi_loss: 3.7779  train_loss: 8.5287  time: 2.4668  data: 0.0001  max mem: 20908
Train Epoch: [8]  [3150/4855]  eta: 1:10:01  lr: 0.000010  ml_loss: 3.6657  mi_loss: 4.1462  train_loss: 7.8119  time: 2.4826  data: 0.0001  max mem: 20908
Train Epoch: [8]  [3200/4855]  eta: 1:07:58  lr: 0.000010  ml_loss: 5.0642  mi_loss: 4.2309  train_loss: 9.2952  time: 2.4792  data: 0.0001  max mem: 20908
Train Epoch: [8]  [3250/4855]  eta: 1:05:56  lr: 0.000010  ml_loss: 4.6338  mi_loss: 4.1097  train_loss: 8.7435  time: 2.4781  data: 0.0001  max mem: 20908
Train Epoch: [8]  [3300/4855]  eta: 1:03:53  lr: 0.000010  ml_loss: 5.0752  mi_loss: 4.7137  train_loss: 9.7889  time: 2.4756  data: 0.0001  max mem: 20908
Train Epoch: [8]  [3350/4855]  eta: 1:01:49  lr: 0.000010  ml_loss: 4.9627  mi_loss: 3.1567  train_loss: 8.1194  time: 2.4651  data: 0.0001  max mem: 20908
Train Epoch: [8]  [3400/4855]  eta: 0:59:46  lr: 0.000010  ml_loss: 4.9795  mi_loss: 4.2020  train_loss: 9.1815  time: 2.4752  data: 0.0001  max mem: 20908
Train Epoch: [8]  [3450/4855]  eta: 0:57:43  lr: 0.000010  ml_loss: 5.4251  mi_loss: 3.4160  train_loss: 8.8411  time: 2.4445  data: 0.0001  max mem: 20908
Train Epoch: [8]  [3500/4855]  eta: 0:55:39  lr: 0.000010  ml_loss: 4.5909  mi_loss: 3.7724  train_loss: 8.3633  time: 2.4570  data: 0.0001  max mem: 20908
Train Epoch: [8]  [3550/4855]  eta: 0:53:35  lr: 0.000010  ml_loss: 4.9077  mi_loss: 4.0655  train_loss: 8.9731  time: 2.4463  data: 0.0002  max mem: 20908
Train Epoch: [8]  [3600/4855]  eta: 0:51:32  lr: 0.000010  ml_loss: 4.9245  mi_loss: 4.3775  train_loss: 9.3021  time: 2.4303  data: 0.0001  max mem: 20908
Train Epoch: [8]  [3650/4855]  eta: 0:49:28  lr: 0.000010  ml_loss: 5.0785  mi_loss: 4.5797  train_loss: 9.6581  time: 2.4584  data: 0.0001  max mem: 20908
Train Epoch: [8]  [3700/4855]  eta: 0:47:25  lr: 0.000010  ml_loss: 5.5481  mi_loss: 4.2170  train_loss: 9.7652  time: 2.4704  data: 0.0002  max mem: 20908
Train Epoch: [8]  [3750/4855]  eta: 0:45:22  lr: 0.000010  ml_loss: 5.1882  mi_loss: 4.1600  train_loss: 9.3482  time: 2.4734  data: 0.0001  max mem: 20908
Train Epoch: [8]  [3800/4855]  eta: 0:43:19  lr: 0.000010  ml_loss: 4.6585  mi_loss: 3.6466  train_loss: 8.3051  time: 2.4476  data: 0.0001  max mem: 20908
Train Epoch: [8]  [3850/4855]  eta: 0:41:15  lr: 0.000010  ml_loss: 4.8529  mi_loss: 3.9959  train_loss: 8.8487  time: 2.4522  data: 0.0002  max mem: 20908
Train Epoch: [8]  [3900/4855]  eta: 0:39:12  lr: 0.000010  ml_loss: 5.0512  mi_loss: 4.2338  train_loss: 9.2850  time: 2.4092  data: 0.0001  max mem: 20908
Train Epoch: [8]  [3950/4855]  eta: 0:37:08  lr: 0.000010  ml_loss: 5.1540  mi_loss: 4.1078  train_loss: 9.2618  time: 2.4344  data: 0.0001  max mem: 20908
Train Epoch: [8]  [4000/4855]  eta: 0:35:05  lr: 0.000010  ml_loss: 5.4583  mi_loss: 4.0850  train_loss: 9.5432  time: 2.4356  data: 0.0001  max mem: 20908
Train Epoch: [8]  [4050/4855]  eta: 0:33:01  lr: 0.000010  ml_loss: 5.1916  mi_loss: 4.0007  train_loss: 9.1923  time: 2.4236  data: 0.0001  max mem: 20908
Train Epoch: [8]  [4100/4855]  eta: 0:30:58  lr: 0.000010  ml_loss: 5.0239  mi_loss: 4.1335  train_loss: 9.1573  time: 2.4391  data: 0.0001  max mem: 20908
Train Epoch: [8]  [4150/4855]  eta: 0:28:55  lr: 0.000010  ml_loss: 4.9884  mi_loss: 4.3956  train_loss: 9.3841  time: 2.4303  data: 0.0001  max mem: 20908
Train Epoch: [8]  [4200/4855]  eta: 0:26:51  lr: 0.000010  ml_loss: 5.0205  mi_loss: 4.3173  train_loss: 9.3378  time: 2.4171  data: 0.0001  max mem: 20908
Train Epoch: [8]  [4250/4855]  eta: 0:24:48  lr: 0.000010  ml_loss: 5.3254  mi_loss: 4.5236  train_loss: 9.8490  time: 2.4071  data: 0.0002  max mem: 20908
Train Epoch: [8]  [4300/4855]  eta: 0:22:44  lr: 0.000010  ml_loss: 5.0285  mi_loss: 4.1182  train_loss: 9.1467  time: 2.4095  data: 0.0001  max mem: 20908
Train Epoch: [8]  [4350/4855]  eta: 0:20:41  lr: 0.000010  ml_loss: 5.5057  mi_loss: 3.8874  train_loss: 9.3931  time: 2.4195  data: 0.0001  max mem: 20908
Train Epoch: [8]  [4400/4855]  eta: 0:18:38  lr: 0.000010  ml_loss: 5.6176  mi_loss: 4.2053  train_loss: 9.8229  time: 2.4354  data: 0.0001  max mem: 20908
Train Epoch: [8]  [4450/4855]  eta: 0:16:35  lr: 0.000010  ml_loss: 5.1721  mi_loss: 4.2049  train_loss: 9.3771  time: 2.4057  data: 0.0001  max mem: 20908
Train Epoch: [8]  [4500/4855]  eta: 0:14:32  lr: 0.000010  ml_loss: 5.5730  mi_loss: 3.8925  train_loss: 9.4655  time: 2.4195  data: 0.0001  max mem: 20908
Train Epoch: [8]  [4550/4855]  eta: 0:12:29  lr: 0.000010  ml_loss: 5.0383  mi_loss: 4.2663  train_loss: 9.3046  time: 2.4148  data: 0.0001  max mem: 20908
Train Epoch: [8]  [4600/4855]  eta: 0:10:26  lr: 0.000010  ml_loss: 4.3790  mi_loss: 3.9324  train_loss: 8.3114  time: 2.4439  data: 0.0001  max mem: 20908
Train Epoch: [8]  [4650/4855]  eta: 0:08:23  lr: 0.000010  ml_loss: 5.0287  mi_loss: 4.3220  train_loss: 9.3506  time: 2.4314  data: 0.0001  max mem: 20908
Train Epoch: [8]  [4700/4855]  eta: 0:06:20  lr: 0.000010  ml_loss: 5.5516  mi_loss: 3.6323  train_loss: 9.1839  time: 2.4309  data: 0.0001  max mem: 20908
Train Epoch: [8]  [4750/4855]  eta: 0:04:17  lr: 0.000010  ml_loss: 5.0125  mi_loss: 4.0800  train_loss: 9.0926  time: 2.4410  data: 0.0001  max mem: 20908
Train Epoch: [8]  [4800/4855]  eta: 0:02:15  lr: 0.000010  ml_loss: 4.8877  mi_loss: 4.1171  train_loss: 9.0048  time: 2.4311  data: 0.0001  max mem: 20908
Train Epoch: [8]  [4850/4855]  eta: 0:00:12  lr: 0.000010  ml_loss: 5.4048  mi_loss: 3.7660  train_loss: 9.1708  time: 2.4187  data: 0.0001  max mem: 20908
Train Epoch: [8]  [4854/4855]  eta: 0:00:02  lr: 0.000010  ml_loss: 4.7413  mi_loss: 4.4171  train_loss: 9.1584  time: 2.4209  data: 0.0007  max mem: 20908
Train Epoch: [8] Total time: 3:18:45 (2.4563 s / it)
Val Epoch: [8]  [  0/540]  eta: 0:24:24  ml_loss: 5.1065  mi_loss: 4.1829  val_loss: 9.2894  accML: 0.2173  accMI: 0.1108  time: 2.7121  data: 2.3302  max mem: 20908
Val Epoch: [8]  [ 50/540]  eta: 0:06:34  ml_loss: 5.0626  mi_loss: 3.8501  val_loss: 8.9126  accML: 0.2539  accMI: 0.1957  time: 0.7840  data: 0.6224  max mem: 20908
Val Epoch: [8]  [100/540]  eta: 0:05:52  ml_loss: 4.7821  mi_loss: 4.3575  val_loss: 9.1395  accML: 0.2521  accMI: 0.1493  time: 0.7598  data: 0.5973  max mem: 20908
Val Epoch: [8]  [150/540]  eta: 0:05:22  ml_loss: 5.2737  mi_loss: 4.4920  val_loss: 9.7656  accML: 0.1924  accMI: 0.1132  time: 0.9286  data: 0.7651  max mem: 20908
Val Epoch: [8]  [200/540]  eta: 0:04:42  ml_loss: 5.0896  mi_loss: 4.5040  val_loss: 9.5937  accML: 0.2300  accMI: 0.0856  time: 0.8377  data: 0.6750  max mem: 20908
Val Epoch: [8]  [250/540]  eta: 0:03:59  ml_loss: 4.6939  mi_loss: 3.9336  val_loss: 8.6275  accML: 0.2762  accMI: 0.1630  time: 0.8456  data: 0.6830  max mem: 20908
Val Epoch: [8]  [300/540]  eta: 0:03:18  ml_loss: 4.6040  mi_loss: 3.9159  val_loss: 8.5199  accML: 0.2719  accMI: 0.1855  time: 0.8512  data: 0.6879  max mem: 20908
Val Epoch: [8]  [350/540]  eta: 0:02:36  ml_loss: 4.8307  mi_loss: 3.2108  val_loss: 8.0415  accML: 0.2689  accMI: 0.2907  time: 0.7904  data: 0.6280  max mem: 20908
Val Epoch: [8]  [400/540]  eta: 0:01:56  ml_loss: 5.4735  mi_loss: 4.3314  val_loss: 9.8049  accML: 0.1924  accMI: 0.1102  time: 0.8655  data: 0.7023  max mem: 20908
Val Epoch: [8]  [450/540]  eta: 0:01:14  ml_loss: 5.3490  mi_loss: 4.0750  val_loss: 9.4240  accML: 0.2130  accMI: 0.1360  time: 0.8467  data: 0.6843  max mem: 20908
Val Epoch: [8]  [500/540]  eta: 0:00:33  ml_loss: 5.3423  mi_loss: 3.9637  val_loss: 9.3060  accML: 0.2215  accMI: 0.1622  time: 0.7673  data: 0.6049  max mem: 20908
Val Epoch: [8]  [539/540]  eta: 0:00:00  ml_loss: 5.3392  mi_loss: 4.0728  val_loss: 9.4120  accML: 0.1914  accMI: 0.1622  time: 0.7784  data: 0.6181  max mem: 20908
Val Epoch: [8] Total time: 0:07:30 (0.8345 s / it)
epoch:8, iter:43694, 4854,  train_loss: 9.15838623046875, valid_loss: 9.080058382175586, idiv_loss:(4.967128839316191, 4.112929532263014), acc:(0.23934347204588077, 0.15356532678146054)
Averaged stats: lr: 0.0000  ml_loss: 5.0209  mi_loss: 4.1786  train_loss: 9.1995
epoch 8 9.15838623046875
Train Epoch: [9]  [   0/4855]  eta: 7:20:35  lr: 0.000010  ml_loss: 5.0583  mi_loss: 4.1208  train_loss: 9.1790  time: 5.4450  data: 2.9817  max mem: 20908
Train Epoch: [9]  [  50/4855]  eta: 3:20:27  lr: 0.000010  ml_loss: 5.4841  mi_loss: 3.7032  train_loss: 9.1873  time: 2.4464  data: 0.0001  max mem: 20908
Train Epoch: [9]  [ 100/4855]  eta: 3:15:29  lr: 0.000010  ml_loss: 4.8861  mi_loss: 3.7151  train_loss: 8.6012  time: 2.4309  data: 0.0001  max mem: 20908
Train Epoch: [9]  [ 150/4855]  eta: 3:12:38  lr: 0.000010  ml_loss: 5.1360  mi_loss: 3.9198  train_loss: 9.0558  time: 2.4420  data: 0.0001  max mem: 20908
Train Epoch: [9]  [ 200/4855]  eta: 3:10:18  lr: 0.000010  ml_loss: 4.5884  mi_loss: 3.5639  train_loss: 8.1523  time: 2.4579  data: 0.0001  max mem: 20908
Train Epoch: [9]  [ 250/4855]  eta: 3:08:01  lr: 0.000010  ml_loss: 4.7171  mi_loss: 3.9823  train_loss: 8.6994  time: 2.4417  data: 0.0001  max mem: 20908
Train Epoch: [9]  [ 300/4855]  eta: 3:05:51  lr: 0.000010  ml_loss: 5.1109  mi_loss: 4.3489  train_loss: 9.4598  time: 2.4364  data: 0.0001  max mem: 20908
Train Epoch: [9]  [ 350/4855]  eta: 3:03:26  lr: 0.000010  ml_loss: 5.5516  mi_loss: 3.9309  train_loss: 9.4825  time: 2.3991  data: 0.0001  max mem: 20908
Train Epoch: [9]  [ 400/4855]  eta: 3:01:10  lr: 0.000010  ml_loss: 4.7185  mi_loss: 4.0652  train_loss: 8.7837  time: 2.4133  data: 0.0001  max mem: 20908
Train Epoch: [9]  [ 450/4855]  eta: 2:59:01  lr: 0.000010  ml_loss: 5.1489  mi_loss: 4.2204  train_loss: 9.3693  time: 2.4144  data: 0.0001  max mem: 20908
Train Epoch: [9]  [ 500/4855]  eta: 2:56:59  lr: 0.000010  ml_loss: 5.1490  mi_loss: 3.7407  train_loss: 8.8897  time: 2.4257  data: 0.0001  max mem: 20908
Train Epoch: [9]  [ 550/4855]  eta: 2:54:56  lr: 0.000010  ml_loss: 5.2624  mi_loss: 4.1374  train_loss: 9.3998  time: 2.4134  data: 0.0001  max mem: 20908
Train Epoch: [9]  [ 600/4855]  eta: 2:52:50  lr: 0.000010  ml_loss: 4.8044  mi_loss: 3.7684  train_loss: 8.5727  time: 2.4285  data: 0.0001  max mem: 20908
Train Epoch: [9]  [ 650/4855]  eta: 2:50:40  lr: 0.000010  ml_loss: 4.2983  mi_loss: 4.0085  train_loss: 8.3068  time: 2.4160  data: 0.0001  max mem: 20908
Train Epoch: [9]  [ 700/4855]  eta: 2:48:39  lr: 0.000010  ml_loss: 5.2929  mi_loss: 4.3394  train_loss: 9.6322  time: 2.4365  data: 0.0001  max mem: 20908
Train Epoch: [9]  [ 750/4855]  eta: 2:46:41  lr: 0.000010  ml_loss: 5.2335  mi_loss: 4.2591  train_loss: 9.4926  time: 2.4476  data: 0.0001  max mem: 20908
Train Epoch: [9]  [ 800/4855]  eta: 2:44:35  lr: 0.000010  ml_loss: 5.1783  mi_loss: 4.0278  train_loss: 9.2062  time: 2.4354  data: 0.0001  max mem: 20908
Train Epoch: [9]  [ 850/4855]  eta: 2:42:37  lr: 0.000010  ml_loss: 4.5817  mi_loss: 3.6573  train_loss: 8.2389  time: 2.4516  data: 0.0001  max mem: 20908
Train Epoch: [9]  [ 900/4855]  eta: 2:40:36  lr: 0.000010  ml_loss: 4.5688  mi_loss: 3.7295  train_loss: 8.2984  time: 2.4455  data: 0.0001  max mem: 20908
Train Epoch: [9]  [ 950/4855]  eta: 2:38:33  lr: 0.000010  ml_loss: 4.8027  mi_loss: 3.9025  train_loss: 8.7052  time: 2.4265  data: 0.0001  max mem: 20908
Train Epoch: [9]  [1000/4855]  eta: 2:36:33  lr: 0.000010  ml_loss: 5.1893  mi_loss: 4.1734  train_loss: 9.3626  time: 2.4516  data: 0.0001  max mem: 20908
Train Epoch: [9]  [1050/4855]  eta: 2:34:37  lr: 0.000010  ml_loss: 5.5868  mi_loss: 4.0094  train_loss: 9.5962  time: 2.4732  data: 0.0001  max mem: 20908
Train Epoch: [9]  [1100/4855]  eta: 2:32:39  lr: 0.000010  ml_loss: 5.1777  mi_loss: 4.2130  train_loss: 9.3906  time: 2.4724  data: 0.0002  max mem: 20908
Train Epoch: [9]  [1150/4855]  eta: 2:30:43  lr: 0.000010  ml_loss: 5.0607  mi_loss: 3.7713  train_loss: 8.8320  time: 2.4753  data: 0.0001  max mem: 20908
Train Epoch: [9]  [1200/4855]  eta: 2:28:43  lr: 0.000010  ml_loss: 5.2363  mi_loss: 4.0473  train_loss: 9.2836  time: 2.4285  data: 0.0001  max mem: 20908
Train Epoch: [9]  [1250/4855]  eta: 2:26:44  lr: 0.000010  ml_loss: 4.9488  mi_loss: 4.0567  train_loss: 9.0055  time: 2.4606  data: 0.0001  max mem: 20908
Train Epoch: [9]  [1300/4855]  eta: 2:24:45  lr: 0.000010  ml_loss: 5.3857  mi_loss: 4.2828  train_loss: 9.6685  time: 2.4660  data: 0.0001  max mem: 20908
Train Epoch: [9]  [1350/4855]  eta: 2:22:45  lr: 0.000010  ml_loss: 5.1469  mi_loss: 3.8099  train_loss: 8.9568  time: 2.4436  data: 0.0001  max mem: 20908
Train Epoch: [9]  [1400/4855]  eta: 2:20:46  lr: 0.000010  ml_loss: 4.3840  mi_loss: 3.8108  train_loss: 8.1948  time: 2.4594  data: 0.0001  max mem: 20908
Train Epoch: [9]  [1450/4855]  eta: 2:18:45  lr: 0.000010  ml_loss: 5.4681  mi_loss: 4.5244  train_loss: 9.9925  time: 2.4396  data: 0.0001  max mem: 20908
Train Epoch: [9]  [1500/4855]  eta: 2:16:42  lr: 0.000010  ml_loss: 5.2407  mi_loss: 3.8850  train_loss: 9.1257  time: 2.4390  data: 0.0001  max mem: 20908
Train Epoch: [9]  [1550/4855]  eta: 2:14:41  lr: 0.000010  ml_loss: 5.0576  mi_loss: 4.4548  train_loss: 9.5123  time: 2.4625  data: 0.0001  max mem: 20908
Train Epoch: [9]  [1600/4855]  eta: 2:12:40  lr: 0.000010  ml_loss: 4.0743  mi_loss: 4.2721  train_loss: 8.3464  time: 2.4529  data: 0.0001  max mem: 20908
Train Epoch: [9]  [1650/4855]  eta: 2:10:40  lr: 0.000010  ml_loss: 5.2728  mi_loss: 4.4429  train_loss: 9.7157  time: 2.4736  data: 0.0001  max mem: 20908
Train Epoch: [9]  [1700/4855]  eta: 2:08:37  lr: 0.000010  ml_loss: 5.2985  mi_loss: 3.9319  train_loss: 9.2304  time: 2.4330  data: 0.0001  max mem: 20908
Train Epoch: [9]  [1750/4855]  eta: 2:06:36  lr: 0.000010  ml_loss: 4.7154  mi_loss: 3.9299  train_loss: 8.6454  time: 2.4492  data: 0.0001  max mem: 20908
Train Epoch: [9]  [1800/4855]  eta: 2:04:35  lr: 0.000010  ml_loss: 4.9144  mi_loss: 4.1435  train_loss: 9.0579  time: 2.4651  data: 0.0001  max mem: 20908
Train Epoch: [9]  [1850/4855]  eta: 2:02:34  lr: 0.000010  ml_loss: 5.1455  mi_loss: 4.4969  train_loss: 9.6424  time: 2.4488  data: 0.0001  max mem: 20908
Train Epoch: [9]  [1900/4855]  eta: 2:00:32  lr: 0.000010  ml_loss: 4.5811  mi_loss: 3.8391  train_loss: 8.4202  time: 2.4575  data: 0.0001  max mem: 20908
Train Epoch: [9]  [1950/4855]  eta: 1:58:31  lr: 0.000010  ml_loss: 4.8512  mi_loss: 3.8138  train_loss: 8.6650  time: 2.4549  data: 0.0001  max mem: 20908
Train Epoch: [9]  [2000/4855]  eta: 1:56:29  lr: 0.000010  ml_loss: 4.8811  mi_loss: 3.8349  train_loss: 8.7159  time: 2.4516  data: 0.0001  max mem: 20908
Train Epoch: [9]  [2050/4855]  eta: 1:54:26  lr: 0.000010  ml_loss: 5.1757  mi_loss: 4.0963  train_loss: 9.2720  time: 2.4391  data: 0.0001  max mem: 20908
Train Epoch: [9]  [2100/4855]  eta: 1:52:24  lr: 0.000010  ml_loss: 4.9622  mi_loss: 4.4473  train_loss: 9.4095  time: 2.4759  data: 0.0001  max mem: 20908
Train Epoch: [9]  [2150/4855]  eta: 1:50:21  lr: 0.000010  ml_loss: 5.2657  mi_loss: 4.5070  train_loss: 9.7727  time: 2.4408  data: 0.0001  max mem: 20908
Train Epoch: [9]  [2200/4855]  eta: 1:48:20  lr: 0.000010  ml_loss: 5.5480  mi_loss: 4.2821  train_loss: 9.8301  time: 2.4603  data: 0.0001  max mem: 20908
Train Epoch: [9]  [2250/4855]  eta: 1:46:18  lr: 0.000010  ml_loss: 4.4542  mi_loss: 4.1551  train_loss: 8.6092  time: 2.4481  data: 0.0001  max mem: 20908
Train Epoch: [9]  [2300/4855]  eta: 1:44:16  lr: 0.000010  ml_loss: 5.3067  mi_loss: 4.3729  train_loss: 9.6796  time: 2.4442  data: 0.0001  max mem: 20908
Train Epoch: [9]  [2350/4855]  eta: 1:42:14  lr: 0.000010  ml_loss: 4.4743  mi_loss: 3.8390  train_loss: 8.3133  time: 2.4291  data: 0.0001  max mem: 20908
Train Epoch: [9]  [2400/4855]  eta: 1:40:12  lr: 0.000010  ml_loss: 5.1219  mi_loss: 4.2512  train_loss: 9.3731  time: 2.4656  data: 0.0001  max mem: 20908
Train Epoch: [9]  [2450/4855]  eta: 1:38:10  lr: 0.000010  ml_loss: 5.4614  mi_loss: 4.3476  train_loss: 9.8091  time: 2.4740  data: 0.0001  max mem: 20908
Train Epoch: [9]  [2500/4855]  eta: 1:36:09  lr: 0.000010  ml_loss: 5.5037  mi_loss: 3.8374  train_loss: 9.3411  time: 2.4642  data: 0.0001  max mem: 20908
Train Epoch: [9]  [2550/4855]  eta: 1:34:06  lr: 0.000010  ml_loss: 5.1086  mi_loss: 4.1475  train_loss: 9.2561  time: 2.4350  data: 0.0001  max mem: 20908
Train Epoch: [9]  [2600/4855]  eta: 1:32:03  lr: 0.000010  ml_loss: 4.4668  mi_loss: 4.2221  train_loss: 8.6889  time: 2.4485  data: 0.0001  max mem: 20908
Train Epoch: [9]  [2650/4855]  eta: 1:30:00  lr: 0.000010  ml_loss: 5.1025  mi_loss: 3.7892  train_loss: 8.8917  time: 2.4460  data: 0.0001  max mem: 20908
Train Epoch: [9]  [2700/4855]  eta: 1:27:59  lr: 0.000010  ml_loss: 5.5065  mi_loss: 4.2020  train_loss: 9.7084  time: 2.4713  data: 0.0001  max mem: 20908
Train Epoch: [9]  [2750/4855]  eta: 1:25:56  lr: 0.000010  ml_loss: 5.3406  mi_loss: 3.8496  train_loss: 9.1902  time: 2.4761  data: 0.0001  max mem: 20908
Train Epoch: [9]  [2800/4855]  eta: 1:23:54  lr: 0.000010  ml_loss: 5.1293  mi_loss: 4.3416  train_loss: 9.4709  time: 2.4337  data: 0.0001  max mem: 20908
Train Epoch: [9]  [2850/4855]  eta: 1:21:51  lr: 0.000010  ml_loss: 4.5790  mi_loss: 4.0822  train_loss: 8.6612  time: 2.4437  data: 0.0001  max mem: 20908
Train Epoch: [9]  [2900/4855]  eta: 1:19:48  lr: 0.000010  ml_loss: 5.5071  mi_loss: 4.5903  train_loss: 10.0974  time: 2.4151  data: 0.0001  max mem: 20908
Train Epoch: [9]  [2950/4855]  eta: 1:17:45  lr: 0.000010  ml_loss: 4.7918  mi_loss: 4.3741  train_loss: 9.1659  time: 2.4451  data: 0.0001  max mem: 20908
Train Epoch: [9]  [3000/4855]  eta: 1:15:42  lr: 0.000010  ml_loss: 3.7978  mi_loss: 4.5445  train_loss: 8.3422  time: 2.4401  data: 0.0001  max mem: 20908
Train Epoch: [9]  [3050/4855]  eta: 1:13:39  lr: 0.000010  ml_loss: 5.0697  mi_loss: 4.3025  train_loss: 9.3722  time: 2.4187  data: 0.0001  max mem: 20908
Train Epoch: [9]  [3100/4855]  eta: 1:11:35  lr: 0.000010  ml_loss: 5.1100  mi_loss: 4.2257  train_loss: 9.3357  time: 2.4012  data: 0.0001  max mem: 20908
Train Epoch: [9]  [3150/4855]  eta: 1:09:32  lr: 0.000010  ml_loss: 4.4830  mi_loss: 4.4676  train_loss: 8.9505  time: 2.4009  data: 0.0001  max mem: 20908
Train Epoch: [9]  [3200/4855]  eta: 1:07:29  lr: 0.000010  ml_loss: 4.4812  mi_loss: 4.0105  train_loss: 8.4917  time: 2.4429  data: 0.0001  max mem: 20908
Train Epoch: [9]  [3250/4855]  eta: 1:05:26  lr: 0.000010  ml_loss: 4.8385  mi_loss: 3.9130  train_loss: 8.7515  time: 2.4024  data: 0.0001  max mem: 20908
Train Epoch: [9]  [3300/4855]  eta: 1:03:24  lr: 0.000010  ml_loss: 4.1936  mi_loss: 4.0688  train_loss: 8.2624  time: 2.4392  data: 0.0001  max mem: 20908
Train Epoch: [9]  [3350/4855]  eta: 1:01:21  lr: 0.000010  ml_loss: 4.7062  mi_loss: 4.2486  train_loss: 8.9548  time: 2.4237  data: 0.0001  max mem: 20908
Train Epoch: [9]  [3400/4855]  eta: 0:59:18  lr: 0.000010  ml_loss: 5.6355  mi_loss: 4.0793  train_loss: 9.7148  time: 2.4593  data: 0.0001  max mem: 20908
Train Epoch: [9]  [3450/4855]  eta: 0:57:15  lr: 0.000010  ml_loss: 5.3445  mi_loss: 4.3420  train_loss: 9.6864  time: 2.4430  data: 0.0001  max mem: 20908
Train Epoch: [9]  [3500/4855]  eta: 0:55:13  lr: 0.000010  ml_loss: 5.1753  mi_loss: 3.9782  train_loss: 9.1536  time: 2.4213  data: 0.0001  max mem: 20908
Train Epoch: [9]  [3550/4855]  eta: 0:53:10  lr: 0.000010  ml_loss: 4.6442  mi_loss: 3.8559  train_loss: 8.5001  time: 2.4109  data: 0.0001  max mem: 20908
Train Epoch: [9]  [3600/4855]  eta: 0:51:08  lr: 0.000010  ml_loss: 4.6107  mi_loss: 3.6346  train_loss: 8.2453  time: 2.3990  data: 0.0001  max mem: 20908
Train Epoch: [9]  [3650/4855]  eta: 0:49:05  lr: 0.000010  ml_loss: 5.1441  mi_loss: 4.3945  train_loss: 9.5386  time: 2.4229  data: 0.0001  max mem: 20908
Train Epoch: [9]  [3700/4855]  eta: 0:47:03  lr: 0.000010  ml_loss: 4.9972  mi_loss: 4.7041  train_loss: 9.7013  time: 2.4474  data: 0.0001  max mem: 20908
Train Epoch: [9]  [3750/4855]  eta: 0:45:01  lr: 0.000010  ml_loss: 5.0566  mi_loss: 4.0452  train_loss: 9.1019  time: 2.4474  data: 0.0001  max mem: 20908
Train Epoch: [9]  [3800/4855]  eta: 0:42:59  lr: 0.000010  ml_loss: 4.8498  mi_loss: 4.1511  train_loss: 9.0008  time: 2.4504  data: 0.0001  max mem: 20908
Train Epoch: [9]  [3850/4855]  eta: 0:40:56  lr: 0.000010  ml_loss: 5.1355  mi_loss: 3.6640  train_loss: 8.7994  time: 2.4025  data: 0.0001  max mem: 20908
Train Epoch: [9]  [3900/4855]  eta: 0:38:54  lr: 0.000010  ml_loss: 5.7929  mi_loss: 4.3265  train_loss: 10.1194  time: 2.4489  data: 0.0001  max mem: 20908
Train Epoch: [9]  [3950/4855]  eta: 0:36:51  lr: 0.000010  ml_loss: 4.1228  mi_loss: 4.7830  train_loss: 8.9058  time: 2.4094  data: 0.0001  max mem: 20908
Train Epoch: [9]  [4000/4855]  eta: 0:34:49  lr: 0.000010  ml_loss: 4.3656  mi_loss: 4.1631  train_loss: 8.5287  time: 2.4294  data: 0.0001  max mem: 20908
Train Epoch: [9]  [4050/4855]  eta: 0:32:47  lr: 0.000010  ml_loss: 5.5786  mi_loss: 4.3268  train_loss: 9.9053  time: 2.4314  data: 0.0001  max mem: 20908
Train Epoch: [9]  [4100/4855]  eta: 0:30:44  lr: 0.000010  ml_loss: 4.8609  mi_loss: 4.5717  train_loss: 9.4326  time: 2.4220  data: 0.0001  max mem: 20908
Train Epoch: [9]  [4150/4855]  eta: 0:28:42  lr: 0.000010  ml_loss: 4.3080  mi_loss: 4.3216  train_loss: 8.6296  time: 2.4440  data: 0.0001  max mem: 20908
Train Epoch: [9]  [4200/4855]  eta: 0:26:40  lr: 0.000010  ml_loss: 4.9381  mi_loss: 3.9607  train_loss: 8.8988  time: 2.4460  data: 0.0001  max mem: 20908
Train Epoch: [9]  [4250/4855]  eta: 0:24:38  lr: 0.000010  ml_loss: 4.9785  mi_loss: 4.3217  train_loss: 9.3002  time: 2.4457  data: 0.0001  max mem: 20908
Train Epoch: [9]  [4300/4855]  eta: 0:22:36  lr: 0.000010  ml_loss: 5.3048  mi_loss: 4.6008  train_loss: 9.9056  time: 2.4457  data: 0.0001  max mem: 20908
Train Epoch: [9]  [4350/4855]  eta: 0:20:33  lr: 0.000010  ml_loss: 5.1677  mi_loss: 3.6163  train_loss: 8.7839  time: 2.4106  data: 0.0001  max mem: 20908
Train Epoch: [9]  [4400/4855]  eta: 0:18:31  lr: 0.000010  ml_loss: 5.0315  mi_loss: 3.9562  train_loss: 8.9877  time: 2.4166  data: 0.0001  max mem: 20908
Train Epoch: [9]  [4450/4855]  eta: 0:16:29  lr: 0.000010  ml_loss: 4.4665  mi_loss: 4.3085  train_loss: 8.7750  time: 2.4094  data: 0.0001  max mem: 20908
Train Epoch: [9]  [4500/4855]  eta: 0:14:27  lr: 0.000010  ml_loss: 5.7533  mi_loss: 3.7572  train_loss: 9.5105  time: 2.4298  data: 0.0001  max mem: 20908
Train Epoch: [9]  [4550/4855]  eta: 0:12:24  lr: 0.000010  ml_loss: 4.4707  mi_loss: 3.9859  train_loss: 8.4567  time: 2.4422  data: 0.0001  max mem: 20908
Train Epoch: [9]  [4600/4855]  eta: 0:10:22  lr: 0.000010  ml_loss: 5.0323  mi_loss: 3.9111  train_loss: 8.9434  time: 2.4330  data: 0.0001  max mem: 20908
Train Epoch: [9]  [4650/4855]  eta: 0:08:20  lr: 0.000010  ml_loss: 4.7444  mi_loss: 4.2099  train_loss: 8.9543  time: 2.4153  data: 0.0001  max mem: 20908
Train Epoch: [9]  [4700/4855]  eta: 0:06:18  lr: 0.000010  ml_loss: 4.7233  mi_loss: 4.0992  train_loss: 8.8225  time: 2.4479  data: 0.0001  max mem: 20908
Train Epoch: [9]  [4750/4855]  eta: 0:04:16  lr: 0.000010  ml_loss: 4.5741  mi_loss: 3.9416  train_loss: 8.5157  time: 2.4286  data: 0.0001  max mem: 20908
Train Epoch: [9]  [4800/4855]  eta: 0:02:14  lr: 0.000010  ml_loss: 4.5347  mi_loss: 4.2473  train_loss: 8.7820  time: 2.4568  data: 0.0001  max mem: 20908
Train Epoch: [9]  [4850/4855]  eta: 0:00:12  lr: 0.000010  ml_loss: 4.9413  mi_loss: 3.9065  train_loss: 8.8478  time: 2.4835  data: 0.0001  max mem: 20908
Train Epoch: [9]  [4854/4855]  eta: 0:00:02  lr: 0.000010  ml_loss: 4.8895  mi_loss: 4.0481  train_loss: 8.9376  time: 2.4857  data: 0.0010  max mem: 20908
Train Epoch: [9] Total time: 3:17:38 (2.4425 s / it)
Val Epoch: [9]  [  0/540]  eta: 0:28:26  ml_loss: 5.0771  mi_loss: 4.1783  val_loss: 9.2554  accML: 0.2251  accMI: 0.1189  time: 3.1607  data: 2.7715  max mem: 20908
Val Epoch: [9]  [ 50/540]  eta: 0:08:00  ml_loss: 4.8791  mi_loss: 3.8401  val_loss: 8.7191  accML: 0.2452  accMI: 0.2011  time: 0.8782  data: 0.7166  max mem: 20908
Val Epoch: [9]  [100/540]  eta: 0:06:37  ml_loss: 4.8325  mi_loss: 4.3704  val_loss: 9.2029  accML: 0.2621  accMI: 0.1573  time: 0.7846  data: 0.6225  max mem: 20908
Val Epoch: [9]  [150/540]  eta: 0:05:51  ml_loss: 4.8633  mi_loss: 4.5483  val_loss: 9.4116  accML: 0.2491  accMI: 0.1186  time: 0.9400  data: 0.7766  max mem: 20908
Val Epoch: [9]  [200/540]  eta: 0:05:03  ml_loss: 5.1096  mi_loss: 4.4046  val_loss: 9.5142  accML: 0.2033  accMI: 0.1203  time: 0.8641  data: 0.7015  max mem: 20908
Val Epoch: [9]  [250/540]  eta: 0:04:15  ml_loss: 4.7707  mi_loss: 3.9075  val_loss: 8.6782  accML: 0.2739  accMI: 0.1712  time: 0.8644  data: 0.7018  max mem: 20908
Val Epoch: [9]  [300/540]  eta: 0:03:30  ml_loss: 4.6141  mi_loss: 3.8861  val_loss: 8.5001  accML: 0.2457  accMI: 0.1882  time: 0.9153  data: 0.7523  max mem: 20908
Val Epoch: [9]  [350/540]  eta: 0:02:45  ml_loss: 4.9744  mi_loss: 3.1750  val_loss: 8.1494  accML: 0.2301  accMI: 0.2987  time: 0.8316  data: 0.6692  max mem: 20908
Val Epoch: [9]  [400/540]  eta: 0:02:02  ml_loss: 5.2992  mi_loss: 4.3471  val_loss: 9.6463  accML: 0.2490  accMI: 0.1156  time: 0.8860  data: 0.7231  max mem: 20908
Val Epoch: [9]  [450/540]  eta: 0:01:18  ml_loss: 5.2085  mi_loss: 4.0737  val_loss: 9.2822  accML: 0.2192  accMI: 0.1280  time: 0.8806  data: 0.7176  max mem: 20908
Val Epoch: [9]  [500/540]  eta: 0:00:35  ml_loss: 5.3163  mi_loss: 3.8998  val_loss: 9.2161  accML: 0.2013  accMI: 0.1541  time: 0.7960  data: 0.6341  max mem: 20908
Val Epoch: [9]  [539/540]  eta: 0:00:00  ml_loss: 5.1761  mi_loss: 3.9785  val_loss: 9.1546  accML: 0.1907  accMI: 0.1892  time: 0.7776  data: 0.6180  max mem: 20908
Val Epoch: [9] Total time: 0:07:52 (0.8745 s / it)
epoch:9, iter:48549, 4854,  train_loss: 8.937592506408691, valid_loss: 8.972178038844357, idiv_loss:(4.889073898615661, 4.083104149942045), acc:(0.24510952173559755, 0.15558624159268758)
Averaged stats: lr: 0.0000  ml_loss: 4.9769  mi_loss: 4.0867  train_loss: 9.0635
./src/pretrain_mlm_mim.py:79: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure()
epoch 9 8.937592506408691
Train Epoch: [10]  [   0/4855]  eta: 7:32:18  lr: 0.000010  ml_loss: 4.9313  mi_loss: 3.4108  train_loss: 8.3421  time: 5.5899  data: 2.4170  max mem: 20908
Train Epoch: [10]  [  50/4855]  eta: 3:23:51  lr: 0.000010  ml_loss: 4.5916  mi_loss: 4.3038  train_loss: 8.8954  time: 2.4834  data: 0.0001  max mem: 20908
Train Epoch: [10]  [ 100/4855]  eta: 3:19:22  lr: 0.000010  ml_loss: 5.3872  mi_loss: 4.1151  train_loss: 9.5023  time: 2.4905  data: 0.0001  max mem: 20908
Train Epoch: [10]  [ 150/4855]  eta: 3:15:55  lr: 0.000010  ml_loss: 4.0970  mi_loss: 4.0227  train_loss: 8.1197  time: 2.4381  data: 0.0001  max mem: 20908
Train Epoch: [10]  [ 200/4855]  eta: 3:13:10  lr: 0.000010  ml_loss: 4.3133  mi_loss: 3.7936  train_loss: 8.1069  time: 2.4674  data: 0.0001  max mem: 20908
Train Epoch: [10]  [ 250/4855]  eta: 3:11:00  lr: 0.000010  ml_loss: 5.2878  mi_loss: 4.8275  train_loss: 10.1153  time: 2.4763  data: 0.0001  max mem: 20908
Train Epoch: [10]  [ 300/4855]  eta: 3:08:42  lr: 0.000010  ml_loss: 5.2690  mi_loss: 4.0829  train_loss: 9.3519  time: 2.4557  data: 0.0001  max mem: 20908
Train Epoch: [10]  [ 350/4855]  eta: 3:06:12  lr: 0.000010  ml_loss: 4.6661  mi_loss: 3.5095  train_loss: 8.1755  time: 2.4328  data: 0.0001  max mem: 20908
Train Epoch: [10]  [ 400/4855]  eta: 3:03:58  lr: 0.000010  ml_loss: 5.2481  mi_loss: 3.9737  train_loss: 9.2218  time: 2.4467  data: 0.0001  max mem: 20908
Train Epoch: [10]  [ 450/4855]  eta: 3:01:42  lr: 0.000010  ml_loss: 4.8969  mi_loss: 4.0085  train_loss: 8.9054  time: 2.4700  data: 0.0001  max mem: 20908
Train Epoch: [10]  [ 500/4855]  eta: 2:59:38  lr: 0.000010  ml_loss: 4.4449  mi_loss: 4.0840  train_loss: 8.5289  time: 2.4820  data: 0.0001  max mem: 20908
Train Epoch: [10]  [ 550/4855]  eta: 2:57:34  lr: 0.000010  ml_loss: 4.9837  mi_loss: 4.2446  train_loss: 9.2283  time: 2.4549  data: 0.0001  max mem: 20908
Train Epoch: [10]  [ 600/4855]  eta: 2:55:25  lr: 0.000010  ml_loss: 4.8345  mi_loss: 4.0120  train_loss: 8.8465  time: 2.4520  data: 0.0001  max mem: 20908
Train Epoch: [10]  [ 650/4855]  eta: 2:53:20  lr: 0.000010  ml_loss: 4.9360  mi_loss: 3.9597  train_loss: 8.8957  time: 2.4832  data: 0.0001  max mem: 20908
Train Epoch: [10]  [ 700/4855]  eta: 2:51:10  lr: 0.000010  ml_loss: 5.0143  mi_loss: 4.1331  train_loss: 9.1475  time: 2.4516  data: 0.0001  max mem: 20908
Train Epoch: [10]  [ 750/4855]  eta: 2:48:56  lr: 0.000010  ml_loss: 4.5650  mi_loss: 4.1279  train_loss: 8.6930  time: 2.4332  data: 0.0001  max mem: 20908
Train Epoch: [10]  [ 800/4855]  eta: 2:46:51  lr: 0.000010  ml_loss: 5.3839  mi_loss: 4.3276  train_loss: 9.7116  time: 2.4535  data: 0.0001  max mem: 20908
Train Epoch: [10]  [ 850/4855]  eta: 2:44:47  lr: 0.000010  ml_loss: 5.0540  mi_loss: 3.9986  train_loss: 9.0525  time: 2.4710  data: 0.0001  max mem: 20908
Train Epoch: [10]  [ 900/4855]  eta: 2:42:42  lr: 0.000010  ml_loss: 5.3115  mi_loss: 4.1316  train_loss: 9.4431  time: 2.4445  data: 0.0001  max mem: 20908
Train Epoch: [10]  [ 950/4855]  eta: 2:40:33  lr: 0.000010  ml_loss: 4.9955  mi_loss: 4.1315  train_loss: 9.1270  time: 2.4462  data: 0.0002  max mem: 20908
Train Epoch: [10]  [1000/4855]  eta: 2:38:28  lr: 0.000010  ml_loss: 4.8882  mi_loss: 3.9059  train_loss: 8.7940  time: 2.4722  data: 0.0001  max mem: 20908
Train Epoch: [10]  [1050/4855]  eta: 2:36:25  lr: 0.000010  ml_loss: 5.0363  mi_loss: 3.6478  train_loss: 8.6841  time: 2.4681  data: 0.0002  max mem: 20908
Train Epoch: [10]  [1100/4855]  eta: 2:34:21  lr: 0.000010  ml_loss: 5.2091  mi_loss: 3.7684  train_loss: 8.9774  time: 2.4515  data: 0.0001  max mem: 20908
Train Epoch: [10]  [1150/4855]  eta: 2:32:15  lr: 0.000010  ml_loss: 5.6407  mi_loss: 3.9956  train_loss: 9.6363  time: 2.4679  data: 0.0001  max mem: 20908
Train Epoch: [10]  [1200/4855]  eta: 2:30:08  lr: 0.000010  ml_loss: 4.8227  mi_loss: 4.5890  train_loss: 9.4117  time: 2.4489  data: 0.0001  max mem: 20908
Train Epoch: [10]  [1250/4855]  eta: 2:28:04  lr: 0.000010  ml_loss: 5.0656  mi_loss: 3.6766  train_loss: 8.7422  time: 2.4552  data: 0.0001  max mem: 20908
Train Epoch: [10]  [1300/4855]  eta: 2:26:00  lr: 0.000010  ml_loss: 5.1119  mi_loss: 4.0466  train_loss: 9.1585  time: 2.4727  data: 0.0002  max mem: 20908
Train Epoch: [10]  [1350/4855]  eta: 2:23:54  lr: 0.000010  ml_loss: 4.8247  mi_loss: 4.2414  train_loss: 9.0661  time: 2.4497  data: 0.0003  max mem: 20908
Train Epoch: [10]  [1400/4855]  eta: 2:21:50  lr: 0.000010  ml_loss: 4.8326  mi_loss: 3.4697  train_loss: 8.3023  time: 2.4584  data: 0.0001  max mem: 20908
Train Epoch: [10]  [1450/4855]  eta: 2:19:46  lr: 0.000010  ml_loss: 4.7222  mi_loss: 4.3285  train_loss: 9.0507  time: 2.4567  data: 0.0001  max mem: 20908
Train Epoch: [10]  [1500/4855]  eta: 2:17:42  lr: 0.000010  ml_loss: 5.2576  mi_loss: 4.1470  train_loss: 9.4046  time: 2.4643  data: 0.0001  max mem: 20908
Train Epoch: [10]  [1550/4855]  eta: 2:15:40  lr: 0.000010  ml_loss: 5.2298  mi_loss: 4.0189  train_loss: 9.2487  time: 2.4668  data: 0.0001  max mem: 20908
Train Epoch: [10]  [1600/4855]  eta: 2:13:38  lr: 0.000010  ml_loss: 5.2301  mi_loss: 4.3638  train_loss: 9.5940  time: 2.4866  data: 0.0001  max mem: 20908
Train Epoch: [10]  [1650/4855]  eta: 2:11:35  lr: 0.000010  ml_loss: 5.1723  mi_loss: 3.9964  train_loss: 9.1686  time: 2.4775  data: 0.0001  max mem: 20908
Train Epoch: [10]  [1700/4855]  eta: 2:09:32  lr: 0.000010  ml_loss: 4.6558  mi_loss: 3.8725  train_loss: 8.5283  time: 2.4807  data: 0.0001  max mem: 20908
Train Epoch: [10]  [1750/4855]  eta: 2:07:28  lr: 0.000010  ml_loss: 5.0977  mi_loss: 3.9836  train_loss: 9.0813  time: 2.4653  data: 0.0001  max mem: 20908
Train Epoch: [10]  [1800/4855]  eta: 2:05:24  lr: 0.000010  ml_loss: 4.9620  mi_loss: 3.7832  train_loss: 8.7452  time: 2.4527  data: 0.0001  max mem: 20908
Train Epoch: [10]  [1850/4855]  eta: 2:03:22  lr: 0.000010  ml_loss: 4.7972  mi_loss: 3.6990  train_loss: 8.4961  time: 2.4870  data: 0.0001  max mem: 20908
Train Epoch: [10]  [1900/4855]  eta: 2:01:21  lr: 0.000010  ml_loss: 4.8267  mi_loss: 3.5119  train_loss: 8.3386  time: 2.4982  data: 0.0001  max mem: 20908
Train Epoch: [10]  [1950/4855]  eta: 1:59:20  lr: 0.000010  ml_loss: 4.6428  mi_loss: 4.3663  train_loss: 9.0092  time: 2.5116  data: 0.0001  max mem: 20908
Train Epoch: [10]  [2000/4855]  eta: 1:57:19  lr: 0.000010  ml_loss: 3.9077  mi_loss: 3.6521  train_loss: 7.5598  time: 2.4968  data: 0.0001  max mem: 20908
Train Epoch: [10]  [2050/4855]  eta: 1:55:18  lr: 0.000010  ml_loss: 4.2040  mi_loss: 4.0274  train_loss: 8.2314  time: 2.5092  data: 0.0001  max mem: 20908
Train Epoch: [10]  [2100/4855]  eta: 1:53:15  lr: 0.000010  ml_loss: 5.4953  mi_loss: 4.0654  train_loss: 9.5608  time: 2.4707  data: 0.0001  max mem: 20908
Train Epoch: [10]  [2150/4855]  eta: 1:51:14  lr: 0.000010  ml_loss: 4.9549  mi_loss: 3.9992  train_loss: 8.9542  time: 2.5099  data: 0.0001  max mem: 20908
Train Epoch: [10]  [2200/4855]  eta: 1:49:13  lr: 0.000010  ml_loss: 5.2763  mi_loss: 3.8829  train_loss: 9.1593  time: 2.5019  data: 0.0002  max mem: 20908
Train Epoch: [10]  [2250/4855]  eta: 1:47:11  lr: 0.000010  ml_loss: 4.7664  mi_loss: 3.6871  train_loss: 8.4535  time: 2.4976  data: 0.0002  max mem: 20908
Train Epoch: [10]  [2300/4855]  eta: 1:45:08  lr: 0.000010  ml_loss: 4.9104  mi_loss: 4.2521  train_loss: 9.1625  time: 2.4670  data: 0.0001  max mem: 20908
Train Epoch: [10]  [2350/4855]  eta: 1:43:04  lr: 0.000010  ml_loss: 5.1103  mi_loss: 3.9157  train_loss: 9.0260  time: 2.4650  data: 0.0001  max mem: 20908
Train Epoch: [10]  [2400/4855]  eta: 1:41:00  lr: 0.000010  ml_loss: 5.0672  mi_loss: 4.2051  train_loss: 9.2723  time: 2.4590  data: 0.0001  max mem: 20908
Train Epoch: [10]  [2450/4855]  eta: 1:38:58  lr: 0.000010  ml_loss: 5.3293  mi_loss: 4.2324  train_loss: 9.5617  time: 2.4741  data: 0.0001  max mem: 20908
Train Epoch: [10]  [2500/4855]  eta: 1:36:56  lr: 0.000010  ml_loss: 4.4565  mi_loss: 3.8967  train_loss: 8.3532  time: 2.5063  data: 0.0001  max mem: 20908
Train Epoch: [10]  [2550/4855]  eta: 1:34:53  lr: 0.000010  ml_loss: 4.9542  mi_loss: 3.9211  train_loss: 8.8753  time: 2.4917  data: 0.0001  max mem: 20908
Train Epoch: [10]  [2600/4855]  eta: 1:32:50  lr: 0.000010  ml_loss: 4.9087  mi_loss: 3.0634  train_loss: 7.9721  time: 2.4856  data: 0.0001  max mem: 20908
Train Epoch: [10]  [2650/4855]  eta: 1:30:47  lr: 0.000010  ml_loss: 4.9319  mi_loss: 4.3781  train_loss: 9.3100  time: 2.4836  data: 0.0001  max mem: 20908
Train Epoch: [10]  [2700/4855]  eta: 1:28:44  lr: 0.000010  ml_loss: 4.8514  mi_loss: 3.8742  train_loss: 8.7256  time: 2.4828  data: 0.0001  max mem: 20908
Train Epoch: [10]  [2750/4855]  eta: 1:26:41  lr: 0.000010  ml_loss: 5.1080  mi_loss: 4.3656  train_loss: 9.4736  time: 2.4820  data: 0.0001  max mem: 20908
Train Epoch: [10]  [2800/4855]  eta: 1:24:38  lr: 0.000010  ml_loss: 4.5450  mi_loss: 4.1125  train_loss: 8.6575  time: 2.4853  data: 0.0001  max mem: 20908
Train Epoch: [10]  [2850/4855]  eta: 1:22:35  lr: 0.000010  ml_loss: 4.9518  mi_loss: 3.8640  train_loss: 8.8158  time: 2.4771  data: 0.0001  max mem: 20908
Train Epoch: [10]  [2900/4855]  eta: 1:20:32  lr: 0.000010  ml_loss: 5.1872  mi_loss: 4.1005  train_loss: 9.2877  time: 2.4859  data: 0.0001  max mem: 20908
Train Epoch: [10]  [2950/4855]  eta: 1:18:29  lr: 0.000010  ml_loss: 5.1979  mi_loss: 3.6329  train_loss: 8.8308  time: 2.4829  data: 0.0002  max mem: 20908
Train Epoch: [10]  [3000/4855]  eta: 1:16:25  lr: 0.000010  ml_loss: 4.5336  mi_loss: 4.6580  train_loss: 9.1916  time: 2.4828  data: 0.0001  max mem: 20908
Train Epoch: [10]  [3050/4855]  eta: 1:14:22  lr: 0.000010  ml_loss: 4.7413  mi_loss: 4.2148  train_loss: 8.9561  time: 2.4856  data: 0.0001  max mem: 20908
Train Epoch: [10]  [3100/4855]  eta: 1:12:19  lr: 0.000010  ml_loss: 5.2629  mi_loss: 4.2964  train_loss: 9.5593  time: 2.4819  data: 0.0001  max mem: 20908
Train Epoch: [10]  [3150/4855]  eta: 1:10:15  lr: 0.000010  ml_loss: 5.1645  mi_loss: 3.7327  train_loss: 8.8972  time: 2.4724  data: 0.0001  max mem: 20908
Train Epoch: [10]  [3200/4855]  eta: 1:08:11  lr: 0.000010  ml_loss: 5.3141  mi_loss: 4.2779  train_loss: 9.5920  time: 2.4791  data: 0.0001  max mem: 20908
Train Epoch: [10]  [3250/4855]  eta: 1:06:08  lr: 0.000010  ml_loss: 4.8763  mi_loss: 3.0633  train_loss: 7.9396  time: 2.4729  data: 0.0001  max mem: 20908
Train Epoch: [10]  [3300/4855]  eta: 1:04:05  lr: 0.000010  ml_loss: 4.9460  mi_loss: 4.1665  train_loss: 9.1125  time: 2.5020  data: 0.0001  max mem: 20908
Train Epoch: [10]  [3350/4855]  eta: 1:02:01  lr: 0.000010  ml_loss: 4.9797  mi_loss: 4.5611  train_loss: 9.5407  time: 2.4842  data: 0.0001  max mem: 20908
Train Epoch: [10]  [3400/4855]  eta: 0:59:58  lr: 0.000010  ml_loss: 5.4176  mi_loss: 3.7865  train_loss: 9.2041  time: 2.5070  data: 0.0001  max mem: 20908
Train Epoch: [10]  [3450/4855]  eta: 0:57:55  lr: 0.000010  ml_loss: 5.0412  mi_loss: 3.8977  train_loss: 8.9389  time: 2.4820  data: 0.0001  max mem: 20908
Train Epoch: [10]  [3500/4855]  eta: 0:55:52  lr: 0.000010  ml_loss: 4.9864  mi_loss: 3.4718  train_loss: 8.4582  time: 2.4887  data: 0.0001  max mem: 20908
Train Epoch: [10]  [3550/4855]  eta: 0:53:48  lr: 0.000010  ml_loss: 5.0814  mi_loss: 3.8863  train_loss: 8.9677  time: 2.4584  data: 0.0001  max mem: 20908
Train Epoch: [10]  [3600/4855]  eta: 0:51:45  lr: 0.000010  ml_loss: 5.1509  mi_loss: 4.2921  train_loss: 9.4429  time: 2.4768  data: 0.0001  max mem: 20908
Train Epoch: [10]  [3650/4855]  eta: 0:49:41  lr: 0.000010  ml_loss: 5.0515  mi_loss: 4.0222  train_loss: 9.0737  time: 2.4867  data: 0.0001  max mem: 20908
Train Epoch: [10]  [3700/4855]  eta: 0:47:37  lr: 0.000010  ml_loss: 5.4109  mi_loss: 4.4620  train_loss: 9.8729  time: 2.4741  data: 0.0001  max mem: 20908
Train Epoch: [10]  [3750/4855]  eta: 0:45:34  lr: 0.000010  ml_loss: 5.3253  mi_loss: 4.1037  train_loss: 9.4289  time: 2.4690  data: 0.0001  max mem: 20908
Train Epoch: [10]  [3800/4855]  eta: 0:43:30  lr: 0.000010  ml_loss: 5.2582  mi_loss: 4.0011  train_loss: 9.2593  time: 2.4843  data: 0.0001  max mem: 20908
Train Epoch: [10]  [3850/4855]  eta: 0:41:26  lr: 0.000010  ml_loss: 4.4345  mi_loss: 3.6212  train_loss: 8.0557  time: 2.4688  data: 0.0001  max mem: 20908
Train Epoch: [10]  [3900/4855]  eta: 0:39:22  lr: 0.000010  ml_loss: 4.7559  mi_loss: 4.0272  train_loss: 8.7831  time: 2.4543  data: 0.0001  max mem: 20908
Train Epoch: [10]  [3950/4855]  eta: 0:37:19  lr: 0.000010  ml_loss: 5.2499  mi_loss: 4.0735  train_loss: 9.3234  time: 2.4880  data: 0.0001  max mem: 20908
Train Epoch: [10]  [4000/4855]  eta: 0:35:15  lr: 0.000010  ml_loss: 4.9591  mi_loss: 3.9029  train_loss: 8.8620  time: 2.4935  data: 0.0002  max mem: 20908
Train Epoch: [10]  [4050/4855]  eta: 0:33:12  lr: 0.000010  ml_loss: 4.7759  mi_loss: 4.2229  train_loss: 8.9988  time: 2.4721  data: 0.0001  max mem: 20908
Train Epoch: [10]  [4100/4855]  eta: 0:31:08  lr: 0.000010  ml_loss: 4.9807  mi_loss: 4.2334  train_loss: 9.2140  time: 2.4591  data: 0.0001  max mem: 20908
Train Epoch: [10]  [4150/4855]  eta: 0:29:04  lr: 0.000010  ml_loss: 5.0942  mi_loss: 4.4435  train_loss: 9.5377  time: 2.4696  data: 0.0001  max mem: 20908
Train Epoch: [10]  [4200/4855]  eta: 0:27:01  lr: 0.000010  ml_loss: 5.1100  mi_loss: 4.1359  train_loss: 9.2459  time: 2.5051  data: 0.0001  max mem: 20908
Train Epoch: [10]  [4250/4855]  eta: 0:24:57  lr: 0.000010  ml_loss: 5.2308  mi_loss: 4.3158  train_loss: 9.5466  time: 2.4653  data: 0.0001  max mem: 20908
Train Epoch: [10]  [4300/4855]  eta: 0:22:53  lr: 0.000010  ml_loss: 5.0861  mi_loss: 3.9765  train_loss: 9.0626  time: 2.4569  data: 0.0001  max mem: 20908
Train Epoch: [10]  [4350/4855]  eta: 0:20:50  lr: 0.000010  ml_loss: 4.8063  mi_loss: 3.8922  train_loss: 8.6985  time: 2.5013  data: 0.0001  max mem: 20908
Train Epoch: [10]  [4400/4855]  eta: 0:18:46  lr: 0.000010  ml_loss: 5.6207  mi_loss: 3.1137  train_loss: 8.7345  time: 2.4899  data: 0.0001  max mem: 20908
Train Epoch: [10]  [4450/4855]  eta: 0:16:42  lr: 0.000010  ml_loss: 4.8086  mi_loss: 3.8169  train_loss: 8.6255  time: 2.4951  data: 0.0001  max mem: 20908
Train Epoch: [10]  [4500/4855]  eta: 0:14:38  lr: 0.000010  ml_loss: 4.7344  mi_loss: 4.3126  train_loss: 9.0470  time: 2.4782  data: 0.0001  max mem: 20908
Train Epoch: [10]  [4550/4855]  eta: 0:12:35  lr: 0.000010  ml_loss: 4.6206  mi_loss: 3.9590  train_loss: 8.5796  time: 2.4702  data: 0.0001  max mem: 20908
Train Epoch: [10]  [4600/4855]  eta: 0:10:31  lr: 0.000010  ml_loss: 5.4808  mi_loss: 4.0781  train_loss: 9.5588  time: 2.4618  data: 0.0001  max mem: 20908
Train Epoch: [10]  [4650/4855]  eta: 0:08:27  lr: 0.000010  ml_loss: 4.6591  mi_loss: 4.1808  train_loss: 8.8399  time: 2.4920  data: 0.0001  max mem: 20908
Train Epoch: [10]  [4700/4855]  eta: 0:06:23  lr: 0.000010  ml_loss: 5.5878  mi_loss: 3.8150  train_loss: 9.4028  time: 2.4640  data: 0.0001  max mem: 20908
Train Epoch: [10]  [4750/4855]  eta: 0:04:19  lr: 0.000010  ml_loss: 4.9954  mi_loss: 3.7182  train_loss: 8.7136  time: 2.4506  data: 0.0001  max mem: 20908
Train Epoch: [10]  [4800/4855]  eta: 0:02:16  lr: 0.000010  ml_loss: 4.9047  mi_loss: 4.4856  train_loss: 9.3903  time: 2.4633  data: 0.0001  max mem: 20908
Train Epoch: [10]  [4850/4855]  eta: 0:00:12  lr: 0.000010  ml_loss: 4.8498  mi_loss: 4.0138  train_loss: 8.8637  time: 2.4959  data: 0.0001  max mem: 20908
Train Epoch: [10]  [4854/4855]  eta: 0:00:02  lr: 0.000010  ml_loss: 5.2677  mi_loss: 4.0768  train_loss: 9.3445  time: 2.5076  data: 0.0006  max mem: 20908
Train Epoch: [10] Total time: 3:20:20 (2.4759 s / it)
Val Epoch: [10]  [  0/540]  eta: 0:24:21  ml_loss: 4.9372  mi_loss: 4.0956  val_loss: 9.0328  accML: 0.2339  accMI: 0.1270  time: 2.7060  data: 2.2913  max mem: 20908
Val Epoch: [10]  [ 50/540]  eta: 0:06:39  ml_loss: 4.5606  mi_loss: 3.7794  val_loss: 8.3399  accML: 0.2981  accMI: 0.1957  time: 0.7837  data: 0.6218  max mem: 20908
Val Epoch: [10]  [100/540]  eta: 0:05:55  ml_loss: 4.4905  mi_loss: 4.2834  val_loss: 8.7740  accML: 0.3123  accMI: 0.1520  time: 0.7580  data: 0.5961  max mem: 20908
Val Epoch: [10]  [150/540]  eta: 0:05:26  ml_loss: 4.9429  mi_loss: 4.4830  val_loss: 9.4260  accML: 0.2332  accMI: 0.1132  time: 0.9458  data: 0.7822  max mem: 20908
Val Epoch: [10]  [200/540]  eta: 0:04:45  ml_loss: 4.8817  mi_loss: 4.3982  val_loss: 9.2799  accML: 0.2737  accMI: 0.1070  time: 0.8512  data: 0.6884  max mem: 20908
Val Epoch: [10]  [250/540]  eta: 0:04:01  ml_loss: 4.4072  mi_loss: 3.8915  val_loss: 8.2987  accML: 0.3011  accMI: 0.1821  time: 0.8465  data: 0.6840  max mem: 20908
Val Epoch: [10]  [300/540]  eta: 0:03:20  ml_loss: 4.6693  mi_loss: 3.8957  val_loss: 8.5650  accML: 0.2584  accMI: 0.1801  time: 0.8712  data: 0.7084  max mem: 20908
Val Epoch: [10]  [350/540]  eta: 0:02:38  ml_loss: 4.4792  mi_loss: 3.1712  val_loss: 7.6504  accML: 0.2769  accMI: 0.3013  time: 0.7996  data: 0.6372  max mem: 20908
Val Epoch: [10]  [400/540]  eta: 0:01:57  ml_loss: 5.1887  mi_loss: 4.3123  val_loss: 9.5010  accML: 0.2353  accMI: 0.1156  time: 0.8631  data: 0.7003  max mem: 20908
Val Epoch: [10]  [450/540]  eta: 0:01:15  ml_loss: 5.4354  mi_loss: 4.0958  val_loss: 9.5312  accML: 0.1956  accMI: 0.1280  time: 0.8508  data: 0.6879  max mem: 20908
Val Epoch: [10]  [500/540]  eta: 0:00:33  ml_loss: 4.9850  mi_loss: 3.9444  val_loss: 8.9293  accML: 0.2455  accMI: 0.1459  time: 0.7673  data: 0.6054  max mem: 20908
Val Epoch: [10]  [539/540]  eta: 0:00:00  ml_loss: 5.0441  mi_loss: 3.9133  val_loss: 8.9574  accML: 0.2500  accMI: 0.1667  time: 0.7778  data: 0.6180  max mem: 20908
Val Epoch: [10] Total time: 0:07:34 (0.8410 s / it)
epoch:10, iter:53404, 4854,  train_loss: 9.344482421875, valid_loss: 8.897430662755612, idiv_loss:(4.826786551210615, 4.070644109337418), acc:(0.2512917227215237, 0.15700027700513602)
Averaged stats: lr: 0.0000  ml_loss: 4.9017  mi_loss: 4.0314  train_loss: 8.9332
./src/pretrain_mlm_mim.py:58: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure()
epoch 10 9.344482421875
Train Epoch: [11]  [   0/4855]  eta: 7:43:22  lr: 0.000010  ml_loss: 5.3135  mi_loss: 4.2297  train_loss: 9.5432  time: 5.7266  data: 2.6603  max mem: 20908
Train Epoch: [11]  [  50/4855]  eta: 3:23:01  lr: 0.000010  ml_loss: 4.8527  mi_loss: 3.5950  train_loss: 8.4477  time: 2.4719  data: 0.0001  max mem: 20909
Train Epoch: [11]  [ 100/4855]  eta: 3:18:44  lr: 0.000010  ml_loss: 4.9609  mi_loss: 3.5867  train_loss: 8.5476  time: 2.4807  data: 0.0001  max mem: 20909
Train Epoch: [11]  [ 150/4855]  eta: 3:16:10  lr: 0.000010  ml_loss: 4.3574  mi_loss: 3.8778  train_loss: 8.2352  time: 2.4992  data: 0.0001  max mem: 20909
Train Epoch: [11]  [ 200/4855]  eta: 3:13:41  lr: 0.000010  ml_loss: 5.0454  mi_loss: 4.0290  train_loss: 9.0744  time: 2.4883  data: 0.0001  max mem: 20909
Train Epoch: [11]  [ 250/4855]  eta: 3:11:13  lr: 0.000010  ml_loss: 4.8712  mi_loss: 3.8271  train_loss: 8.6983  time: 2.4769  data: 0.0001  max mem: 20909
Train Epoch: [11]  [ 300/4855]  eta: 3:08:47  lr: 0.000010  ml_loss: 5.3129  mi_loss: 3.8709  train_loss: 9.1838  time: 2.4637  data: 0.0001  max mem: 20909
Train Epoch: [11]  [ 350/4855]  eta: 3:06:32  lr: 0.000010  ml_loss: 4.9324  mi_loss: 3.7783  train_loss: 8.7107  time: 2.4876  data: 0.0001  max mem: 20909
Train Epoch: [11]  [ 400/4855]  eta: 3:04:25  lr: 0.000010  ml_loss: 4.1612  mi_loss: 3.6949  train_loss: 7.8560  time: 2.4857  data: 0.0001  max mem: 20909
Train Epoch: [11]  [ 450/4855]  eta: 3:02:19  lr: 0.000010  ml_loss: 3.5808  mi_loss: 3.5114  train_loss: 7.0922  time: 2.4674  data: 0.0001  max mem: 20909
Train Epoch: [11]  [ 500/4855]  eta: 3:00:16  lr: 0.000010  ml_loss: 5.0986  mi_loss: 4.0795  train_loss: 9.1782  time: 2.4682  data: 0.0001  max mem: 20909
Train Epoch: [11]  [ 550/4855]  eta: 2:58:16  lr: 0.000010  ml_loss: 5.4022  mi_loss: 4.1699  train_loss: 9.5722  time: 2.5002  data: 0.0001  max mem: 20909
Train Epoch: [11]  [ 600/4855]  eta: 2:56:16  lr: 0.000010  ml_loss: 3.5855  mi_loss: 4.2164  train_loss: 7.8019  time: 2.4928  data: 0.0002  max mem: 20909
Train Epoch: [11]  [ 650/4855]  eta: 2:54:15  lr: 0.000010  ml_loss: 4.9011  mi_loss: 3.8355  train_loss: 8.7367  time: 2.4913  data: 0.0001  max mem: 20909
Train Epoch: [11]  [ 700/4855]  eta: 2:52:05  lr: 0.000010  ml_loss: 4.9017  mi_loss: 4.1694  train_loss: 9.0712  time: 2.4760  data: 0.0001  max mem: 20909
Train Epoch: [11]  [ 750/4855]  eta: 2:49:59  lr: 0.000010  ml_loss: 5.1758  mi_loss: 3.8889  train_loss: 9.0647  time: 2.4968  data: 0.0001  max mem: 20909
Train Epoch: [11]  [ 800/4855]  eta: 2:47:59  lr: 0.000010  ml_loss: 4.9882  mi_loss: 4.0715  train_loss: 9.0597  time: 2.5000  data: 0.0001  max mem: 20909
Train Epoch: [11]  [ 850/4855]  eta: 2:45:57  lr: 0.000010  ml_loss: 5.2137  mi_loss: 3.8412  train_loss: 9.0548  time: 2.5022  data: 0.0001  max mem: 20909
Train Epoch: [11]  [ 900/4855]  eta: 2:43:53  lr: 0.000010  ml_loss: 4.5156  mi_loss: 4.1641  train_loss: 8.6797  time: 2.4925  data: 0.0001  max mem: 20909
Train Epoch: [11]  [ 950/4855]  eta: 2:41:50  lr: 0.000010  ml_loss: 5.1745  mi_loss: 4.0634  train_loss: 9.2379  time: 2.4903  data: 0.0001  max mem: 20909
Train Epoch: [11]  [1000/4855]  eta: 2:39:47  lr: 0.000010  ml_loss: 5.2132  mi_loss: 3.8243  train_loss: 9.0375  time: 2.5018  data: 0.0001  max mem: 20909
Train Epoch: [11]  [1050/4855]  eta: 2:37:45  lr: 0.000010  ml_loss: 5.2340  mi_loss: 3.7244  train_loss: 8.9583  time: 2.4968  data: 0.0001  max mem: 20909
Train Epoch: [11]  [1100/4855]  eta: 2:35:42  lr: 0.000010  ml_loss: 5.1565  mi_loss: 3.5085  train_loss: 8.6650  time: 2.4980  data: 0.0001  max mem: 20909
Train Epoch: [11]  [1150/4855]  eta: 2:33:33  lr: 0.000010  ml_loss: 4.8081  mi_loss: 4.3686  train_loss: 9.1768  time: 2.4659  data: 0.0001  max mem: 20909
Train Epoch: [11]  [1200/4855]  eta: 2:31:26  lr: 0.000010  ml_loss: 5.0584  mi_loss: 4.5624  train_loss: 9.6208  time: 2.4664  data: 0.0001  max mem: 20909
Train Epoch: [11]  [1250/4855]  eta: 2:29:19  lr: 0.000010  ml_loss: 5.1400  mi_loss: 4.4915  train_loss: 9.6315  time: 2.4521  data: 0.0001  max mem: 20909
Train Epoch: [11]  [1300/4855]  eta: 2:27:13  lr: 0.000010  ml_loss: 4.7049  mi_loss: 3.7588  train_loss: 8.4637  time: 2.4808  data: 0.0001  max mem: 20909
Train Epoch: [11]  [1350/4855]  eta: 2:25:07  lr: 0.000010  ml_loss: 4.9617  mi_loss: 4.2113  train_loss: 9.1730  time: 2.4726  data: 0.0001  max mem: 20909
Train Epoch: [11]  [1400/4855]  eta: 2:22:59  lr: 0.000010  ml_loss: 5.1481  mi_loss: 3.3899  train_loss: 8.5380  time: 2.4553  data: 0.0001  max mem: 20909
Train Epoch: [11]  [1450/4855]  eta: 2:20:52  lr: 0.000010  ml_loss: 5.0175  mi_loss: 4.0351  train_loss: 9.0526  time: 2.4667  data: 0.0001  max mem: 20909
Train Epoch: [11]  [1500/4855]  eta: 2:18:43  lr: 0.000010  ml_loss: 5.2851  mi_loss: 4.3034  train_loss: 9.5886  time: 2.4200  data: 0.0001  max mem: 20909
Train Epoch: [11]  [1550/4855]  eta: 2:16:37  lr: 0.000010  ml_loss: 5.2649  mi_loss: 4.3599  train_loss: 9.6247  time: 2.4692  data: 0.0001  max mem: 20909
Train Epoch: [11]  [1600/4855]  eta: 2:14:32  lr: 0.000010  ml_loss: 4.5982  mi_loss: 4.3873  train_loss: 8.9854  time: 2.4756  data: 0.0001  max mem: 20909
Train Epoch: [11]  [1650/4855]  eta: 2:12:26  lr: 0.000010  ml_loss: 5.1157  mi_loss: 4.1829  train_loss: 9.2986  time: 2.4314  data: 0.0001  max mem: 20909
Train Epoch: [11]  [1700/4855]  eta: 2:10:19  lr: 0.000010  ml_loss: 5.1096  mi_loss: 3.6511  train_loss: 8.7607  time: 2.4689  data: 0.0001  max mem: 20909
Train Epoch: [11]  [1750/4855]  eta: 2:08:13  lr: 0.000010  ml_loss: 4.4070  mi_loss: 4.2367  train_loss: 8.6438  time: 2.4342  data: 0.0001  max mem: 20909
Train Epoch: [11]  [1800/4855]  eta: 2:06:09  lr: 0.000010  ml_loss: 4.8737  mi_loss: 4.1347  train_loss: 9.0083  time: 2.4775  data: 0.0001  max mem: 20909
Train Epoch: [11]  [1850/4855]  eta: 2:04:04  lr: 0.000010  ml_loss: 5.4238  mi_loss: 4.1172  train_loss: 9.5411  time: 2.4502  data: 0.0001  max mem: 20909
Train Epoch: [11]  [1900/4855]  eta: 2:01:58  lr: 0.000010  ml_loss: 4.6098  mi_loss: 3.6650  train_loss: 8.2748  time: 2.4496  data: 0.0001  max mem: 20909
Train Epoch: [11]  [1950/4855]  eta: 1:59:52  lr: 0.000010  ml_loss: 4.5470  mi_loss: 4.4543  train_loss: 9.0013  time: 2.4410  data: 0.0001  max mem: 20909
Train Epoch: [11]  [2000/4855]  eta: 1:57:46  lr: 0.000010  ml_loss: 4.3891  mi_loss: 3.9797  train_loss: 8.3688  time: 2.4344  data: 0.0001  max mem: 20909
Train Epoch: [11]  [2050/4855]  eta: 1:55:41  lr: 0.000010  ml_loss: 3.7159  mi_loss: 3.8510  train_loss: 7.5669  time: 2.4651  data: 0.0001  max mem: 20909
Train Epoch: [11]  [2100/4855]  eta: 1:53:36  lr: 0.000010  ml_loss: 4.8988  mi_loss: 3.5491  train_loss: 8.4478  time: 2.4686  data: 0.0001  max mem: 20909
Train Epoch: [11]  [2150/4855]  eta: 1:51:31  lr: 0.000010  ml_loss: 4.6132  mi_loss: 4.2812  train_loss: 8.8944  time: 2.4415  data: 0.0001  max mem: 20909
Train Epoch: [11]  [2200/4855]  eta: 1:49:26  lr: 0.000010  ml_loss: 4.5835  mi_loss: 4.1428  train_loss: 8.7263  time: 2.4882  data: 0.0001  max mem: 20909
Train Epoch: [11]  [2250/4855]  eta: 1:47:21  lr: 0.000010  ml_loss: 4.8635  mi_loss: 4.2825  train_loss: 9.1461  time: 2.4495  data: 0.0001  max mem: 20909
Train Epoch: [11]  [2300/4855]  eta: 1:45:16  lr: 0.000010  ml_loss: 5.4175  mi_loss: 3.5642  train_loss: 8.9818  time: 2.4283  data: 0.0001  max mem: 20909
Train Epoch: [11]  [2350/4855]  eta: 1:43:12  lr: 0.000010  ml_loss: 5.4579  mi_loss: 3.9057  train_loss: 9.3635  time: 2.4576  data: 0.0001  max mem: 20909
Train Epoch: [11]  [2400/4855]  eta: 1:41:08  lr: 0.000010  ml_loss: 4.2438  mi_loss: 3.9422  train_loss: 8.1860  time: 2.4738  data: 0.0001  max mem: 20909
Train Epoch: [11]  [2450/4855]  eta: 1:39:04  lr: 0.000010  ml_loss: 4.7767  mi_loss: 3.8133  train_loss: 8.5900  time: 2.4675  data: 0.0001  max mem: 20909
Train Epoch: [11]  [2500/4855]  eta: 1:36:59  lr: 0.000010  ml_loss: 5.1823  mi_loss: 4.2022  train_loss: 9.3845  time: 2.4404  data: 0.0001  max mem: 20909
Train Epoch: [11]  [2550/4855]  eta: 1:34:56  lr: 0.000010  ml_loss: 4.8172  mi_loss: 4.1854  train_loss: 9.0026  time: 2.4820  data: 0.0001  max mem: 20909
Train Epoch: [11]  [2600/4855]  eta: 1:32:52  lr: 0.000010  ml_loss: 4.4077  mi_loss: 4.1297  train_loss: 8.5374  time: 2.4502  data: 0.0001  max mem: 20909
Train Epoch: [11]  [2650/4855]  eta: 1:30:48  lr: 0.000010  ml_loss: 4.9652  mi_loss: 4.3386  train_loss: 9.3039  time: 2.4733  data: 0.0001  max mem: 20909
Train Epoch: [11]  [2700/4855]  eta: 1:28:44  lr: 0.000010  ml_loss: 4.4035  mi_loss: 3.9394  train_loss: 8.3428  time: 2.4423  data: 0.0001  max mem: 20909
Train Epoch: [11]  [2750/4855]  eta: 1:26:40  lr: 0.000010  ml_loss: 4.9631  mi_loss: 4.3377  train_loss: 9.3007  time: 2.4695  data: 0.0001  max mem: 20909
Train Epoch: [11]  [2800/4855]  eta: 1:24:36  lr: 0.000010  ml_loss: 4.9014  mi_loss: 4.4366  train_loss: 9.3380  time: 2.4547  data: 0.0001  max mem: 20909
Train Epoch: [11]  [2850/4855]  eta: 1:22:32  lr: 0.000010  ml_loss: 4.5598  mi_loss: 4.0252  train_loss: 8.5850  time: 2.4605  data: 0.0001  max mem: 20909
Train Epoch: [11]  [2900/4855]  eta: 1:20:28  lr: 0.000010  ml_loss: 4.0364  mi_loss: 4.0011  train_loss: 8.0376  time: 2.4629  data: 0.0001  max mem: 20909
Train Epoch: [11]  [2950/4855]  eta: 1:18:24  lr: 0.000010  ml_loss: 5.0227  mi_loss: 4.1295  train_loss: 9.1522  time: 2.4520  data: 0.0001  max mem: 20909
Train Epoch: [11]  [3000/4855]  eta: 1:16:20  lr: 0.000010  ml_loss: 5.5353  mi_loss: 4.1271  train_loss: 9.6623  time: 2.4532  data: 0.0001  max mem: 20909
Train Epoch: [11]  [3050/4855]  eta: 1:14:15  lr: 0.000010  ml_loss: 5.2428  mi_loss: 4.4345  train_loss: 9.6773  time: 2.4167  data: 0.0001  max mem: 20909
Train Epoch: [11]  [3100/4855]  eta: 1:12:11  lr: 0.000010  ml_loss: 5.3138  mi_loss: 4.0862  train_loss: 9.4001  time: 2.4327  data: 0.0001  max mem: 20909
Train Epoch: [11]  [3150/4855]  eta: 1:10:08  lr: 0.000010  ml_loss: 4.7918  mi_loss: 4.3064  train_loss: 9.0981  time: 2.4818  data: 0.0001  max mem: 20909
Train Epoch: [11]  [3200/4855]  eta: 1:08:04  lr: 0.000010  ml_loss: 5.4634  mi_loss: 4.5309  train_loss: 9.9943  time: 2.4639  data: 0.0001  max mem: 20909
Train Epoch: [11]  [3250/4855]  eta: 1:06:01  lr: 0.000010  ml_loss: 4.6429  mi_loss: 4.1573  train_loss: 8.8001  time: 2.4611  data: 0.0001  max mem: 20909
Train Epoch: [11]  [3300/4855]  eta: 1:03:58  lr: 0.000010  ml_loss: 4.6184  mi_loss: 4.1145  train_loss: 8.7329  time: 2.4985  data: 0.0002  max mem: 20909
Train Epoch: [11]  [3350/4855]  eta: 1:01:55  lr: 0.000010  ml_loss: 5.1039  mi_loss: 4.2211  train_loss: 9.3250  time: 2.4800  data: 0.0001  max mem: 20909
Train Epoch: [11]  [3400/4855]  eta: 0:59:52  lr: 0.000010  ml_loss: 4.6827  mi_loss: 3.5545  train_loss: 8.2371  time: 2.4809  data: 0.0001  max mem: 20909
Train Epoch: [11]  [3450/4855]  eta: 0:57:49  lr: 0.000010  ml_loss: 4.7198  mi_loss: 4.4147  train_loss: 9.1344  time: 2.4799  data: 0.0001  max mem: 20909
Train Epoch: [11]  [3500/4855]  eta: 0:55:45  lr: 0.000010  ml_loss: 4.9747  mi_loss: 4.0849  train_loss: 9.0595  time: 2.4628  data: 0.0001  max mem: 20909
Train Epoch: [11]  [3550/4855]  eta: 0:53:41  lr: 0.000010  ml_loss: 4.9670  mi_loss: 3.8774  train_loss: 8.8444  time: 2.4818  data: 0.0001  max mem: 20909
Train Epoch: [11]  [3600/4855]  eta: 0:51:38  lr: 0.000010  ml_loss: 5.0716  mi_loss: 3.9316  train_loss: 9.0032  time: 2.4663  data: 0.0001  max mem: 20909
Train Epoch: [11]  [3650/4855]  eta: 0:49:35  lr: 0.000010  ml_loss: 5.1288  mi_loss: 3.8843  train_loss: 9.0131  time: 2.4788  data: 0.0001  max mem: 20909
Train Epoch: [11]  [3700/4855]  eta: 0:47:31  lr: 0.000010  ml_loss: 5.3343  mi_loss: 4.2620  train_loss: 9.5963  time: 2.4815  data: 0.0001  max mem: 20909
Train Epoch: [11]  [3750/4855]  eta: 0:45:28  lr: 0.000010  ml_loss: 4.8522  mi_loss: 3.6602  train_loss: 8.5124  time: 2.4930  data: 0.0001  max mem: 20909
Train Epoch: [11]  [3800/4855]  eta: 0:43:25  lr: 0.000010  ml_loss: 4.8765  mi_loss: 3.6105  train_loss: 8.4870  time: 2.4661  data: 0.0001  max mem: 20909
Train Epoch: [11]  [3850/4855]  eta: 0:41:21  lr: 0.000010  ml_loss: 4.3705  mi_loss: 3.8834  train_loss: 8.2539  time: 2.4776  data: 0.0001  max mem: 20909
Train Epoch: [11]  [3900/4855]  eta: 0:39:18  lr: 0.000010  ml_loss: 4.4732  mi_loss: 4.4838  train_loss: 8.9569  time: 2.4803  data: 0.0001  max mem: 20909
Train Epoch: [11]  [3950/4855]  eta: 0:37:14  lr: 0.000010  ml_loss: 5.2928  mi_loss: 4.1528  train_loss: 9.4456  time: 2.4794  data: 0.0001  max mem: 20909
Train Epoch: [11]  [4000/4855]  eta: 0:35:11  lr: 0.000010  ml_loss: 4.6659  mi_loss: 4.2162  train_loss: 8.8821  time: 2.4813  data: 0.0001  max mem: 20909
Train Epoch: [11]  [4050/4855]  eta: 0:33:08  lr: 0.000010  ml_loss: 4.7391  mi_loss: 4.0478  train_loss: 8.7869  time: 2.4856  data: 0.0001  max mem: 20909
Train Epoch: [11]  [4100/4855]  eta: 0:31:04  lr: 0.000010  ml_loss: 4.7298  mi_loss: 3.7653  train_loss: 8.4950  time: 2.4798  data: 0.0001  max mem: 20909
Train Epoch: [11]  [4150/4855]  eta: 0:29:01  lr: 0.000010  ml_loss: 5.3907  mi_loss: 3.6999  train_loss: 9.0906  time: 2.4726  data: 0.0001  max mem: 20909
Train Epoch: [11]  [4200/4855]  eta: 0:26:57  lr: 0.000010  ml_loss: 4.9777  mi_loss: 4.3727  train_loss: 9.3504  time: 2.4820  data: 0.0001  max mem: 20909
Train Epoch: [11]  [4250/4855]  eta: 0:24:54  lr: 0.000010  ml_loss: 4.6887  mi_loss: 4.1751  train_loss: 8.8638  time: 2.4749  data: 0.0001  max mem: 20909
Train Epoch: [11]  [4300/4855]  eta: 0:22:51  lr: 0.000010  ml_loss: 4.6183  mi_loss: 4.1802  train_loss: 8.7985  time: 2.4821  data: 0.0001  max mem: 20909
Train Epoch: [11]  [4350/4855]  eta: 0:20:47  lr: 0.000010  ml_loss: 4.7931  mi_loss: 3.9277  train_loss: 8.7208  time: 2.4495  data: 0.0001  max mem: 20909
Train Epoch: [11]  [4400/4855]  eta: 0:18:43  lr: 0.000010  ml_loss: 4.9241  mi_loss: 3.9460  train_loss: 8.8701  time: 2.4518  data: 0.0001  max mem: 20909
Train Epoch: [11]  [4450/4855]  eta: 0:16:40  lr: 0.000010  ml_loss: 4.7065  mi_loss: 4.6430  train_loss: 9.3496  time: 2.4579  data: 0.0001  max mem: 20909
Train Epoch: [11]  [4500/4855]  eta: 0:14:36  lr: 0.000010  ml_loss: 4.5848  mi_loss: 4.0670  train_loss: 8.6518  time: 2.4780  data: 0.0001  max mem: 20909
Train Epoch: [11]  [4550/4855]  eta: 0:12:33  lr: 0.000010  ml_loss: 5.4445  mi_loss: 4.2898  train_loss: 9.7343  time: 2.4651  data: 0.0001  max mem: 20909
Train Epoch: [11]  [4600/4855]  eta: 0:10:29  lr: 0.000010  ml_loss: 4.5948  mi_loss: 4.4923  train_loss: 9.0871  time: 2.4603  data: 0.0001  max mem: 20909
Train Epoch: [11]  [4650/4855]  eta: 0:08:26  lr: 0.000010  ml_loss: 4.8771  mi_loss: 3.8822  train_loss: 8.7593  time: 2.4382  data: 0.0002  max mem: 20909
Train Epoch: [11]  [4700/4855]  eta: 0:06:22  lr: 0.000010  ml_loss: 5.6018  mi_loss: 4.1086  train_loss: 9.7105  time: 2.4185  data: 0.0001  max mem: 20909
Train Epoch: [11]  [4750/4855]  eta: 0:04:19  lr: 0.000010  ml_loss: 5.1274  mi_loss: 4.0333  train_loss: 9.1607  time: 2.4370  data: 0.0001  max mem: 20909
Train Epoch: [11]  [4800/4855]  eta: 0:02:15  lr: 0.000010  ml_loss: 5.0775  mi_loss: 3.9868  train_loss: 9.0643  time: 2.4447  data: 0.0001  max mem: 20909
Train Epoch: [11]  [4850/4855]  eta: 0:00:12  lr: 0.000010  ml_loss: 5.1219  mi_loss: 3.9027  train_loss: 9.0247  time: 2.4428  data: 0.0001  max mem: 20909
Train Epoch: [11]  [4854/4855]  eta: 0:00:02  lr: 0.000010  ml_loss: 4.4357  mi_loss: 3.6302  train_loss: 8.0659  time: 2.4513  data: 0.0006  max mem: 20909
Train Epoch: [11] Total time: 3:19:47 (2.4690 s / it)
Val Epoch: [11]  [  0/540]  eta: 0:23:35  ml_loss: 5.0463  mi_loss: 4.1131  val_loss: 9.1595  accML: 0.2110  accMI: 0.1297  time: 2.6212  data: 2.2556  max mem: 20909
Val Epoch: [11]  [ 50/540]  eta: 0:06:25  ml_loss: 4.5643  mi_loss: 3.8813  val_loss: 8.4455  accML: 0.3135  accMI: 0.1877  time: 0.7596  data: 0.5981  max mem: 20909
Val Epoch: [11]  [100/540]  eta: 0:05:46  ml_loss: 4.6093  mi_loss: 4.3405  val_loss: 8.9498  accML: 0.2458  accMI: 0.1333  time: 0.7663  data: 0.6037  max mem: 20909
Val Epoch: [11]  [150/540]  eta: 0:05:19  ml_loss: 4.7253  mi_loss: 4.6197  val_loss: 9.3450  accML: 0.2548  accMI: 0.1267  time: 0.9281  data: 0.7642  max mem: 20909
Val Epoch: [11]  [200/540]  eta: 0:04:40  ml_loss: 4.8962  mi_loss: 4.3956  val_loss: 9.2918  accML: 0.2594  accMI: 0.1096  time: 0.8330  data: 0.6702  max mem: 20909
Val Epoch: [11]  [250/540]  eta: 0:03:58  ml_loss: 4.5812  mi_loss: 3.9056  val_loss: 8.4868  accML: 0.2817  accMI: 0.1495  time: 0.8542  data: 0.6912  max mem: 20909
Val Epoch: [11]  [300/540]  eta: 0:03:18  ml_loss: 4.4927  mi_loss: 3.9476  val_loss: 8.4403  accML: 0.2791  accMI: 0.1909  time: 0.8789  data: 0.7153  max mem: 20909
Val Epoch: [11]  [350/540]  eta: 0:02:37  ml_loss: 4.6944  mi_loss: 3.2208  val_loss: 7.9153  accML: 0.2610  accMI: 0.3013  time: 0.8283  data: 0.6651  max mem: 20909
Val Epoch: [11]  [400/540]  eta: 0:01:57  ml_loss: 5.4420  mi_loss: 4.3163  val_loss: 9.7583  accML: 0.1853  accMI: 0.1048  time: 0.8897  data: 0.7264  max mem: 20909
Val Epoch: [11]  [450/540]  eta: 0:01:15  ml_loss: 5.2527  mi_loss: 4.1115  val_loss: 9.3642  accML: 0.2195  accMI: 0.1387  time: 0.8572  data: 0.6944  max mem: 20909
Val Epoch: [11]  [500/540]  eta: 0:00:33  ml_loss: 5.0235  mi_loss: 3.9360  val_loss: 8.9596  accML: 0.2630  accMI: 0.1432  time: 0.7609  data: 0.5990  max mem: 20909
Val Epoch: [11]  [539/540]  eta: 0:00:00  ml_loss: 4.8853  mi_loss: 4.0170  val_loss: 8.9023  accML: 0.2365  accMI: 0.1802  time: 0.7784  data: 0.6185  max mem: 20909
Val Epoch: [11] Total time: 0:07:32 (0.8387 s / it)
epoch:11, iter:58259, 4854,  train_loss: 8.06586742401123, valid_loss: 8.90800725000876, idiv_loss:(4.782469623618656, 4.125537620650397), acc:(0.25593274547545997, 0.15303121656179428)
Averaged stats: lr: 0.0000  ml_loss: 4.8519  mi_loss: 4.0861  train_loss: 8.9379
epoch 11 8.06586742401123
Train Epoch: [12]  [   0/4855]  eta: 8:09:01  lr: 0.000010  ml_loss: 4.9029  mi_loss: 3.9480  train_loss: 8.8509  time: 6.0435  data: 3.6070  max mem: 20909
Train Epoch: [12]  [  50/4855]  eta: 3:21:44  lr: 0.000010  ml_loss: 4.9297  mi_loss: 3.8285  train_loss: 8.7582  time: 2.4441  data: 0.0001  max mem: 20909
Train Epoch: [12]  [ 100/4855]  eta: 3:16:27  lr: 0.000010  ml_loss: 5.4403  mi_loss: 3.7926  train_loss: 9.2330  time: 2.4516  data: 0.0001  max mem: 20909
Train Epoch: [12]  [ 150/4855]  eta: 3:13:48  lr: 0.000010  ml_loss: 4.7801  mi_loss: 3.9160  train_loss: 8.6961  time: 2.4581  data: 0.0001  max mem: 20909
Train Epoch: [12]  [ 200/4855]  eta: 3:11:27  lr: 0.000010  ml_loss: 4.8356  mi_loss: 3.8419  train_loss: 8.6775  time: 2.4536  data: 0.0001  max mem: 20909
Train Epoch: [12]  [ 250/4855]  eta: 3:09:13  lr: 0.000010  ml_loss: 5.0034  mi_loss: 4.3111  train_loss: 9.3145  time: 2.4622  data: 0.0001  max mem: 20909
Train Epoch: [12]  [ 300/4855]  eta: 3:07:05  lr: 0.000010  ml_loss: 4.5464  mi_loss: 4.2092  train_loss: 8.7556  time: 2.4604  data: 0.0001  max mem: 20909
Train Epoch: [12]  [ 350/4855]  eta: 3:04:39  lr: 0.000010  ml_loss: 5.1240  mi_loss: 4.1689  train_loss: 9.2929  time: 2.4321  data: 0.0002  max mem: 20909
Train Epoch: [12]  [ 400/4855]  eta: 3:02:36  lr: 0.000010  ml_loss: 4.8267  mi_loss: 3.8845  train_loss: 8.7112  time: 2.4661  data: 0.0001  max mem: 20909
Train Epoch: [12]  [ 450/4855]  eta: 3:00:25  lr: 0.000010  ml_loss: 5.1050  mi_loss: 4.1451  train_loss: 9.2501  time: 2.4389  data: 0.0001  max mem: 20909
Train Epoch: [12]  [ 500/4855]  eta: 2:58:16  lr: 0.000010  ml_loss: 4.5911  mi_loss: 4.0228  train_loss: 8.6139  time: 2.4565  data: 0.0001  max mem: 20909
Train Epoch: [12]  [ 550/4855]  eta: 2:56:06  lr: 0.000010  ml_loss: 5.4815  mi_loss: 4.2749  train_loss: 9.7564  time: 2.4341  data: 0.0001  max mem: 20909
Train Epoch: [12]  [ 600/4855]  eta: 2:54:01  lr: 0.000010  ml_loss: 4.6292  mi_loss: 2.8350  train_loss: 7.4642  time: 2.4350  data: 0.0001  max mem: 20909
Train Epoch: [12]  [ 650/4855]  eta: 2:51:56  lr: 0.000010  ml_loss: 4.9395  mi_loss: 4.0809  train_loss: 9.0205  time: 2.4557  data: 0.0001  max mem: 20909
Train Epoch: [12]  [ 700/4855]  eta: 2:49:55  lr: 0.000010  ml_loss: 4.4594  mi_loss: 4.3112  train_loss: 8.7706  time: 2.4585  data: 0.0001  max mem: 20909
Train Epoch: [12]  [ 750/4855]  eta: 2:47:52  lr: 0.000010  ml_loss: 5.4224  mi_loss: 3.9561  train_loss: 9.3785  time: 2.4518  data: 0.0001  max mem: 20909
Train Epoch: [12]  [ 800/4855]  eta: 2:45:51  lr: 0.000010  ml_loss: 4.0457  mi_loss: 4.0862  train_loss: 8.1318  time: 2.4488  data: 0.0001  max mem: 20909
Train Epoch: [12]  [ 850/4855]  eta: 2:43:47  lr: 0.000010  ml_loss: 4.9192  mi_loss: 3.2221  train_loss: 8.1413  time: 2.4455  data: 0.0002  max mem: 20909
Train Epoch: [12]  [ 900/4855]  eta: 2:41:41  lr: 0.000010  ml_loss: 5.0488  mi_loss: 4.1484  train_loss: 9.1972  time: 2.4549  data: 0.0001  max mem: 20909
Train Epoch: [12]  [ 950/4855]  eta: 2:39:41  lr: 0.000010  ml_loss: 4.7306  mi_loss: 3.9330  train_loss: 8.6636  time: 2.4719  data: 0.0002  max mem: 20909
Train Epoch: [12]  [1000/4855]  eta: 2:37:39  lr: 0.000010  ml_loss: 4.3837  mi_loss: 3.7956  train_loss: 8.1793  time: 2.4635  data: 0.0001  max mem: 20909
Train Epoch: [12]  [1050/4855]  eta: 2:35:39  lr: 0.000010  ml_loss: 4.5064  mi_loss: 4.0100  train_loss: 8.5164  time: 2.4721  data: 0.0001  max mem: 20909
Train Epoch: [12]  [1100/4855]  eta: 2:33:36  lr: 0.000010  ml_loss: 4.7982  mi_loss: 3.8366  train_loss: 8.6348  time: 2.4429  data: 0.0002  max mem: 20909
Train Epoch: [12]  [1150/4855]  eta: 2:31:31  lr: 0.000010  ml_loss: 4.5025  mi_loss: 3.8586  train_loss: 8.3610  time: 2.4523  data: 0.0001  max mem: 20909
Train Epoch: [12]  [1200/4855]  eta: 2:29:28  lr: 0.000010  ml_loss: 5.3705  mi_loss: 4.0494  train_loss: 9.4199  time: 2.4698  data: 0.0002  max mem: 20909
Train Epoch: [12]  [1250/4855]  eta: 2:27:24  lr: 0.000010  ml_loss: 4.4030  mi_loss: 4.3199  train_loss: 8.7229  time: 2.4276  data: 0.0001  max mem: 20909
Train Epoch: [12]  [1300/4855]  eta: 2:25:18  lr: 0.000010  ml_loss: 5.2465  mi_loss: 3.9540  train_loss: 9.2004  time: 2.4218  data: 0.0002  max mem: 20909
Train Epoch: [12]  [1350/4855]  eta: 2:23:15  lr: 0.000010  ml_loss: 5.1009  mi_loss: 4.0513  train_loss: 9.1522  time: 2.4493  data: 0.0001  max mem: 20909
Train Epoch: [12]  [1400/4855]  eta: 2:21:14  lr: 0.000010  ml_loss: 5.1103  mi_loss: 3.9631  train_loss: 9.0733  time: 2.4674  data: 0.0002  max mem: 20909
Train Epoch: [12]  [1450/4855]  eta: 2:19:12  lr: 0.000010  ml_loss: 5.0739  mi_loss: 3.3995  train_loss: 8.4735  time: 2.4536  data: 0.0001  max mem: 20909
Train Epoch: [12]  [1500/4855]  eta: 2:17:08  lr: 0.000010  ml_loss: 5.0607  mi_loss: 3.9806  train_loss: 9.0413  time: 2.4539  data: 0.0002  max mem: 20909
Train Epoch: [12]  [1550/4855]  eta: 2:15:06  lr: 0.000010  ml_loss: 4.3333  mi_loss: 3.2013  train_loss: 7.5346  time: 2.4696  data: 0.0002  max mem: 20909
Train Epoch: [12]  [1600/4855]  eta: 2:13:03  lr: 0.000010  ml_loss: 5.0528  mi_loss: 4.5106  train_loss: 9.5634  time: 2.4359  data: 0.0001  max mem: 20909
Train Epoch: [12]  [1650/4855]  eta: 2:10:59  lr: 0.000010  ml_loss: 5.0826  mi_loss: 3.9279  train_loss: 9.0104  time: 2.4410  data: 0.0001  max mem: 20909
Train Epoch: [12]  [1700/4855]  eta: 2:08:55  lr: 0.000010  ml_loss: 5.0632  mi_loss: 3.9441  train_loss: 9.0073  time: 2.4493  data: 0.0001  max mem: 20909
Train Epoch: [12]  [1750/4855]  eta: 2:06:53  lr: 0.000010  ml_loss: 4.5356  mi_loss: 4.0962  train_loss: 8.6317  time: 2.4625  data: 0.0001  max mem: 20909
Train Epoch: [12]  [1800/4855]  eta: 2:04:52  lr: 0.000010  ml_loss: 4.6161  mi_loss: 3.6002  train_loss: 8.2164  time: 2.4828  data: 0.0001  max mem: 20909
Train Epoch: [12]  [1850/4855]  eta: 2:02:52  lr: 0.000010  ml_loss: 4.9871  mi_loss: 3.8685  train_loss: 8.8556  time: 2.4823  data: 0.0001  max mem: 20909
Train Epoch: [12]  [1900/4855]  eta: 2:00:51  lr: 0.000010  ml_loss: 4.3860  mi_loss: 4.1182  train_loss: 8.5042  time: 2.4674  data: 0.0002  max mem: 20909
Train Epoch: [12]  [1950/4855]  eta: 1:58:50  lr: 0.000010  ml_loss: 4.7844  mi_loss: 4.2965  train_loss: 9.0809  time: 2.4817  data: 0.0002  max mem: 20909
Train Epoch: [12]  [2000/4855]  eta: 1:56:49  lr: 0.000010  ml_loss: 4.5925  mi_loss: 3.9577  train_loss: 8.5502  time: 2.4729  data: 0.0001  max mem: 20909
Train Epoch: [12]  [2050/4855]  eta: 1:54:47  lr: 0.000010  ml_loss: 4.8257  mi_loss: 3.9650  train_loss: 8.7907  time: 2.4721  data: 0.0001  max mem: 20909
Train Epoch: [12]  [2100/4855]  eta: 1:52:46  lr: 0.000010  ml_loss: 4.6283  mi_loss: 3.7904  train_loss: 8.4187  time: 2.4737  data: 0.0001  max mem: 20909
Train Epoch: [12]  [2150/4855]  eta: 1:50:44  lr: 0.000010  ml_loss: 4.4618  mi_loss: 3.9070  train_loss: 8.3688  time: 2.4691  data: 0.0001  max mem: 20909
Train Epoch: [12]  [2200/4855]  eta: 1:48:42  lr: 0.000010  ml_loss: 5.0886  mi_loss: 4.3161  train_loss: 9.4047  time: 2.4689  data: 0.0001  max mem: 20909
Train Epoch: [12]  [2250/4855]  eta: 1:46:40  lr: 0.000010  ml_loss: 4.3123  mi_loss: 4.3670  train_loss: 8.6793  time: 2.4822  data: 0.0002  max mem: 20909
Train Epoch: [12]  [2300/4855]  eta: 1:44:39  lr: 0.000010  ml_loss: 4.4500  mi_loss: 3.9693  train_loss: 8.4193  time: 2.4785  data: 0.0001  max mem: 20909
Train Epoch: [12]  [2350/4855]  eta: 1:42:36  lr: 0.000010  ml_loss: 4.8207  mi_loss: 4.1597  train_loss: 8.9804  time: 2.4384  data: 0.0001  max mem: 20909
Train Epoch: [12]  [2400/4855]  eta: 1:40:33  lr: 0.000010  ml_loss: 4.7462  mi_loss: 4.1791  train_loss: 8.9253  time: 2.4495  data: 0.0001  max mem: 20909
Train Epoch: [12]  [2450/4855]  eta: 1:38:30  lr: 0.000010  ml_loss: 4.7618  mi_loss: 4.3982  train_loss: 9.1599  time: 2.4583  data: 0.0001  max mem: 20909
Train Epoch: [12]  [2500/4855]  eta: 1:36:27  lr: 0.000010  ml_loss: 4.5982  mi_loss: 4.1520  train_loss: 8.7502  time: 2.4607  data: 0.0001  max mem: 20909
Train Epoch: [12]  [2550/4855]  eta: 1:34:24  lr: 0.000010  ml_loss: 4.8482  mi_loss: 4.1043  train_loss: 8.9524  time: 2.4454  data: 0.0001  max mem: 20909
Train Epoch: [12]  [2600/4855]  eta: 1:32:20  lr: 0.000010  ml_loss: 4.7680  mi_loss: 4.0003  train_loss: 8.7683  time: 2.4290  data: 0.0001  max mem: 20909
Train Epoch: [12]  [2650/4855]  eta: 1:30:16  lr: 0.000010  ml_loss: 5.0303  mi_loss: 4.0422  train_loss: 9.0725  time: 2.4309  data: 0.0001  max mem: 20909
Train Epoch: [12]  [2700/4855]  eta: 1:28:13  lr: 0.000010  ml_loss: 4.6353  mi_loss: 4.3568  train_loss: 8.9920  time: 2.4462  data: 0.0001  max mem: 20909
Train Epoch: [12]  [2750/4855]  eta: 1:26:10  lr: 0.000010  ml_loss: 5.1008  mi_loss: 4.2334  train_loss: 9.3342  time: 2.4478  data: 0.0001  max mem: 20909
Train Epoch: [12]  [2800/4855]  eta: 1:24:08  lr: 0.000010  ml_loss: 4.3241  mi_loss: 4.1752  train_loss: 8.4993  time: 2.4686  data: 0.0001  max mem: 20909
Train Epoch: [12]  [2850/4855]  eta: 1:22:06  lr: 0.000010  ml_loss: 4.4810  mi_loss: 4.0635  train_loss: 8.5445  time: 2.4736  data: 0.0001  max mem: 20909
Train Epoch: [12]  [2900/4855]  eta: 1:20:03  lr: 0.000010  ml_loss: 5.0777  mi_loss: 4.2115  train_loss: 9.2892  time: 2.4735  data: 0.0001  max mem: 20909
Train Epoch: [12]  [2950/4855]  eta: 1:18:00  lr: 0.000010  ml_loss: 4.6463  mi_loss: 4.3641  train_loss: 9.0104  time: 2.4634  data: 0.0001  max mem: 20909
Train Epoch: [12]  [3000/4855]  eta: 1:15:57  lr: 0.000010  ml_loss: 4.8069  mi_loss: 4.0529  train_loss: 8.8599  time: 2.4614  data: 0.0001  max mem: 20909
Train Epoch: [12]  [3050/4855]  eta: 1:13:55  lr: 0.000010  ml_loss: 5.0050  mi_loss: 3.9328  train_loss: 8.9378  time: 2.4669  data: 0.0001  max mem: 20909
Train Epoch: [12]  [3100/4855]  eta: 1:11:52  lr: 0.000010  ml_loss: 4.5894  mi_loss: 3.8499  train_loss: 8.4393  time: 2.4786  data: 0.0001  max mem: 20909
Train Epoch: [12]  [3150/4855]  eta: 1:09:50  lr: 0.000010  ml_loss: 4.5626  mi_loss: 4.0645  train_loss: 8.6271  time: 2.4763  data: 0.0001  max mem: 20909
Train Epoch: [12]  [3200/4855]  eta: 1:07:46  lr: 0.000010  ml_loss: 4.8823  mi_loss: 4.2227  train_loss: 9.1050  time: 2.4443  data: 0.0001  max mem: 20909
Train Epoch: [12]  [3250/4855]  eta: 1:05:43  lr: 0.000010  ml_loss: 5.0106  mi_loss: 3.7870  train_loss: 8.7976  time: 2.4390  data: 0.0002  max mem: 20909
Train Epoch: [12]  [3300/4855]  eta: 1:03:40  lr: 0.000010  ml_loss: 4.8395  mi_loss: 3.8150  train_loss: 8.6545  time: 2.4597  data: 0.0002  max mem: 20909
Train Epoch: [12]  [3350/4855]  eta: 1:01:37  lr: 0.000010  ml_loss: 4.3533  mi_loss: 3.9675  train_loss: 8.3208  time: 2.4653  data: 0.0002  max mem: 20909
Train Epoch: [12]  [3400/4855]  eta: 0:59:34  lr: 0.000010  ml_loss: 5.6326  mi_loss: 4.2620  train_loss: 9.8946  time: 2.4478  data: 0.0001  max mem: 20909
Train Epoch: [12]  [3450/4855]  eta: 0:57:32  lr: 0.000010  ml_loss: 4.7453  mi_loss: 4.0049  train_loss: 8.7501  time: 2.4517  data: 0.0001  max mem: 20909
Train Epoch: [12]  [3500/4855]  eta: 0:55:29  lr: 0.000010  ml_loss: 4.6106  mi_loss: 3.9307  train_loss: 8.5414  time: 2.4616  data: 0.0001  max mem: 20909
Train Epoch: [12]  [3550/4855]  eta: 0:53:26  lr: 0.000010  ml_loss: 4.8956  mi_loss: 3.3157  train_loss: 8.2113  time: 2.4785  data: 0.0001  max mem: 20909
Train Epoch: [12]  [3600/4855]  eta: 0:51:23  lr: 0.000010  ml_loss: 4.8517  mi_loss: 4.1585  train_loss: 9.0101  time: 2.4603  data: 0.0002  max mem: 20909
Train Epoch: [12]  [3650/4855]  eta: 0:49:20  lr: 0.000010  ml_loss: 4.9231  mi_loss: 4.0544  train_loss: 8.9775  time: 2.4565  data: 0.0001  max mem: 20909
Train Epoch: [12]  [3700/4855]  eta: 0:47:17  lr: 0.000010  ml_loss: 4.6626  mi_loss: 4.0870  train_loss: 8.7496  time: 2.4540  data: 0.0001  max mem: 20909
Train Epoch: [12]  [3750/4855]  eta: 0:45:14  lr: 0.000010  ml_loss: 5.2241  mi_loss: 3.9942  train_loss: 9.2183  time: 2.4294  data: 0.0001  max mem: 20909
Train Epoch: [12]  [3800/4855]  eta: 0:43:11  lr: 0.000010  ml_loss: 4.7917  mi_loss: 4.3725  train_loss: 9.1642  time: 2.4305  data: 0.0001  max mem: 20909
Train Epoch: [12]  [3850/4855]  eta: 0:41:08  lr: 0.000010  ml_loss: 5.0351  mi_loss: 3.6568  train_loss: 8.6919  time: 2.4364  data: 0.0001  max mem: 20909
Train Epoch: [12]  [3900/4855]  eta: 0:39:05  lr: 0.000010  ml_loss: 4.8760  mi_loss: 3.8744  train_loss: 8.7505  time: 2.4197  data: 0.0002  max mem: 20909
Train Epoch: [12]  [3950/4855]  eta: 0:37:02  lr: 0.000010  ml_loss: 5.3987  mi_loss: 4.0119  train_loss: 9.4106  time: 2.4728  data: 0.0001  max mem: 20909
Train Epoch: [12]  [4000/4855]  eta: 0:34:59  lr: 0.000010  ml_loss: 4.7200  mi_loss: 3.8316  train_loss: 8.5516  time: 2.4492  data: 0.0001  max mem: 20909
Train Epoch: [12]  [4050/4855]  eta: 0:32:56  lr: 0.000010  ml_loss: 4.9732  mi_loss: 4.1105  train_loss: 9.0837  time: 2.4229  data: 0.0001  max mem: 20909
Train Epoch: [12]  [4100/4855]  eta: 0:30:53  lr: 0.000010  ml_loss: 4.4427  mi_loss: 4.3183  train_loss: 8.7610  time: 2.4523  data: 0.0001  max mem: 20909
Train Epoch: [12]  [4150/4855]  eta: 0:28:51  lr: 0.000010  ml_loss: 5.3614  mi_loss: 4.3132  train_loss: 9.6746  time: 2.4617  data: 0.0001  max mem: 20909
Train Epoch: [12]  [4200/4855]  eta: 0:26:48  lr: 0.000010  ml_loss: 4.5484  mi_loss: 3.9461  train_loss: 8.4945  time: 2.4402  data: 0.0001  max mem: 20909
Train Epoch: [12]  [4250/4855]  eta: 0:24:45  lr: 0.000010  ml_loss: 4.5471  mi_loss: 4.2246  train_loss: 8.7717  time: 2.4334  data: 0.0001  max mem: 20909
Train Epoch: [12]  [4300/4855]  eta: 0:22:42  lr: 0.000010  ml_loss: 4.5869  mi_loss: 3.9151  train_loss: 8.5021  time: 2.4484  data: 0.0003  max mem: 20909
Train Epoch: [12]  [4350/4855]  eta: 0:20:39  lr: 0.000010  ml_loss: 5.0459  mi_loss: 4.2585  train_loss: 9.3044  time: 2.4968  data: 0.0001  max mem: 20909
Train Epoch: [12]  [4400/4855]  eta: 0:18:37  lr: 0.000010  ml_loss: 4.7903  mi_loss: 4.2651  train_loss: 9.0553  time: 2.4848  data: 0.0001  max mem: 20909
Train Epoch: [12]  [4450/4855]  eta: 0:16:34  lr: 0.000010  ml_loss: 3.8902  mi_loss: 4.0000  train_loss: 7.8901  time: 2.4809  data: 0.0001  max mem: 20909
Train Epoch: [12]  [4500/4855]  eta: 0:14:31  lr: 0.000010  ml_loss: 5.2743  mi_loss: 4.1010  train_loss: 9.3753  time: 2.4808  data: 0.0001  max mem: 20909
Train Epoch: [12]  [4550/4855]  eta: 0:12:29  lr: 0.000010  ml_loss: 4.8263  mi_loss: 4.3464  train_loss: 9.1727  time: 2.4746  data: 0.0001  max mem: 20909
Train Epoch: [12]  [4600/4855]  eta: 0:10:26  lr: 0.000010  ml_loss: 4.9410  mi_loss: 4.2561  train_loss: 9.1971  time: 2.4664  data: 0.0001  max mem: 20909
Train Epoch: [12]  [4650/4855]  eta: 0:08:23  lr: 0.000010  ml_loss: 4.5520  mi_loss: 3.2877  train_loss: 7.8397  time: 2.4820  data: 0.0001  max mem: 20909
Train Epoch: [12]  [4700/4855]  eta: 0:06:20  lr: 0.000010  ml_loss: 5.1287  mi_loss: 3.9970  train_loss: 9.1256  time: 2.4816  data: 0.0001  max mem: 20909
Train Epoch: [12]  [4750/4855]  eta: 0:04:17  lr: 0.000010  ml_loss: 4.4111  mi_loss: 3.7693  train_loss: 8.1804  time: 2.4840  data: 0.0001  max mem: 20909
Train Epoch: [12]  [4800/4855]  eta: 0:02:15  lr: 0.000010  ml_loss: 5.1005  mi_loss: 4.1097  train_loss: 9.2102  time: 2.5034  data: 0.0002  max mem: 20909
Train Epoch: [12]  [4850/4855]  eta: 0:00:12  lr: 0.000010  ml_loss: 5.1674  mi_loss: 4.0603  train_loss: 9.2277  time: 2.4669  data: 0.0001  max mem: 20909
Train Epoch: [12]  [4854/4855]  eta: 0:00:02  lr: 0.000010  ml_loss: 4.1748  mi_loss: 2.5430  train_loss: 6.7178  time: 2.4756  data: 0.0006  max mem: 20909
Train Epoch: [12] Total time: 3:18:53 (2.4580 s / it)
Val Epoch: [12]  [  0/540]  eta: 0:23:38  ml_loss: 5.2335  mi_loss: 4.1366  val_loss: 9.3702  accML: 0.2178  accMI: 0.1243  time: 2.6274  data: 2.2659  max mem: 20909
Val Epoch: [12]  [ 50/540]  eta: 0:06:32  ml_loss: 4.7415  mi_loss: 3.8211  val_loss: 8.5626  accML: 0.2975  accMI: 0.1823  time: 0.7777  data: 0.6161  max mem: 20909
Val Epoch: [12]  [100/540]  eta: 0:05:51  ml_loss: 4.4499  mi_loss: 4.3207  val_loss: 8.7705  accML: 0.2657  accMI: 0.1360  time: 0.7678  data: 0.6057  max mem: 20909
Val Epoch: [12]  [150/540]  eta: 0:05:23  ml_loss: 4.6975  mi_loss: 4.5733  val_loss: 9.2708  accML: 0.2332  accMI: 0.1213  time: 0.9279  data: 0.7645  max mem: 20909
Val Epoch: [12]  [200/540]  eta: 0:04:42  ml_loss: 4.8271  mi_loss: 4.3300  val_loss: 9.1571  accML: 0.2605  accMI: 0.1257  time: 0.8376  data: 0.6750  max mem: 20909
Val Epoch: [12]  [250/540]  eta: 0:04:00  ml_loss: 4.3569  mi_loss: 3.9038  val_loss: 8.2607  accML: 0.3340  accMI: 0.1576  time: 0.8434  data: 0.6810  max mem: 20909
Val Epoch: [12]  [300/540]  eta: 0:03:18  ml_loss: 4.2522  mi_loss: 3.8729  val_loss: 8.1251  accML: 0.2976  accMI: 0.1559  time: 0.8647  data: 0.7012  max mem: 20909
Val Epoch: [12]  [350/540]  eta: 0:02:37  ml_loss: 4.7546  mi_loss: 3.1513  val_loss: 7.9060  accML: 0.2500  accMI: 0.3040  time: 0.8205  data: 0.6578  max mem: 20909
Val Epoch: [12]  [400/540]  eta: 0:01:57  ml_loss: 5.4369  mi_loss: 4.2806  val_loss: 9.7174  accML: 0.1935  accMI: 0.1210  time: 0.8782  data: 0.7147  max mem: 20909
Val Epoch: [12]  [450/540]  eta: 0:01:15  ml_loss: 4.8903  mi_loss: 4.0636  val_loss: 8.9539  accML: 0.2416  accMI: 0.1307  time: 0.8605  data: 0.6972  max mem: 20909
Val Epoch: [12]  [500/540]  eta: 0:00:33  ml_loss: 5.0116  mi_loss: 3.9442  val_loss: 8.9557  accML: 0.2650  accMI: 0.1459  time: 0.7734  data: 0.6110  max mem: 20909
Val Epoch: [12]  [539/540]  eta: 0:00:00  ml_loss: 5.1791  mi_loss: 3.9322  val_loss: 9.1113  accML: 0.2008  accMI: 0.1892  time: 0.7692  data: 0.6090  max mem: 20909
Val Epoch: [12] Total time: 0:07:33 (0.8404 s / it)
epoch:12, iter:63114, 4854,  train_loss: 6.717835426330566, valid_loss: 8.813896953618086, idiv_loss:(4.725139429392638, 4.088757559105202), acc:(0.26026312112808225, 0.15570657584402298)
Averaged stats: lr: 0.0000  ml_loss: 4.8096  mi_loss: 4.0467  train_loss: 8.8563
epoch 12 6.717835426330566
Train Epoch: [13]  [   0/4855]  eta: 7:52:53  lr: 0.000010  ml_loss: 4.7025  mi_loss: 3.7666  train_loss: 8.4692  time: 5.8442  data: 3.3456  max mem: 20909
Train Epoch: [13]  [  50/4855]  eta: 3:24:02  lr: 0.000010  ml_loss: 4.4952  mi_loss: 3.6164  train_loss: 8.1115  time: 2.4801  data: 0.0001  max mem: 20909
Train Epoch: [13]  [ 100/4855]  eta: 3:19:16  lr: 0.000010  ml_loss: 5.1021  mi_loss: 3.5396  train_loss: 8.6417  time: 2.4780  data: 0.0001  max mem: 20909
Train Epoch: [13]  [ 150/4855]  eta: 3:16:03  lr: 0.000010  ml_loss: 3.5485  mi_loss: 4.0618  train_loss: 7.6103  time: 2.4741  data: 0.0001  max mem: 20909
Train Epoch: [13]  [ 200/4855]  eta: 3:13:32  lr: 0.000010  ml_loss: 4.9234  mi_loss: 3.3237  train_loss: 8.2472  time: 2.4832  data: 0.0001  max mem: 20909
Train Epoch: [13]  [ 250/4855]  eta: 3:10:51  lr: 0.000010  ml_loss: 4.8551  mi_loss: 4.1249  train_loss: 8.9800  time: 2.4345  data: 0.0001  max mem: 20909
Train Epoch: [13]  [ 300/4855]  eta: 3:08:36  lr: 0.000010  ml_loss: 4.4625  mi_loss: 3.4865  train_loss: 7.9490  time: 2.4713  data: 0.0001  max mem: 20909
Train Epoch: [13]  [ 350/4855]  eta: 3:06:17  lr: 0.000010  ml_loss: 4.9829  mi_loss: 4.1412  train_loss: 9.1241  time: 2.4586  data: 0.0001  max mem: 20909
Train Epoch: [13]  [ 400/4855]  eta: 3:04:05  lr: 0.000010  ml_loss: 4.7373  mi_loss: 3.8786  train_loss: 8.6159  time: 2.4737  data: 0.0001  max mem: 20909
Train Epoch: [13]  [ 450/4855]  eta: 3:02:01  lr: 0.000010  ml_loss: 4.7249  mi_loss: 4.2745  train_loss: 8.9993  time: 2.4708  data: 0.0001  max mem: 20909
Train Epoch: [13]  [ 500/4855]  eta: 2:59:54  lr: 0.000010  ml_loss: 5.0880  mi_loss: 3.0591  train_loss: 8.1471  time: 2.4809  data: 0.0001  max mem: 20909
Train Epoch: [13]  [ 550/4855]  eta: 2:57:48  lr: 0.000010  ml_loss: 4.5574  mi_loss: 3.6867  train_loss: 8.2441  time: 2.4686  data: 0.0001  max mem: 20909
Train Epoch: [13]  [ 600/4855]  eta: 2:55:22  lr: 0.000010  ml_loss: 4.8450  mi_loss: 3.9812  train_loss: 8.8261  time: 2.4265  data: 0.0001  max mem: 20909
Train Epoch: [13]  [ 650/4855]  eta: 2:53:03  lr: 0.000010  ml_loss: 4.8116  mi_loss: 4.3250  train_loss: 9.1366  time: 2.4359  data: 0.0001  max mem: 20909
Train Epoch: [13]  [ 700/4855]  eta: 2:50:51  lr: 0.000010  ml_loss: 4.5721  mi_loss: 4.1458  train_loss: 8.7179  time: 2.4461  data: 0.0001  max mem: 20909
Train Epoch: [13]  [ 750/4855]  eta: 2:48:37  lr: 0.000010  ml_loss: 5.1260  mi_loss: 4.1712  train_loss: 9.2973  time: 2.4370  data: 0.0001  max mem: 20909
Train Epoch: [13]  [ 800/4855]  eta: 2:46:27  lr: 0.000010  ml_loss: 4.6059  mi_loss: 3.2705  train_loss: 7.8764  time: 2.4398  data: 0.0001  max mem: 20909
Train Epoch: [13]  [ 850/4855]  eta: 2:44:20  lr: 0.000010  ml_loss: 5.4538  mi_loss: 4.2699  train_loss: 9.7237  time: 2.4545  data: 0.0001  max mem: 20909
Train Epoch: [13]  [ 900/4855]  eta: 2:42:16  lr: 0.000010  ml_loss: 5.0081  mi_loss: 4.0149  train_loss: 9.0230  time: 2.4620  data: 0.0001  max mem: 20909
Train Epoch: [13]  [ 950/4855]  eta: 2:40:12  lr: 0.000010  ml_loss: 5.1435  mi_loss: 3.4269  train_loss: 8.5704  time: 2.4535  data: 0.0001  max mem: 20909
Train Epoch: [13]  [1000/4855]  eta: 2:38:06  lr: 0.000010  ml_loss: 4.6501  mi_loss: 3.7454  train_loss: 8.3955  time: 2.4468  data: 0.0001  max mem: 20909
Train Epoch: [13]  [1050/4855]  eta: 2:36:02  lr: 0.000010  ml_loss: 5.0930  mi_loss: 3.9442  train_loss: 9.0372  time: 2.4596  data: 0.0001  max mem: 20909
Train Epoch: [13]  [1100/4855]  eta: 2:33:54  lr: 0.000010  ml_loss: 5.3338  mi_loss: 3.7240  train_loss: 9.0579  time: 2.4306  data: 0.0001  max mem: 20909
Train Epoch: [13]  [1150/4855]  eta: 2:31:48  lr: 0.000010  ml_loss: 4.8157  mi_loss: 3.7417  train_loss: 8.5575  time: 2.4389  data: 0.0001  max mem: 20909
Train Epoch: [13]  [1200/4855]  eta: 2:29:39  lr: 0.000010  ml_loss: 4.9391  mi_loss: 4.3441  train_loss: 9.2831  time: 2.4184  data: 0.0001  max mem: 20909
Train Epoch: [13]  [1250/4855]  eta: 2:27:35  lr: 0.000010  ml_loss: 4.3870  mi_loss: 4.0152  train_loss: 8.4022  time: 2.4668  data: 0.0001  max mem: 20909
Train Epoch: [13]  [1300/4855]  eta: 2:25:32  lr: 0.000010  ml_loss: 5.0176  mi_loss: 4.1908  train_loss: 9.2084  time: 2.4582  data: 0.0001  max mem: 20909
Train Epoch: [13]  [1350/4855]  eta: 2:23:25  lr: 0.000010  ml_loss: 5.3043  mi_loss: 4.3890  train_loss: 9.6933  time: 2.4236  data: 0.0001  max mem: 20909
Train Epoch: [13]  [1400/4855]  eta: 2:21:22  lr: 0.000010  ml_loss: 4.9238  mi_loss: 4.3270  train_loss: 9.2508  time: 2.4526  data: 0.0001  max mem: 20909
Train Epoch: [13]  [1450/4855]  eta: 2:19:19  lr: 0.000010  ml_loss: 4.9706  mi_loss: 3.8502  train_loss: 8.8208  time: 2.4565  data: 0.0001  max mem: 20909
Train Epoch: [13]  [1500/4855]  eta: 2:17:18  lr: 0.000010  ml_loss: 4.7491  mi_loss: 4.0558  train_loss: 8.8049  time: 2.4586  data: 0.0001  max mem: 20909
Train Epoch: [13]  [1550/4855]  eta: 2:15:14  lr: 0.000010  ml_loss: 5.0310  mi_loss: 3.7109  train_loss: 8.7420  time: 2.4320  data: 0.0001  max mem: 20909
Train Epoch: [13]  [1600/4855]  eta: 2:13:10  lr: 0.000010  ml_loss: 4.7390  mi_loss: 3.8060  train_loss: 8.5449  time: 2.4458  data: 0.0001  max mem: 20909
Train Epoch: [13]  [1650/4855]  eta: 2:11:06  lr: 0.000010  ml_loss: 4.6467  mi_loss: 3.8946  train_loss: 8.5413  time: 2.4197  data: 0.0001  max mem: 20909
Train Epoch: [13]  [1700/4855]  eta: 2:09:03  lr: 0.000010  ml_loss: 4.9359  mi_loss: 4.2649  train_loss: 9.2008  time: 2.4525  data: 0.0001  max mem: 20909
Train Epoch: [13]  [1750/4855]  eta: 2:06:58  lr: 0.000010  ml_loss: 5.2853  mi_loss: 4.1111  train_loss: 9.3964  time: 2.4360  data: 0.0001  max mem: 20909
Train Epoch: [13]  [1800/4855]  eta: 2:04:54  lr: 0.000010  ml_loss: 4.1337  mi_loss: 4.2742  train_loss: 8.4079  time: 2.4242  data: 0.0001  max mem: 20909
Train Epoch: [13]  [1850/4855]  eta: 2:02:51  lr: 0.000010  ml_loss: 5.0625  mi_loss: 4.2224  train_loss: 9.2849  time: 2.4340  data: 0.0001  max mem: 20909
Train Epoch: [13]  [1900/4855]  eta: 2:00:48  lr: 0.000010  ml_loss: 4.5079  mi_loss: 4.0709  train_loss: 8.5789  time: 2.4340  data: 0.0001  max mem: 20909
Train Epoch: [13]  [1950/4855]  eta: 1:58:44  lr: 0.000010  ml_loss: 5.0709  mi_loss: 3.8270  train_loss: 8.8979  time: 2.4428  data: 0.0001  max mem: 20909
Train Epoch: [13]  [2000/4855]  eta: 1:56:41  lr: 0.000010  ml_loss: 4.1724  mi_loss: 4.1715  train_loss: 8.3439  time: 2.4751  data: 0.0001  max mem: 20909
Train Epoch: [13]  [2050/4855]  eta: 1:54:39  lr: 0.000010  ml_loss: 4.1434  mi_loss: 3.9295  train_loss: 8.0729  time: 2.4762  data: 0.0002  max mem: 20909
Train Epoch: [13]  [2100/4855]  eta: 1:52:37  lr: 0.000010  ml_loss: 4.7537  mi_loss: 3.8559  train_loss: 8.6095  time: 2.4625  data: 0.0001  max mem: 20909
Train Epoch: [13]  [2150/4855]  eta: 1:50:34  lr: 0.000010  ml_loss: 5.3086  mi_loss: 3.4484  train_loss: 8.7570  time: 2.4429  data: 0.0001  max mem: 20909
Train Epoch: [13]  [2200/4855]  eta: 1:48:30  lr: 0.000010  ml_loss: 5.3038  mi_loss: 3.8325  train_loss: 9.1363  time: 2.4276  data: 0.0001  max mem: 20909
Train Epoch: [13]  [2250/4855]  eta: 1:46:27  lr: 0.000010  ml_loss: 4.3703  mi_loss: 4.2305  train_loss: 8.6009  time: 2.4571  data: 0.0001  max mem: 20909
Train Epoch: [13]  [2300/4855]  eta: 1:44:26  lr: 0.000010  ml_loss: 4.8817  mi_loss: 4.1931  train_loss: 9.0748  time: 2.4682  data: 0.0001  max mem: 20909
Train Epoch: [13]  [2350/4855]  eta: 1:42:23  lr: 0.000010  ml_loss: 4.5382  mi_loss: 3.8922  train_loss: 8.4305  time: 2.4316  data: 0.0001  max mem: 20909
Train Epoch: [13]  [2400/4855]  eta: 1:40:21  lr: 0.000010  ml_loss: 4.9542  mi_loss: 3.7793  train_loss: 8.7334  time: 2.4696  data: 0.0002  max mem: 20909
Train Epoch: [13]  [2450/4855]  eta: 1:38:19  lr: 0.000010  ml_loss: 5.3829  mi_loss: 3.9333  train_loss: 9.3162  time: 2.4771  data: 0.0001  max mem: 20909
Train Epoch: [13]  [2500/4855]  eta: 1:36:17  lr: 0.000010  ml_loss: 4.8563  mi_loss: 4.3185  train_loss: 9.1748  time: 2.4861  data: 0.0001  max mem: 20909
Train Epoch: [13]  [2550/4855]  eta: 1:34:15  lr: 0.000010  ml_loss: 4.9492  mi_loss: 3.7605  train_loss: 8.7097  time: 2.4808  data: 0.0001  max mem: 20909
Train Epoch: [13]  [2600/4855]  eta: 1:32:13  lr: 0.000010  ml_loss: 4.8731  mi_loss: 3.3663  train_loss: 8.2395  time: 2.4878  data: 0.0001  max mem: 20909
Train Epoch: [13]  [2650/4855]  eta: 1:30:11  lr: 0.000010  ml_loss: 5.2650  mi_loss: 4.0955  train_loss: 9.3605  time: 2.4900  data: 0.0001  max mem: 20909
Train Epoch: [13]  [2700/4855]  eta: 1:28:09  lr: 0.000010  ml_loss: 4.2914  mi_loss: 3.7729  train_loss: 8.0643  time: 2.4968  data: 0.0001  max mem: 20909
Train Epoch: [13]  [2750/4855]  eta: 1:26:07  lr: 0.000010  ml_loss: 4.5989  mi_loss: 3.8913  train_loss: 8.4902  time: 2.4610  data: 0.0001  max mem: 20909
Train Epoch: [13]  [2800/4855]  eta: 1:24:05  lr: 0.000010  ml_loss: 5.4113  mi_loss: 4.4949  train_loss: 9.9061  time: 2.4632  data: 0.0001  max mem: 20909
Train Epoch: [13]  [2850/4855]  eta: 1:22:03  lr: 0.000010  ml_loss: 5.2274  mi_loss: 3.9173  train_loss: 9.1448  time: 2.4699  data: 0.0001  max mem: 20909
Train Epoch: [13]  [2900/4855]  eta: 1:20:00  lr: 0.000010  ml_loss: 5.3482  mi_loss: 3.7126  train_loss: 9.0608  time: 2.4632  data: 0.0001  max mem: 20909
Train Epoch: [13]  [2950/4855]  eta: 1:17:57  lr: 0.000010  ml_loss: 4.7035  mi_loss: 4.1530  train_loss: 8.8565  time: 2.4568  data: 0.0001  max mem: 20909
Train Epoch: [13]  [3000/4855]  eta: 1:15:55  lr: 0.000010  ml_loss: 4.4954  mi_loss: 3.3020  train_loss: 7.7975  time: 2.4704  data: 0.0001  max mem: 20909
Train Epoch: [13]  [3050/4855]  eta: 1:13:53  lr: 0.000010  ml_loss: 4.9591  mi_loss: 3.6806  train_loss: 8.6397  time: 2.4670  data: 0.0001  max mem: 20909
Train Epoch: [13]  [3100/4855]  eta: 1:11:50  lr: 0.000010  ml_loss: 5.0998  mi_loss: 3.8159  train_loss: 8.9157  time: 2.4755  data: 0.0001  max mem: 20909
Train Epoch: [13]  [3150/4855]  eta: 1:09:48  lr: 0.000010  ml_loss: 4.9680  mi_loss: 4.2360  train_loss: 9.2040  time: 2.4698  data: 0.0001  max mem: 20909
Train Epoch: [13]  [3200/4855]  eta: 1:07:45  lr: 0.000010  ml_loss: 4.6409  mi_loss: 3.3846  train_loss: 8.0255  time: 2.4492  data: 0.0001  max mem: 20909
Train Epoch: [13]  [3250/4855]  eta: 1:05:43  lr: 0.000010  ml_loss: 5.0382  mi_loss: 4.0041  train_loss: 9.0423  time: 2.4702  data: 0.0001  max mem: 20909
Train Epoch: [13]  [3300/4855]  eta: 1:03:40  lr: 0.000010  ml_loss: 5.1347  mi_loss: 4.2797  train_loss: 9.4144  time: 2.4472  data: 0.0001  max mem: 20909
Train Epoch: [13]  [3350/4855]  eta: 1:01:37  lr: 0.000010  ml_loss: 4.6956  mi_loss: 4.1374  train_loss: 8.8330  time: 2.4733  data: 0.0001  max mem: 20909
Train Epoch: [13]  [3400/4855]  eta: 0:59:34  lr: 0.000010  ml_loss: 4.9430  mi_loss: 3.9955  train_loss: 8.9384  time: 2.4613  data: 0.0001  max mem: 20909
Train Epoch: [13]  [3450/4855]  eta: 0:57:32  lr: 0.000010  ml_loss: 4.6312  mi_loss: 3.8072  train_loss: 8.4385  time: 2.4851  data: 0.0001  max mem: 20909
Train Epoch: [13]  [3500/4855]  eta: 0:55:29  lr: 0.000010  ml_loss: 4.4120  mi_loss: 3.8211  train_loss: 8.2331  time: 2.4679  data: 0.0001  max mem: 20909
Train Epoch: [13]  [3550/4855]  eta: 0:53:26  lr: 0.000010  ml_loss: 4.8689  mi_loss: 4.2750  train_loss: 9.1439  time: 2.4794  data: 0.0001  max mem: 20909
Train Epoch: [13]  [3600/4855]  eta: 0:51:24  lr: 0.000010  ml_loss: 4.8783  mi_loss: 3.9312  train_loss: 8.8095  time: 2.4902  data: 0.0001  max mem: 20909
Train Epoch: [13]  [3650/4855]  eta: 0:49:22  lr: 0.000010  ml_loss: 4.3387  mi_loss: 4.2311  train_loss: 8.5697  time: 2.5004  data: 0.0001  max mem: 20909
Train Epoch: [13]  [3700/4855]  eta: 0:47:20  lr: 0.000010  ml_loss: 3.7977  mi_loss: 3.9752  train_loss: 7.7729  time: 2.5063  data: 0.0001  max mem: 20909
Train Epoch: [13]  [3750/4855]  eta: 0:45:17  lr: 0.000010  ml_loss: 4.7154  mi_loss: 4.1560  train_loss: 8.8714  time: 2.4691  data: 0.0001  max mem: 20909
Train Epoch: [13]  [3800/4855]  eta: 0:43:15  lr: 0.000010  ml_loss: 5.2723  mi_loss: 3.9178  train_loss: 9.1901  time: 2.4950  data: 0.0001  max mem: 20909
Train Epoch: [13]  [3850/4855]  eta: 0:41:12  lr: 0.000010  ml_loss: 5.2735  mi_loss: 3.9386  train_loss: 9.2121  time: 2.4738  data: 0.0001  max mem: 20909
Train Epoch: [13]  [3900/4855]  eta: 0:39:09  lr: 0.000010  ml_loss: 5.0955  mi_loss: 3.9275  train_loss: 9.0230  time: 2.4736  data: 0.0002  max mem: 20909
Train Epoch: [13]  [3950/4855]  eta: 0:37:06  lr: 0.000010  ml_loss: 4.6854  mi_loss: 3.8183  train_loss: 8.5038  time: 2.4676  data: 0.0001  max mem: 20909
Train Epoch: [13]  [4000/4855]  eta: 0:35:03  lr: 0.000010  ml_loss: 4.7518  mi_loss: 3.8754  train_loss: 8.6272  time: 2.4676  data: 0.0001  max mem: 20909
Train Epoch: [13]  [4050/4855]  eta: 0:33:00  lr: 0.000010  ml_loss: 5.3763  mi_loss: 3.8218  train_loss: 9.1982  time: 2.4552  data: 0.0001  max mem: 20909
Train Epoch: [13]  [4100/4855]  eta: 0:30:57  lr: 0.000010  ml_loss: 4.8565  mi_loss: 3.5566  train_loss: 8.4130  time: 2.4783  data: 0.0001  max mem: 20909
Train Epoch: [13]  [4150/4855]  eta: 0:28:54  lr: 0.000010  ml_loss: 4.7191  mi_loss: 3.9384  train_loss: 8.6574  time: 2.4660  data: 0.0001  max mem: 20909
Train Epoch: [13]  [4200/4855]  eta: 0:26:51  lr: 0.000010  ml_loss: 4.4328  mi_loss: 3.9645  train_loss: 8.3974  time: 2.4707  data: 0.0001  max mem: 20909
Train Epoch: [13]  [4250/4855]  eta: 0:24:48  lr: 0.000010  ml_loss: 4.4408  mi_loss: 3.2699  train_loss: 7.7108  time: 2.4576  data: 0.0001  max mem: 20909
Train Epoch: [13]  [4300/4855]  eta: 0:22:45  lr: 0.000010  ml_loss: 4.8932  mi_loss: 4.0913  train_loss: 8.9845  time: 2.4944  data: 0.0001  max mem: 20909
Train Epoch: [13]  [4350/4855]  eta: 0:20:43  lr: 0.000010  ml_loss: 5.1817  mi_loss: 3.9105  train_loss: 9.0922  time: 2.4931  data: 0.0001  max mem: 20909
Train Epoch: [13]  [4400/4855]  eta: 0:18:40  lr: 0.000010  ml_loss: 4.8935  mi_loss: 4.4516  train_loss: 9.3451  time: 2.4727  data: 0.0001  max mem: 20909
Train Epoch: [13]  [4450/4855]  eta: 0:16:36  lr: 0.000010  ml_loss: 4.5839  mi_loss: 4.5430  train_loss: 9.1270  time: 2.4475  data: 0.0001  max mem: 20909
Train Epoch: [13]  [4500/4855]  eta: 0:14:33  lr: 0.000010  ml_loss: 4.7682  mi_loss: 3.9159  train_loss: 8.6841  time: 2.4900  data: 0.0001  max mem: 20909
Train Epoch: [13]  [4550/4855]  eta: 0:12:30  lr: 0.000010  ml_loss: 4.7437  mi_loss: 3.8732  train_loss: 8.6169  time: 2.4751  data: 0.0001  max mem: 20909
Train Epoch: [13]  [4600/4855]  eta: 0:10:27  lr: 0.000010  ml_loss: 4.6561  mi_loss: 3.2968  train_loss: 7.9529  time: 2.4875  data: 0.0001  max mem: 20909
Train Epoch: [13]  [4650/4855]  eta: 0:08:24  lr: 0.000010  ml_loss: 5.0121  mi_loss: 3.9300  train_loss: 8.9420  time: 2.4630  data: 0.0001  max mem: 20909
Train Epoch: [13]  [4700/4855]  eta: 0:06:21  lr: 0.000010  ml_loss: 4.6051  mi_loss: 4.2543  train_loss: 8.8594  time: 2.4812  data: 0.0001  max mem: 20909
Train Epoch: [13]  [4750/4855]  eta: 0:04:18  lr: 0.000010  ml_loss: 4.3990  mi_loss: 3.7003  train_loss: 8.0993  time: 2.5017  data: 0.0001  max mem: 20909
Train Epoch: [13]  [4800/4855]  eta: 0:02:15  lr: 0.000010  ml_loss: 5.0548  mi_loss: 4.1254  train_loss: 9.1802  time: 2.5056  data: 0.0001  max mem: 20909
Train Epoch: [13]  [4850/4855]  eta: 0:00:12  lr: 0.000010  ml_loss: 5.2082  mi_loss: 3.8325  train_loss: 9.0408  time: 2.4741  data: 0.0001  max mem: 20909
Train Epoch: [13]  [4854/4855]  eta: 0:00:02  lr: 0.000010  ml_loss: 5.1147  mi_loss: 3.9453  train_loss: 9.0601  time: 2.4811  data: 0.0006  max mem: 20909
Train Epoch: [13] Total time: 3:19:21 (2.4638 s / it)
Val Epoch: [13]  [  0/540]  eta: 0:24:43  ml_loss: 4.7282  mi_loss: 4.1182  val_loss: 8.8464  accML: 0.2762  accMI: 0.1054  time: 2.7478  data: 2.3680  max mem: 20909
Val Epoch: [13]  [ 50/540]  eta: 0:06:35  ml_loss: 4.6218  mi_loss: 3.7986  val_loss: 8.4204  accML: 0.2976  accMI: 0.1850  time: 0.7804  data: 0.6189  max mem: 20909
Val Epoch: [13]  [100/540]  eta: 0:05:54  ml_loss: 4.4781  mi_loss: 4.2888  val_loss: 8.7669  accML: 0.2904  accMI: 0.1440  time: 0.7791  data: 0.6169  max mem: 20909
Val Epoch: [13]  [150/540]  eta: 0:05:23  ml_loss: 4.9124  mi_loss: 4.4784  val_loss: 9.3907  accML: 0.2263  accMI: 0.1267  time: 0.9125  data: 0.7488  max mem: 20909
Val Epoch: [13]  [200/540]  eta: 0:04:43  ml_loss: 4.7896  mi_loss: 4.3519  val_loss: 9.1415  accML: 0.2484  accMI: 0.1257  time: 0.8379  data: 0.6749  max mem: 20909
Val Epoch: [13]  [250/540]  eta: 0:04:00  ml_loss: 4.4323  mi_loss: 3.8111  val_loss: 8.2435  accML: 0.3043  accMI: 0.1766  time: 0.8450  data: 0.6824  max mem: 20909
Val Epoch: [13]  [300/540]  eta: 0:03:19  ml_loss: 4.3652  mi_loss: 3.8412  val_loss: 8.2064  accML: 0.2960  accMI: 0.1909  time: 0.8876  data: 0.7240  max mem: 20909
Val Epoch: [13]  [350/540]  eta: 0:02:37  ml_loss: 4.6799  mi_loss: 3.1228  val_loss: 7.8027  accML: 0.2505  accMI: 0.3040  time: 0.8006  data: 0.6385  max mem: 20909
Val Epoch: [13]  [400/540]  eta: 0:01:57  ml_loss: 5.1129  mi_loss: 4.2870  val_loss: 9.4000  accML: 0.2450  accMI: 0.1102  time: 0.8656  data: 0.7028  max mem: 20909
Val Epoch: [13]  [450/540]  eta: 0:01:15  ml_loss: 5.2322  mi_loss: 3.9921  val_loss: 9.2244  accML: 0.1973  accMI: 0.1413  time: 0.8561  data: 0.6934  max mem: 20909
Val Epoch: [13]  [500/540]  eta: 0:00:33  ml_loss: 4.9594  mi_loss: 3.9228  val_loss: 8.8821  accML: 0.2577  accMI: 0.1568  time: 0.7531  data: 0.5914  max mem: 20909
Val Epoch: [13]  [539/540]  eta: 0:00:00  ml_loss: 5.0047  mi_loss: 4.0914  val_loss: 9.0961  accML: 0.2158  accMI: 0.1532  time: 0.7810  data: 0.6206  max mem: 20909
Val Epoch: [13] Total time: 0:07:33 (0.8404 s / it)
epoch:13, iter:67969, 4854,  train_loss: 9.060059547424316, valid_loss: 8.712005414786162, idiv_loss:(4.6855171887962905, 4.026488194200728), acc:(0.2639959238469601, 0.16058448720033522)
Averaged stats: lr: 0.0000  ml_loss: 4.7619  mi_loss: 3.9703  train_loss: 8.7322
epoch 13 9.060059547424316
Train Epoch: [14]  [   0/4855]  eta: 7:30:30  lr: 0.000010  ml_loss: 4.8260  mi_loss: 4.5026  train_loss: 9.3286  time: 5.5676  data: 2.2201  max mem: 20909
Train Epoch: [14]  [  50/4855]  eta: 3:24:30  lr: 0.000010  ml_loss: 5.0632  mi_loss: 4.1312  train_loss: 9.1944  time: 2.4960  data: 0.0001  max mem: 20909
Train Epoch: [14]  [ 100/4855]  eta: 3:20:02  lr: 0.000010  ml_loss: 4.6676  mi_loss: 3.8540  train_loss: 8.5216  time: 2.4843  data: 0.0001  max mem: 20909
Train Epoch: [14]  [ 150/4855]  eta: 3:16:19  lr: 0.000010  ml_loss: 4.4802  mi_loss: 3.8897  train_loss: 8.3699  time: 2.4616  data: 0.0001  max mem: 20909
Train Epoch: [14]  [ 200/4855]  eta: 3:13:30  lr: 0.000010  ml_loss: 4.1780  mi_loss: 3.8554  train_loss: 8.0334  time: 2.4768  data: 0.0001  max mem: 20909
Train Epoch: [14]  [ 250/4855]  eta: 3:11:08  lr: 0.000010  ml_loss: 5.0346  mi_loss: 4.0705  train_loss: 9.1051  time: 2.4812  data: 0.0001  max mem: 20909
Train Epoch: [14]  [ 300/4855]  eta: 3:08:55  lr: 0.000010  ml_loss: 4.9557  mi_loss: 4.3061  train_loss: 9.2618  time: 2.4808  data: 0.0001  max mem: 20909
Train Epoch: [14]  [ 350/4855]  eta: 3:06:29  lr: 0.000010  ml_loss: 5.0052  mi_loss: 3.9349  train_loss: 8.9400  time: 2.4453  data: 0.0001  max mem: 20909
Train Epoch: [14]  [ 400/4855]  eta: 3:04:23  lr: 0.000010  ml_loss: 4.3603  mi_loss: 3.1755  train_loss: 7.5358  time: 2.4722  data: 0.0001  max mem: 20909
Train Epoch: [14]  [ 450/4855]  eta: 3:02:16  lr: 0.000010  ml_loss: 4.5885  mi_loss: 4.0683  train_loss: 8.6568  time: 2.4803  data: 0.0001  max mem: 20909
Train Epoch: [14]  [ 500/4855]  eta: 3:00:10  lr: 0.000010  ml_loss: 4.6743  mi_loss: 4.3063  train_loss: 8.9806  time: 2.4721  data: 0.0001  max mem: 20909
Train Epoch: [14]  [ 550/4855]  eta: 2:57:58  lr: 0.000010  ml_loss: 4.8480  mi_loss: 3.8703  train_loss: 8.7183  time: 2.4696  data: 0.0001  max mem: 20909
Train Epoch: [14]  [ 600/4855]  eta: 2:55:51  lr: 0.000010  ml_loss: 4.8744  mi_loss: 4.2416  train_loss: 9.1160  time: 2.4636  data: 0.0001  max mem: 20909
Train Epoch: [14]  [ 650/4855]  eta: 2:53:41  lr: 0.000010  ml_loss: 5.0640  mi_loss: 3.9584  train_loss: 9.0225  time: 2.4545  data: 0.0001  max mem: 20909
Train Epoch: [14]  [ 700/4855]  eta: 2:51:33  lr: 0.000010  ml_loss: 4.8273  mi_loss: 3.4633  train_loss: 8.2906  time: 2.4656  data: 0.0001  max mem: 20909
Train Epoch: [14]  [ 750/4855]  eta: 2:49:28  lr: 0.000010  ml_loss: 3.8178  mi_loss: 3.3459  train_loss: 7.1638  time: 2.4656  data: 0.0001  max mem: 20909
Train Epoch: [14]  [ 800/4855]  eta: 2:47:23  lr: 0.000010  ml_loss: 4.9353  mi_loss: 3.9845  train_loss: 8.9198  time: 2.5021  data: 0.0001  max mem: 20909
Train Epoch: [14]  [ 850/4855]  eta: 2:45:18  lr: 0.000010  ml_loss: 4.8224  mi_loss: 4.0659  train_loss: 8.8883  time: 2.4672  data: 0.0001  max mem: 20909
Train Epoch: [14]  [ 900/4855]  eta: 2:43:13  lr: 0.000010  ml_loss: 4.6949  mi_loss: 4.5191  train_loss: 9.2140  time: 2.4612  data: 0.0001  max mem: 20909
Train Epoch: [14]  [ 950/4855]  eta: 2:41:07  lr: 0.000010  ml_loss: 4.4706  mi_loss: 3.8776  train_loss: 8.3482  time: 2.4652  data: 0.0002  max mem: 20909
Train Epoch: [14]  [1000/4855]  eta: 2:39:04  lr: 0.000010  ml_loss: 4.7892  mi_loss: 4.0758  train_loss: 8.8650  time: 2.4857  data: 0.0001  max mem: 20909
Train Epoch: [14]  [1050/4855]  eta: 2:36:59  lr: 0.000010  ml_loss: 4.0250  mi_loss: 4.3666  train_loss: 8.3916  time: 2.4487  data: 0.0001  max mem: 20909
Train Epoch: [14]  [1100/4855]  eta: 2:34:48  lr: 0.000010  ml_loss: 4.8888  mi_loss: 3.9427  train_loss: 8.8315  time: 2.4372  data: 0.0001  max mem: 20909
Train Epoch: [14]  [1150/4855]  eta: 2:32:37  lr: 0.000010  ml_loss: 4.6930  mi_loss: 4.1359  train_loss: 8.8289  time: 2.4374  data: 0.0001  max mem: 20909
Train Epoch: [14]  [1200/4855]  eta: 2:30:30  lr: 0.000010  ml_loss: 5.1634  mi_loss: 3.4851  train_loss: 8.6485  time: 2.4692  data: 0.0001  max mem: 20909
Train Epoch: [14]  [1250/4855]  eta: 2:28:22  lr: 0.000010  ml_loss: 4.6658  mi_loss: 3.9909  train_loss: 8.6568  time: 2.4352  data: 0.0001  max mem: 20909
Train Epoch: [14]  [1300/4855]  eta: 2:26:14  lr: 0.000010  ml_loss: 4.3201  mi_loss: 4.9407  train_loss: 9.2607  time: 2.4341  data: 0.0001  max mem: 20909
Train Epoch: [14]  [1350/4855]  eta: 2:24:06  lr: 0.000010  ml_loss: 5.0850  mi_loss: 4.0401  train_loss: 9.1251  time: 2.4379  data: 0.0001  max mem: 20909
Train Epoch: [14]  [1400/4855]  eta: 2:22:02  lr: 0.000010  ml_loss: 4.4170  mi_loss: 4.0006  train_loss: 8.4176  time: 2.4755  data: 0.0001  max mem: 20909
Train Epoch: [14]  [1450/4855]  eta: 2:19:54  lr: 0.000010  ml_loss: 4.2666  mi_loss: 3.7166  train_loss: 7.9832  time: 2.4274  data: 0.0001  max mem: 20909
Train Epoch: [14]  [1500/4855]  eta: 2:17:50  lr: 0.000010  ml_loss: 5.0628  mi_loss: 3.6322  train_loss: 8.6950  time: 2.4542  data: 0.0001  max mem: 20909
Train Epoch: [14]  [1550/4855]  eta: 2:15:44  lr: 0.000010  ml_loss: 5.0304  mi_loss: 3.9558  train_loss: 8.9862  time: 2.4441  data: 0.0001  max mem: 20909
Train Epoch: [14]  [1600/4855]  eta: 2:13:38  lr: 0.000010  ml_loss: 4.8562  mi_loss: 3.3781  train_loss: 8.2343  time: 2.4551  data: 0.0001  max mem: 20909
Train Epoch: [14]  [1650/4855]  eta: 2:11:35  lr: 0.000010  ml_loss: 4.7719  mi_loss: 3.9666  train_loss: 8.7385  time: 2.4870  data: 0.0001  max mem: 20909
Train Epoch: [14]  [1700/4855]  eta: 2:09:34  lr: 0.000010  ml_loss: 4.8973  mi_loss: 3.3322  train_loss: 8.2294  time: 2.4812  data: 0.0001  max mem: 20909
Train Epoch: [14]  [1750/4855]  eta: 2:07:30  lr: 0.000010  ml_loss: 4.9380  mi_loss: 4.1317  train_loss: 9.0697  time: 2.4619  data: 0.0001  max mem: 20909
Train Epoch: [14]  [1800/4855]  eta: 2:05:26  lr: 0.000010  ml_loss: 4.8083  mi_loss: 3.7632  train_loss: 8.5715  time: 2.4223  data: 0.0001  max mem: 20909
Train Epoch: [14]  [1850/4855]  eta: 2:03:22  lr: 0.000010  ml_loss: 4.5434  mi_loss: 4.0355  train_loss: 8.5789  time: 2.4701  data: 0.0001  max mem: 20909
Train Epoch: [14]  [1900/4855]  eta: 2:01:19  lr: 0.000010  ml_loss: 3.6640  mi_loss: 3.6424  train_loss: 7.3063  time: 2.4717  data: 0.0001  max mem: 20909
Train Epoch: [14]  [1950/4855]  eta: 1:59:16  lr: 0.000010  ml_loss: 4.3453  mi_loss: 4.1555  train_loss: 8.5008  time: 2.4645  data: 0.0001  max mem: 20909
Train Epoch: [14]  [2000/4855]  eta: 1:57:13  lr: 0.000010  ml_loss: 4.9323  mi_loss: 4.3023  train_loss: 9.2346  time: 2.4492  data: 0.0001  max mem: 20909
Train Epoch: [14]  [2050/4855]  eta: 1:55:08  lr: 0.000010  ml_loss: 4.9180  mi_loss: 4.0713  train_loss: 8.9893  time: 2.4370  data: 0.0001  max mem: 20909
Train Epoch: [14]  [2100/4855]  eta: 1:53:05  lr: 0.000010  ml_loss: 4.4725  mi_loss: 3.8154  train_loss: 8.2879  time: 2.4631  data: 0.0001  max mem: 20909
Train Epoch: [14]  [2150/4855]  eta: 1:51:01  lr: 0.000010  ml_loss: 4.5676  mi_loss: 3.6636  train_loss: 8.2312  time: 2.4271  data: 0.0001  max mem: 20909
Train Epoch: [14]  [2200/4855]  eta: 1:48:58  lr: 0.000010  ml_loss: 4.2528  mi_loss: 4.1802  train_loss: 8.4330  time: 2.4639  data: 0.0002  max mem: 20909
Train Epoch: [14]  [2250/4855]  eta: 1:46:54  lr: 0.000010  ml_loss: 4.9646  mi_loss: 4.0277  train_loss: 8.9923  time: 2.4638  data: 0.0001  max mem: 20909
Train Epoch: [14]  [2300/4855]  eta: 1:44:50  lr: 0.000010  ml_loss: 4.3608  mi_loss: 3.8743  train_loss: 8.2351  time: 2.4410  data: 0.0001  max mem: 20909
Train Epoch: [14]  [2350/4855]  eta: 1:42:47  lr: 0.000010  ml_loss: 4.9300  mi_loss: 3.8413  train_loss: 8.7713  time: 2.4624  data: 0.0001  max mem: 20909
Train Epoch: [14]  [2400/4855]  eta: 1:40:43  lr: 0.000010  ml_loss: 4.6154  mi_loss: 3.9056  train_loss: 8.5210  time: 2.4660  data: 0.0001  max mem: 20909
Train Epoch: [14]  [2450/4855]  eta: 1:38:40  lr: 0.000010  ml_loss: 5.0433  mi_loss: 3.9590  train_loss: 9.0024  time: 2.4295  data: 0.0001  max mem: 20909
Train Epoch: [14]  [2500/4855]  eta: 1:36:36  lr: 0.000010  ml_loss: 5.0244  mi_loss: 3.9721  train_loss: 8.9965  time: 2.4591  data: 0.0001  max mem: 20909
Train Epoch: [14]  [2550/4855]  eta: 1:34:33  lr: 0.000010  ml_loss: 4.1924  mi_loss: 3.7733  train_loss: 7.9657  time: 2.4669  data: 0.0001  max mem: 20909
Train Epoch: [14]  [2600/4855]  eta: 1:32:30  lr: 0.000010  ml_loss: 4.8902  mi_loss: 4.0769  train_loss: 8.9672  time: 2.4672  data: 0.0001  max mem: 20909
Train Epoch: [14]  [2650/4855]  eta: 1:30:27  lr: 0.000010  ml_loss: 5.1056  mi_loss: 3.9865  train_loss: 9.0920  time: 2.4465  data: 0.0001  max mem: 20909
Train Epoch: [14]  [2700/4855]  eta: 1:28:23  lr: 0.000010  ml_loss: 4.7631  mi_loss: 3.7000  train_loss: 8.4631  time: 2.4735  data: 0.0001  max mem: 20909
Train Epoch: [14]  [2750/4855]  eta: 1:26:20  lr: 0.000010  ml_loss: 4.8768  mi_loss: 4.0276  train_loss: 8.9044  time: 2.4649  data: 0.0001  max mem: 20909
Train Epoch: [14]  [2800/4855]  eta: 1:24:16  lr: 0.000010  ml_loss: 4.3622  mi_loss: 4.1375  train_loss: 8.4996  time: 2.4358  data: 0.0001  max mem: 20909
Train Epoch: [14]  [2850/4855]  eta: 1:22:12  lr: 0.000010  ml_loss: 4.9104  mi_loss: 3.7323  train_loss: 8.6427  time: 2.4398  data: 0.0001  max mem: 20909
Train Epoch: [14]  [2900/4855]  eta: 1:20:09  lr: 0.000010  ml_loss: 4.7068  mi_loss: 4.0414  train_loss: 8.7482  time: 2.4661  data: 0.0001  max mem: 20909
Train Epoch: [14]  [2950/4855]  eta: 1:18:06  lr: 0.000010  ml_loss: 4.8844  mi_loss: 4.1037  train_loss: 8.9881  time: 2.4630  data: 0.0001  max mem: 20909
Train Epoch: [14]  [3000/4855]  eta: 1:16:03  lr: 0.000010  ml_loss: 3.8946  mi_loss: 4.0443  train_loss: 7.9389  time: 2.4551  data: 0.0001  max mem: 20909
Train Epoch: [14]  [3050/4855]  eta: 1:14:00  lr: 0.000010  ml_loss: 4.6480  mi_loss: 3.0726  train_loss: 7.7206  time: 2.4950  data: 0.0001  max mem: 20909
Train Epoch: [14]  [3100/4855]  eta: 1:11:58  lr: 0.000010  ml_loss: 4.8377  mi_loss: 4.2734  train_loss: 9.1111  time: 2.4644  data: 0.0001  max mem: 20909
Train Epoch: [14]  [3150/4855]  eta: 1:09:55  lr: 0.000010  ml_loss: 4.8094  mi_loss: 4.0186  train_loss: 8.8280  time: 2.4910  data: 0.0001  max mem: 20909
Train Epoch: [14]  [3200/4855]  eta: 1:07:53  lr: 0.000010  ml_loss: 4.2843  mi_loss: 4.0307  train_loss: 8.3150  time: 2.4922  data: 0.0001  max mem: 20909
Train Epoch: [14]  [3250/4855]  eta: 1:05:51  lr: 0.000010  ml_loss: 4.5871  mi_loss: 3.8152  train_loss: 8.4024  time: 2.4922  data: 0.0001  max mem: 20909
Train Epoch: [14]  [3300/4855]  eta: 1:03:48  lr: 0.000010  ml_loss: 3.6384  mi_loss: 3.6631  train_loss: 7.3016  time: 2.4664  data: 0.0001  max mem: 20909
Train Epoch: [14]  [3350/4855]  eta: 1:01:45  lr: 0.000010  ml_loss: 5.2984  mi_loss: 3.5201  train_loss: 8.8185  time: 2.4489  data: 0.0001  max mem: 20909
Train Epoch: [14]  [3400/4855]  eta: 0:59:42  lr: 0.000010  ml_loss: 3.8649  mi_loss: 3.6290  train_loss: 7.4940  time: 2.4681  data: 0.0001  max mem: 20909
Train Epoch: [14]  [3450/4855]  eta: 0:57:39  lr: 0.000010  ml_loss: 4.6397  mi_loss: 3.8925  train_loss: 8.5322  time: 2.4441  data: 0.0001  max mem: 20909
Train Epoch: [14]  [3500/4855]  eta: 0:55:36  lr: 0.000010  ml_loss: 4.7571  mi_loss: 3.5103  train_loss: 8.2674  time: 2.4794  data: 0.0001  max mem: 20909
Train Epoch: [14]  [3550/4855]  eta: 0:53:33  lr: 0.000010  ml_loss: 4.8606  mi_loss: 3.7528  train_loss: 8.6134  time: 2.4735  data: 0.0001  max mem: 20909
Train Epoch: [14]  [3600/4855]  eta: 0:51:30  lr: 0.000010  ml_loss: 5.0386  mi_loss: 3.9861  train_loss: 9.0247  time: 2.4980  data: 0.0001  max mem: 20909
Train Epoch: [14]  [3650/4855]  eta: 0:49:28  lr: 0.000010  ml_loss: 4.4167  mi_loss: 3.9568  train_loss: 8.3735  time: 2.4846  data: 0.0001  max mem: 20909
Train Epoch: [14]  [3700/4855]  eta: 0:47:25  lr: 0.000010  ml_loss: 4.2260  mi_loss: 3.9924  train_loss: 8.2184  time: 2.4851  data: 0.0001  max mem: 20909
Train Epoch: [14]  [3750/4855]  eta: 0:45:22  lr: 0.000010  ml_loss: 4.5083  mi_loss: 4.5231  train_loss: 9.0313  time: 2.4559  data: 0.0001  max mem: 20909
Train Epoch: [14]  [3800/4855]  eta: 0:43:18  lr: 0.000010  ml_loss: 4.9061  mi_loss: 3.4790  train_loss: 8.3851  time: 2.4585  data: 0.0001  max mem: 20909
Train Epoch: [14]  [3850/4855]  eta: 0:41:15  lr: 0.000010  ml_loss: 4.2320  mi_loss: 4.0576  train_loss: 8.2896  time: 2.4585  data: 0.0001  max mem: 20909
Train Epoch: [14]  [3900/4855]  eta: 0:39:12  lr: 0.000010  ml_loss: 4.6232  mi_loss: 3.8954  train_loss: 8.5185  time: 2.4608  data: 0.0001  max mem: 20909
Train Epoch: [14]  [3950/4855]  eta: 0:37:09  lr: 0.000010  ml_loss: 4.6390  mi_loss: 4.1797  train_loss: 8.8186  time: 2.4807  data: 0.0001  max mem: 20909
Train Epoch: [14]  [4000/4855]  eta: 0:35:06  lr: 0.000010  ml_loss: 4.4376  mi_loss: 4.0064  train_loss: 8.4440  time: 2.4625  data: 0.0001  max mem: 20909
Train Epoch: [14]  [4050/4855]  eta: 0:33:03  lr: 0.000010  ml_loss: 3.1498  mi_loss: 3.3169  train_loss: 6.4667  time: 2.4899  data: 0.0001  max mem: 20909
Train Epoch: [14]  [4100/4855]  eta: 0:31:00  lr: 0.000010  ml_loss: 5.0546  mi_loss: 3.8672  train_loss: 8.9218  time: 2.4927  data: 0.0001  max mem: 20909
Train Epoch: [14]  [4150/4855]  eta: 0:28:57  lr: 0.000010  ml_loss: 4.9160  mi_loss: 4.1386  train_loss: 9.0546  time: 2.4635  data: 0.0001  max mem: 20909
Train Epoch: [14]  [4200/4855]  eta: 0:26:54  lr: 0.000010  ml_loss: 4.4303  mi_loss: 3.5146  train_loss: 7.9449  time: 2.5017  data: 0.0002  max mem: 20909
Train Epoch: [14]  [4250/4855]  eta: 0:24:51  lr: 0.000010  ml_loss: 4.6828  mi_loss: 3.9706  train_loss: 8.6534  time: 2.4904  data: 0.0001  max mem: 20909
Train Epoch: [14]  [4300/4855]  eta: 0:22:48  lr: 0.000010  ml_loss: 4.5548  mi_loss: 3.8640  train_loss: 8.4188  time: 2.4746  data: 0.0001  max mem: 20909
Train Epoch: [14]  [4350/4855]  eta: 0:20:44  lr: 0.000010  ml_loss: 4.6589  mi_loss: 3.9091  train_loss: 8.5680  time: 2.4592  data: 0.0001  max mem: 20909
Train Epoch: [14]  [4400/4855]  eta: 0:18:41  lr: 0.000010  ml_loss: 4.4174  mi_loss: 3.7396  train_loss: 8.1571  time: 2.4844  data: 0.0001  max mem: 20909
Train Epoch: [14]  [4450/4855]  eta: 0:16:38  lr: 0.000010  ml_loss: 5.1692  mi_loss: 4.1214  train_loss: 9.2907  time: 2.4822  data: 0.0001  max mem: 20909
Train Epoch: [14]  [4500/4855]  eta: 0:14:35  lr: 0.000010  ml_loss: 4.6966  mi_loss: 3.9949  train_loss: 8.6915  time: 2.4679  data: 0.0001  max mem: 20909
Train Epoch: [14]  [4550/4855]  eta: 0:12:31  lr: 0.000010  ml_loss: 4.9873  mi_loss: 4.0662  train_loss: 9.0535  time: 2.4887  data: 0.0001  max mem: 20909
Train Epoch: [14]  [4600/4855]  eta: 0:10:28  lr: 0.000010  ml_loss: 4.7844  mi_loss: 3.9722  train_loss: 8.7566  time: 2.4882  data: 0.0001  max mem: 20909
Train Epoch: [14]  [4650/4855]  eta: 0:08:25  lr: 0.000010  ml_loss: 4.6952  mi_loss: 4.2721  train_loss: 8.9673  time: 2.4793  data: 0.0001  max mem: 20909
Train Epoch: [14]  [4700/4855]  eta: 0:06:22  lr: 0.000010  ml_loss: 4.5633  mi_loss: 4.1235  train_loss: 8.6868  time: 2.4653  data: 0.0001  max mem: 20909
Train Epoch: [14]  [4750/4855]  eta: 0:04:18  lr: 0.000010  ml_loss: 5.1040  mi_loss: 3.7789  train_loss: 8.8828  time: 2.4835  data: 0.0001  max mem: 20909
Train Epoch: [14]  [4800/4855]  eta: 0:02:15  lr: 0.000010  ml_loss: 4.8034  mi_loss: 3.7944  train_loss: 8.5978  time: 2.4955  data: 0.0001  max mem: 20909
Train Epoch: [14]  [4850/4855]  eta: 0:00:12  lr: 0.000010  ml_loss: 3.9485  mi_loss: 3.8753  train_loss: 7.8237  time: 2.4801  data: 0.0002  max mem: 20909
Train Epoch: [14]  [4854/4855]  eta: 0:00:02  lr: 0.000010  ml_loss: 5.1094  mi_loss: 4.3415  train_loss: 9.4509  time: 2.4898  data: 0.0007  max mem: 20909
Train Epoch: [14] Total time: 3:19:36 (2.4668 s / it)
Val Epoch: [14]  [  0/540]  eta: 0:23:23  ml_loss: 4.7031  mi_loss: 4.0781  val_loss: 8.7812  accML: 0.2676  accMI: 0.1270  time: 2.5994  data: 2.2420  max mem: 20909
Val Epoch: [14]  [ 50/540]  eta: 0:06:29  ml_loss: 4.8917  mi_loss: 3.8229  val_loss: 8.7146  accML: 0.2281  accMI: 0.1823  time: 0.7796  data: 0.6179  max mem: 20909
Val Epoch: [14]  [100/540]  eta: 0:05:51  ml_loss: 4.5098  mi_loss: 4.3719  val_loss: 8.8817  accML: 0.2541  accMI: 0.1413  time: 0.7763  data: 0.6144  max mem: 20909
Val Epoch: [14]  [150/540]  eta: 0:05:23  ml_loss: 4.7218  mi_loss: 4.5059  val_loss: 9.2277  accML: 0.2548  accMI: 0.1294  time: 0.9278  data: 0.7641  max mem: 20909
Val Epoch: [14]  [200/540]  eta: 0:04:44  ml_loss: 4.6951  mi_loss: 4.3218  val_loss: 9.0169  accML: 0.2453  accMI: 0.1283  time: 0.8680  data: 0.7051  max mem: 20909
Val Epoch: [14]  [250/540]  eta: 0:04:01  ml_loss: 4.2776  mi_loss: 3.8399  val_loss: 8.1175  accML: 0.3230  accMI: 0.1875  time: 0.8591  data: 0.6963  max mem: 20909
Val Epoch: [14]  [300/540]  eta: 0:03:20  ml_loss: 4.0860  mi_loss: 3.8529  val_loss: 7.9388  accML: 0.3131  accMI: 0.1935  time: 0.8620  data: 0.6978  max mem: 20909
Val Epoch: [14]  [350/540]  eta: 0:02:38  ml_loss: 4.5433  mi_loss: 3.1448  val_loss: 7.6882  accML: 0.2950  accMI: 0.2880  time: 0.8211  data: 0.6580  max mem: 20909
Val Epoch: [14]  [400/540]  eta: 0:01:57  ml_loss: 5.3392  mi_loss: 4.2947  val_loss: 9.6339  accML: 0.2161  accMI: 0.1075  time: 0.8618  data: 0.6991  max mem: 20909
Val Epoch: [14]  [450/540]  eta: 0:01:15  ml_loss: 5.1357  mi_loss: 4.0000  val_loss: 9.1358  accML: 0.2412  accMI: 0.1360  time: 0.8438  data: 0.6815  max mem: 20909
Val Epoch: [14]  [500/540]  eta: 0:00:33  ml_loss: 5.1088  mi_loss: 3.9652  val_loss: 9.0740  accML: 0.2248  accMI: 0.1459  time: 0.7531  data: 0.5915  max mem: 20909
Val Epoch: [14]  [539/540]  eta: 0:00:00  ml_loss: 4.9440  mi_loss: 4.0685  val_loss: 9.0125  accML: 0.1934  accMI: 0.1667  time: 0.7850  data: 0.6255  max mem: 20909
Val Epoch: [14] Total time: 0:07:34 (0.8410 s / it)
epoch:14, iter:72824, 4854,  train_loss: 9.450928688049316, valid_loss: 8.684689771687543, idiv_loss:(4.656503795694422, 4.028185976434637), acc:(0.2667214029365116, 0.16077675318552387)
Averaged stats: lr: 0.0000  ml_loss: 4.7215  mi_loss: 3.9373  train_loss: 8.6588
epoch 14 9.450928688049316
Train Epoch: [15]  [   0/4855]  eta: 8:15:18  lr: 0.000010  ml_loss: 4.6773  mi_loss: 4.2944  train_loss: 8.9717  time: 6.1213  data: 3.3969  max mem: 20909
Train Epoch: [15]  [  50/4855]  eta: 3:23:40  lr: 0.000010  ml_loss: 4.7576  mi_loss: 3.8500  train_loss: 8.6076  time: 2.4758  data: 0.0001  max mem: 20909
Train Epoch: [15]  [ 100/4855]  eta: 3:18:39  lr: 0.000010  ml_loss: 5.3946  mi_loss: 3.9303  train_loss: 9.3249  time: 2.4779  data: 0.0001  max mem: 20909
Train Epoch: [15]  [ 150/4855]  eta: 3:15:54  lr: 0.000010  ml_loss: 4.4777  mi_loss: 3.9045  train_loss: 8.3822  time: 2.4770  data: 0.0001  max mem: 20909
Train Epoch: [15]  [ 200/4855]  eta: 3:13:13  lr: 0.000010  ml_loss: 4.6188  mi_loss: 4.2238  train_loss: 8.8426  time: 2.4604  data: 0.0001  max mem: 20909
Train Epoch: [15]  [ 250/4855]  eta: 3:10:53  lr: 0.000010  ml_loss: 4.6990  mi_loss: 3.8486  train_loss: 8.5476  time: 2.4825  data: 0.0001  max mem: 20909
Train Epoch: [15]  [ 300/4855]  eta: 3:08:39  lr: 0.000010  ml_loss: 3.7678  mi_loss: 4.0226  train_loss: 7.7904  time: 2.4624  data: 0.0001  max mem: 20909
Train Epoch: [15]  [ 350/4855]  eta: 3:06:20  lr: 0.000010  ml_loss: 4.6776  mi_loss: 4.0465  train_loss: 8.7241  time: 2.4642  data: 0.0001  max mem: 20909
Train Epoch: [15]  [ 400/4855]  eta: 3:04:14  lr: 0.000010  ml_loss: 5.4788  mi_loss: 4.0535  train_loss: 9.5323  time: 2.4927  data: 0.0001  max mem: 20909
Train Epoch: [15]  [ 450/4855]  eta: 3:02:03  lr: 0.000010  ml_loss: 4.3995  mi_loss: 4.2460  train_loss: 8.6454  time: 2.4725  data: 0.0001  max mem: 20909
Train Epoch: [15]  [ 500/4855]  eta: 2:59:55  lr: 0.000010  ml_loss: 4.4246  mi_loss: 4.3920  train_loss: 8.8166  time: 2.4821  data: 0.0001  max mem: 20909
Train Epoch: [15]  [ 550/4855]  eta: 2:57:48  lr: 0.000010  ml_loss: 4.5522  mi_loss: 4.0843  train_loss: 8.6365  time: 2.4682  data: 0.0001  max mem: 20909
Train Epoch: [15]  [ 600/4855]  eta: 2:55:42  lr: 0.000010  ml_loss: 4.9218  mi_loss: 4.1621  train_loss: 9.0839  time: 2.4853  data: 0.0001  max mem: 20909
Train Epoch: [15]  [ 650/4855]  eta: 2:53:42  lr: 0.000010  ml_loss: 4.7889  mi_loss: 3.4133  train_loss: 8.2022  time: 2.4926  data: 0.0001  max mem: 20909
Train Epoch: [15]  [ 700/4855]  eta: 2:51:37  lr: 0.000010  ml_loss: 4.0852  mi_loss: 3.9270  train_loss: 8.0121  time: 2.4945  data: 0.0001  max mem: 20909
Train Epoch: [15]  [ 750/4855]  eta: 2:49:34  lr: 0.000010  ml_loss: 4.8389  mi_loss: 3.9822  train_loss: 8.8210  time: 2.4852  data: 0.0001  max mem: 20909
Train Epoch: [15]  [ 800/4855]  eta: 2:47:28  lr: 0.000010  ml_loss: 4.9879  mi_loss: 3.9487  train_loss: 8.9365  time: 2.4763  data: 0.0001  max mem: 20909
Train Epoch: [15]  [ 850/4855]  eta: 2:45:28  lr: 0.000010  ml_loss: 4.7342  mi_loss: 4.1708  train_loss: 8.9050  time: 2.4965  data: 0.0001  max mem: 20909
Train Epoch: [15]  [ 900/4855]  eta: 2:43:24  lr: 0.000010  ml_loss: 4.5737  mi_loss: 4.1797  train_loss: 8.7534  time: 2.4670  data: 0.0001  max mem: 20909
Train Epoch: [15]  [ 950/4855]  eta: 2:41:23  lr: 0.000010  ml_loss: 5.1190  mi_loss: 3.8627  train_loss: 8.9817  time: 2.4915  data: 0.0001  max mem: 20909
Train Epoch: [15]  [1000/4855]  eta: 2:39:17  lr: 0.000010  ml_loss: 4.7521  mi_loss: 4.0752  train_loss: 8.8273  time: 2.4605  data: 0.0001  max mem: 20909
Train Epoch: [15]  [1050/4855]  eta: 2:37:17  lr: 0.000010  ml_loss: 4.1479  mi_loss: 3.9543  train_loss: 8.1022  time: 2.4952  data: 0.0001  max mem: 20909
Train Epoch: [15]  [1100/4855]  eta: 2:35:15  lr: 0.000010  ml_loss: 4.9023  mi_loss: 4.0997  train_loss: 9.0019  time: 2.4870  data: 0.0001  max mem: 20909
Train Epoch: [15]  [1150/4855]  eta: 2:33:09  lr: 0.000010  ml_loss: 5.0354  mi_loss: 4.0457  train_loss: 9.0810  time: 2.4644  data: 0.0001  max mem: 20909
Train Epoch: [15]  [1200/4855]  eta: 2:31:02  lr: 0.000010  ml_loss: 5.0587  mi_loss: 4.0672  train_loss: 9.1258  time: 2.4602  data: 0.0001  max mem: 20909
Train Epoch: [15]  [1250/4855]  eta: 2:28:59  lr: 0.000010  ml_loss: 4.1783  mi_loss: 4.0922  train_loss: 8.2705  time: 2.4791  data: 0.0001  max mem: 20909
Train Epoch: [15]  [1300/4855]  eta: 2:26:56  lr: 0.000010  ml_loss: 4.8329  mi_loss: 4.0827  train_loss: 8.9156  time: 2.4839  data: 0.0001  max mem: 20909
Train Epoch: [15]  [1350/4855]  eta: 2:24:55  lr: 0.000010  ml_loss: 4.7146  mi_loss: 3.9474  train_loss: 8.6620  time: 2.5039  data: 0.0001  max mem: 20909
Train Epoch: [15]  [1400/4855]  eta: 2:22:54  lr: 0.000010  ml_loss: 4.5657  mi_loss: 4.2408  train_loss: 8.8065  time: 2.4991  data: 0.0002  max mem: 20909
Train Epoch: [15]  [1450/4855]  eta: 2:20:52  lr: 0.000010  ml_loss: 4.7282  mi_loss: 4.2542  train_loss: 8.9824  time: 2.5027  data: 0.0001  max mem: 20909
Train Epoch: [15]  [1500/4855]  eta: 2:18:50  lr: 0.000010  ml_loss: 4.8132  mi_loss: 3.8301  train_loss: 8.6433  time: 2.4891  data: 0.0002  max mem: 20909
Train Epoch: [15]  [1550/4855]  eta: 2:16:46  lr: 0.000010  ml_loss: 4.9405  mi_loss: 3.8826  train_loss: 8.8231  time: 2.4970  data: 0.0001  max mem: 20909
Train Epoch: [15]  [1600/4855]  eta: 2:14:42  lr: 0.000010  ml_loss: 5.2931  mi_loss: 4.1997  train_loss: 9.4928  time: 2.4812  data: 0.0001  max mem: 20909
Train Epoch: [15]  [1650/4855]  eta: 2:12:38  lr: 0.000010  ml_loss: 4.5316  mi_loss: 3.6549  train_loss: 8.1865  time: 2.4975  data: 0.0001  max mem: 20909
Train Epoch: [15]  [1700/4855]  eta: 2:10:35  lr: 0.000010  ml_loss: 4.8759  mi_loss: 4.1790  train_loss: 9.0549  time: 2.5059  data: 0.0001  max mem: 20909
Train Epoch: [15]  [1750/4855]  eta: 2:08:31  lr: 0.000010  ml_loss: 4.8422  mi_loss: 3.5598  train_loss: 8.4020  time: 2.4878  data: 0.0001  max mem: 20909
Train Epoch: [15]  [1800/4855]  eta: 2:06:27  lr: 0.000010  ml_loss: 4.4424  mi_loss: 3.6396  train_loss: 8.0820  time: 2.4880  data: 0.0001  max mem: 20909
Train Epoch: [15]  [1850/4855]  eta: 2:04:23  lr: 0.000010  ml_loss: 3.6938  mi_loss: 4.1694  train_loss: 7.8632  time: 2.4925  data: 0.0001  max mem: 20909
Train Epoch: [15]  [1900/4855]  eta: 2:02:18  lr: 0.000010  ml_loss: 4.9254  mi_loss: 3.9249  train_loss: 8.8504  time: 2.4595  data: 0.0001  max mem: 20909
Train Epoch: [15]  [1950/4855]  eta: 2:00:13  lr: 0.000010  ml_loss: 4.1381  mi_loss: 3.6617  train_loss: 7.7998  time: 2.4767  data: 0.0001  max mem: 20909
Train Epoch: [15]  [2000/4855]  eta: 1:58:07  lr: 0.000010  ml_loss: 4.7851  mi_loss: 3.7362  train_loss: 8.5213  time: 2.4542  data: 0.0001  max mem: 20909
Train Epoch: [15]  [2050/4855]  eta: 1:56:02  lr: 0.000010  ml_loss: 4.7377  mi_loss: 4.2838  train_loss: 9.0214  time: 2.4777  data: 0.0001  max mem: 20909
Train Epoch: [15]  [2100/4855]  eta: 1:53:58  lr: 0.000010  ml_loss: 5.0453  mi_loss: 3.9469  train_loss: 8.9922  time: 2.4621  data: 0.0001  max mem: 20911
Train Epoch: [15]  [2150/4855]  eta: 1:51:53  lr: 0.000010  ml_loss: 4.8597  mi_loss: 4.1070  train_loss: 8.9667  time: 2.4681  data: 0.0001  max mem: 20911
Train Epoch: [15]  [2200/4855]  eta: 1:49:49  lr: 0.000010  ml_loss: 4.7458  mi_loss: 3.7403  train_loss: 8.4861  time: 2.4788  data: 0.0001  max mem: 20911
Train Epoch: [15]  [2250/4855]  eta: 1:47:44  lr: 0.000010  ml_loss: 4.7477  mi_loss: 3.9246  train_loss: 8.6723  time: 2.4676  data: 0.0001  max mem: 20911
Train Epoch: [15]  [2300/4855]  eta: 1:45:41  lr: 0.000010  ml_loss: 5.0939  mi_loss: 3.9973  train_loss: 9.0912  time: 2.5079  data: 0.0001  max mem: 20911
Train Epoch: [15]  [2350/4855]  eta: 1:43:39  lr: 0.000010  ml_loss: 4.5049  mi_loss: 3.9369  train_loss: 8.4418  time: 2.5073  data: 0.0001  max mem: 20911
Train Epoch: [15]  [2400/4855]  eta: 1:41:34  lr: 0.000010  ml_loss: 4.5903  mi_loss: 3.9449  train_loss: 8.5352  time: 2.4773  data: 0.0001  max mem: 20911
Train Epoch: [15]  [2450/4855]  eta: 1:39:30  lr: 0.000010  ml_loss: 4.8775  mi_loss: 4.4948  train_loss: 9.3723  time: 2.4762  data: 0.0001  max mem: 20911
Train Epoch: [15]  [2500/4855]  eta: 1:37:26  lr: 0.000010  ml_loss: 3.9291  mi_loss: 3.3974  train_loss: 7.3264  time: 2.4931  data: 0.0001  max mem: 20911
Train Epoch: [15]  [2550/4855]  eta: 1:35:22  lr: 0.000010  ml_loss: 4.6779  mi_loss: 4.1193  train_loss: 8.7972  time: 2.4693  data: 0.0001  max mem: 20911
Train Epoch: [15]  [2600/4855]  eta: 1:33:18  lr: 0.000010  ml_loss: 3.9139  mi_loss: 3.9996  train_loss: 7.9134  time: 2.4862  data: 0.0001  max mem: 20911
Train Epoch: [15]  [2650/4855]  eta: 1:31:14  lr: 0.000010  ml_loss: 4.8392  mi_loss: 4.3064  train_loss: 9.1457  time: 2.4890  data: 0.0001  max mem: 20911
Train Epoch: [15]  [2700/4855]  eta: 1:29:09  lr: 0.000010  ml_loss: 4.6137  mi_loss: 4.1631  train_loss: 8.7768  time: 2.4689  data: 0.0001  max mem: 20911
Train Epoch: [15]  [2750/4855]  eta: 1:27:05  lr: 0.000010  ml_loss: 5.0692  mi_loss: 4.3382  train_loss: 9.4074  time: 2.4691  data: 0.0001  max mem: 20911
Train Epoch: [15]  [2800/4855]  eta: 1:25:00  lr: 0.000010  ml_loss: 4.9759  mi_loss: 3.7472  train_loss: 8.7231  time: 2.4631  data: 0.0001  max mem: 20911
Train Epoch: [15]  [2850/4855]  eta: 1:22:55  lr: 0.000010  ml_loss: 4.3629  mi_loss: 3.6822  train_loss: 8.0451  time: 2.4590  data: 0.0001  max mem: 20911
Train Epoch: [15]  [2900/4855]  eta: 1:20:51  lr: 0.000010  ml_loss: 4.2629  mi_loss: 3.8445  train_loss: 8.1074  time: 2.4736  data: 0.0001  max mem: 20911
Train Epoch: [15]  [2950/4855]  eta: 1:18:46  lr: 0.000010  ml_loss: 4.4219  mi_loss: 3.6268  train_loss: 8.0487  time: 2.4568  data: 0.0001  max mem: 20911
Train Epoch: [15]  [3000/4855]  eta: 1:16:42  lr: 0.000010  ml_loss: 4.9002  mi_loss: 3.5575  train_loss: 8.4577  time: 2.4807  data: 0.0001  max mem: 20911
Train Epoch: [15]  [3050/4855]  eta: 1:14:38  lr: 0.000010  ml_loss: 5.2281  mi_loss: 4.2078  train_loss: 9.4360  time: 2.4801  data: 0.0001  max mem: 20911
Train Epoch: [15]  [3100/4855]  eta: 1:12:34  lr: 0.000010  ml_loss: 4.5068  mi_loss: 4.3246  train_loss: 8.8314  time: 2.4834  data: 0.0001  max mem: 20911
Train Epoch: [15]  [3150/4855]  eta: 1:10:30  lr: 0.000010  ml_loss: 4.3492  mi_loss: 3.4290  train_loss: 7.7782  time: 2.4835  data: 0.0001  max mem: 20911
Train Epoch: [15]  [3200/4855]  eta: 1:08:25  lr: 0.000010  ml_loss: 4.8407  mi_loss: 4.2008  train_loss: 9.0415  time: 2.4572  data: 0.0001  max mem: 20911
Train Epoch: [15]  [3250/4855]  eta: 1:06:21  lr: 0.000010  ml_loss: 4.7966  mi_loss: 4.0126  train_loss: 8.8091  time: 2.4733  data: 0.0001  max mem: 20911
Train Epoch: [15]  [3300/4855]  eta: 1:04:17  lr: 0.000010  ml_loss: 4.0137  mi_loss: 4.3564  train_loss: 8.3701  time: 2.4697  data: 0.0001  max mem: 20911
Train Epoch: [15]  [3350/4855]  eta: 1:02:13  lr: 0.000010  ml_loss: 4.9594  mi_loss: 4.2517  train_loss: 9.2111  time: 2.4691  data: 0.0001  max mem: 20911
Train Epoch: [15]  [3400/4855]  eta: 1:00:08  lr: 0.000010  ml_loss: 5.0244  mi_loss: 3.8003  train_loss: 8.8248  time: 2.4904  data: 0.0001  max mem: 20911
Train Epoch: [15]  [3450/4855]  eta: 0:58:04  lr: 0.000010  ml_loss: 4.4611  mi_loss: 3.5252  train_loss: 7.9863  time: 2.4801  data: 0.0001  max mem: 20911
Train Epoch: [15]  [3500/4855]  eta: 0:56:00  lr: 0.000010  ml_loss: 4.6235  mi_loss: 4.2246  train_loss: 8.8482  time: 2.4815  data: 0.0001  max mem: 20911
Train Epoch: [15]  [3550/4855]  eta: 0:53:56  lr: 0.000010  ml_loss: 4.5523  mi_loss: 3.8614  train_loss: 8.4137  time: 2.4244  data: 0.0001  max mem: 20911
Train Epoch: [15]  [3600/4855]  eta: 0:51:51  lr: 0.000010  ml_loss: 5.1263  mi_loss: 3.8945  train_loss: 9.0208  time: 2.4265  data: 0.0001  max mem: 20911
Train Epoch: [15]  [3650/4855]  eta: 0:49:46  lr: 0.000010  ml_loss: 4.7818  mi_loss: 4.5897  train_loss: 9.3715  time: 2.4276  data: 0.0001  max mem: 20911
Train Epoch: [15]  [3700/4855]  eta: 0:47:42  lr: 0.000010  ml_loss: 3.6575  mi_loss: 3.6492  train_loss: 7.3067  time: 2.4408  data: 0.0001  max mem: 20911
Train Epoch: [15]  [3750/4855]  eta: 0:45:37  lr: 0.000010  ml_loss: 4.4718  mi_loss: 3.9612  train_loss: 8.4330  time: 2.4220  data: 0.0001  max mem: 20911
Train Epoch: [15]  [3800/4855]  eta: 0:43:33  lr: 0.000010  ml_loss: 3.5945  mi_loss: 4.4315  train_loss: 8.0259  time: 2.4313  data: 0.0002  max mem: 20911
Train Epoch: [15]  [3850/4855]  eta: 0:41:28  lr: 0.000010  ml_loss: 4.5233  mi_loss: 4.1766  train_loss: 8.7000  time: 2.4272  data: 0.0001  max mem: 20911
Train Epoch: [15]  [3900/4855]  eta: 0:39:24  lr: 0.000010  ml_loss: 4.6686  mi_loss: 3.6147  train_loss: 8.2833  time: 2.4433  data: 0.0001  max mem: 20911
Train Epoch: [15]  [3950/4855]  eta: 0:37:19  lr: 0.000010  ml_loss: 4.8151  mi_loss: 4.2999  train_loss: 9.1149  time: 2.4328  data: 0.0001  max mem: 20911
Train Epoch: [15]  [4000/4855]  eta: 0:35:15  lr: 0.000010  ml_loss: 5.2157  mi_loss: 4.0524  train_loss: 9.2681  time: 2.4157  data: 0.0001  max mem: 20911
Train Epoch: [15]  [4050/4855]  eta: 0:33:11  lr: 0.000010  ml_loss: 5.0362  mi_loss: 4.0356  train_loss: 9.0718  time: 2.4428  data: 0.0001  max mem: 20911
Train Epoch: [15]  [4100/4855]  eta: 0:31:07  lr: 0.000010  ml_loss: 5.0752  mi_loss: 3.9053  train_loss: 8.9805  time: 2.4281  data: 0.0001  max mem: 20911
Train Epoch: [15]  [4150/4855]  eta: 0:29:03  lr: 0.000010  ml_loss: 4.1605  mi_loss: 3.9116  train_loss: 8.0722  time: 2.4427  data: 0.0001  max mem: 20911
Train Epoch: [15]  [4200/4855]  eta: 0:26:59  lr: 0.000010  ml_loss: 4.6647  mi_loss: 4.1625  train_loss: 8.8272  time: 2.4351  data: 0.0001  max mem: 20911
Train Epoch: [15]  [4250/4855]  eta: 0:24:55  lr: 0.000010  ml_loss: 4.5642  mi_loss: 3.7614  train_loss: 8.3257  time: 2.4330  data: 0.0001  max mem: 20911
Train Epoch: [15]  [4300/4855]  eta: 0:22:51  lr: 0.000010  ml_loss: 4.9498  mi_loss: 2.8906  train_loss: 7.8404  time: 2.4471  data: 0.0001  max mem: 20911
Train Epoch: [15]  [4350/4855]  eta: 0:20:48  lr: 0.000010  ml_loss: 4.8268  mi_loss: 4.0533  train_loss: 8.8801  time: 2.4663  data: 0.0001  max mem: 20911
Train Epoch: [15]  [4400/4855]  eta: 0:18:44  lr: 0.000010  ml_loss: 4.8299  mi_loss: 4.1418  train_loss: 8.9717  time: 2.4532  data: 0.0001  max mem: 20911
Train Epoch: [15]  [4450/4855]  eta: 0:16:40  lr: 0.000010  ml_loss: 4.1013  mi_loss: 4.3047  train_loss: 8.4060  time: 2.4484  data: 0.0001  max mem: 20911
Train Epoch: [15]  [4500/4855]  eta: 0:14:37  lr: 0.000010  ml_loss: 5.0356  mi_loss: 3.9521  train_loss: 8.9877  time: 2.4336  data: 0.0001  max mem: 20911
Train Epoch: [15]  [4550/4855]  eta: 0:12:33  lr: 0.000010  ml_loss: 4.5649  mi_loss: 4.3433  train_loss: 8.9082  time: 2.4308  data: 0.0001  max mem: 20911
Train Epoch: [15]  [4600/4855]  eta: 0:10:29  lr: 0.000010  ml_loss: 4.7672  mi_loss: 3.6223  train_loss: 8.3895  time: 2.4371  data: 0.0001  max mem: 20911
Train Epoch: [15]  [4650/4855]  eta: 0:08:26  lr: 0.000010  ml_loss: 4.4829  mi_loss: 3.5525  train_loss: 8.0355  time: 2.4105  data: 0.0001  max mem: 20911
Train Epoch: [15]  [4700/4855]  eta: 0:06:22  lr: 0.000010  ml_loss: 4.2855  mi_loss: 4.2520  train_loss: 8.5375  time: 2.4335  data: 0.0001  max mem: 20911
Train Epoch: [15]  [4750/4855]  eta: 0:04:19  lr: 0.000010  ml_loss: 4.6771  mi_loss: 4.0691  train_loss: 8.7462  time: 2.4646  data: 0.0001  max mem: 20911
Train Epoch: [15]  [4800/4855]  eta: 0:02:15  lr: 0.000010  ml_loss: 4.5059  mi_loss: 3.8923  train_loss: 8.3982  time: 2.4329  data: 0.0001  max mem: 20911
Train Epoch: [15]  [4850/4855]  eta: 0:00:12  lr: 0.000010  ml_loss: 4.9372  mi_loss: 4.5793  train_loss: 9.5165  time: 2.4420  data: 0.0001  max mem: 20911
Train Epoch: [15]  [4854/4855]  eta: 0:00:02  lr: 0.000010  ml_loss: 4.0950  mi_loss: 4.0972  train_loss: 8.1922  time: 2.4475  data: 0.0007  max mem: 20911
Train Epoch: [15] Total time: 3:19:44 (2.4685 s / it)
Val Epoch: [15]  [  0/540]  eta: 0:23:17  ml_loss: 4.5708  mi_loss: 4.0370  val_loss: 8.6078  accML: 0.2920  accMI: 0.1324  time: 2.5882  data: 2.2389  max mem: 20911
Val Epoch: [15]  [ 50/540]  eta: 0:06:36  ml_loss: 4.5592  mi_loss: 3.8386  val_loss: 8.3977  accML: 0.3074  accMI: 0.2064  time: 0.7992  data: 0.6376  max mem: 20911
Val Epoch: [15]  [100/540]  eta: 0:05:55  ml_loss: 4.3239  mi_loss: 4.3245  val_loss: 8.6484  accML: 0.2981  accMI: 0.1467  time: 0.7813  data: 0.6192  max mem: 20911
Val Epoch: [15]  [150/540]  eta: 0:05:24  ml_loss: 4.7379  mi_loss: 4.5523  val_loss: 9.2902  accML: 0.2550  accMI: 0.1375  time: 0.9228  data: 0.7591  max mem: 20911
Val Epoch: [15]  [200/540]  eta: 0:04:43  ml_loss: 4.7427  mi_loss: 4.2863  val_loss: 9.0290  accML: 0.2474  accMI: 0.1310  time: 0.8527  data: 0.6896  max mem: 20911
Val Epoch: [15]  [250/540]  eta: 0:04:01  ml_loss: 4.3302  mi_loss: 3.8349  val_loss: 8.1652  accML: 0.3149  accMI: 0.1766  time: 0.8494  data: 0.6867  max mem: 20911
Val Epoch: [15]  [300/540]  eta: 0:03:19  ml_loss: 4.1508  mi_loss: 3.8329  val_loss: 7.9837  accML: 0.3396  accMI: 0.1935  time: 0.8662  data: 0.7027  max mem: 20911
Val Epoch: [15]  [350/540]  eta: 0:02:37  ml_loss: 4.4617  mi_loss: 3.1524  val_loss: 7.6141  accML: 0.2876  accMI: 0.2773  time: 0.7924  data: 0.6293  max mem: 20911
Val Epoch: [15]  [400/540]  eta: 0:01:56  ml_loss: 5.1960  mi_loss: 4.2364  val_loss: 9.4324  accML: 0.2188  accMI: 0.1129  time: 0.8590  data: 0.6962  max mem: 20911
Val Epoch: [15]  [450/540]  eta: 0:01:15  ml_loss: 5.0428  mi_loss: 4.0039  val_loss: 9.0467  accML: 0.2275  accMI: 0.1440  time: 0.8300  data: 0.6671  max mem: 20911
Val Epoch: [15]  [500/540]  eta: 0:00:33  ml_loss: 4.6520  mi_loss: 3.9134  val_loss: 8.5654  accML: 0.2603  accMI: 0.1541  time: 0.7638  data: 0.6018  max mem: 20911
Val Epoch: [15]  [539/540]  eta: 0:00:00  ml_loss: 4.8716  mi_loss: 3.9243  val_loss: 8.7958  accML: 0.2437  accMI: 0.1847  time: 0.7610  data: 0.6015  max mem: 20911
Val Epoch: [15] Total time: 0:07:31 (0.8357 s / it)
epoch:15, iter:77679, 4854,  train_loss: 8.192220687866211, valid_loss: 8.642955859502157, idiv_loss:(4.623576697155281, 4.019379150867462), acc:(0.27053480537401303, 0.16175657781185926)
Averaged stats: lr: 0.0000  ml_loss: 4.6749  mi_loss: 3.9400  train_loss: 8.6149
epoch 15 8.192220687866211
Train Epoch: [16]  [   0/4855]  eta: 7:42:25  lr: 0.000010  ml_loss: 4.6178  mi_loss: 3.9225  train_loss: 8.5403  time: 5.7149  data: 2.0747  max mem: 20911
Train Epoch: [16]  [  50/4855]  eta: 3:22:30  lr: 0.000010  ml_loss: 4.9379  mi_loss: 4.2490  train_loss: 9.1869  time: 2.4675  data: 0.0001  max mem: 20911
Train Epoch: [16]  [ 100/4855]  eta: 3:17:17  lr: 0.000010  ml_loss: 4.8816  mi_loss: 3.3355  train_loss: 8.2172  time: 2.4365  data: 0.0001  max mem: 20911
Train Epoch: [16]  [ 150/4855]  eta: 3:14:16  lr: 0.000010  ml_loss: 4.6173  mi_loss: 3.9321  train_loss: 8.5494  time: 2.4664  data: 0.0001  max mem: 20911
Train Epoch: [16]  [ 200/4855]  eta: 3:11:46  lr: 0.000010  ml_loss: 5.0021  mi_loss: 3.8819  train_loss: 8.8840  time: 2.4519  data: 0.0001  max mem: 20911
Train Epoch: [16]  [ 250/4855]  eta: 3:09:16  lr: 0.000010  ml_loss: 4.8854  mi_loss: 3.7342  train_loss: 8.6196  time: 2.4398  data: 0.0001  max mem: 20911
Train Epoch: [16]  [ 300/4855]  eta: 3:06:39  lr: 0.000010  ml_loss: 4.8287  mi_loss: 3.9398  train_loss: 8.7686  time: 2.4524  data: 0.0001  max mem: 20911
Train Epoch: [16]  [ 350/4855]  eta: 3:04:30  lr: 0.000010  ml_loss: 4.4834  mi_loss: 4.6552  train_loss: 9.1386  time: 2.4422  data: 0.0002  max mem: 20911
Train Epoch: [16]  [ 400/4855]  eta: 3:02:28  lr: 0.000010  ml_loss: 3.3394  mi_loss: 3.9565  train_loss: 7.2958  time: 2.4678  data: 0.0001  max mem: 20911
Train Epoch: [16]  [ 450/4855]  eta: 3:00:15  lr: 0.000010  ml_loss: 4.1469  mi_loss: 4.1744  train_loss: 8.3213  time: 2.3950  data: 0.0001  max mem: 20911
Train Epoch: [16]  [ 500/4855]  eta: 2:58:01  lr: 0.000010  ml_loss: 4.5199  mi_loss: 3.4840  train_loss: 8.0039  time: 2.4167  data: 0.0002  max mem: 20911
Train Epoch: [16]  [ 550/4855]  eta: 2:55:55  lr: 0.000010  ml_loss: 5.5315  mi_loss: 3.7040  train_loss: 9.2354  time: 2.4597  data: 0.0001  max mem: 20911
Train Epoch: [16]  [ 600/4855]  eta: 2:53:54  lr: 0.000010  ml_loss: 4.7076  mi_loss: 4.0848  train_loss: 8.7925  time: 2.4557  data: 0.0002  max mem: 20911
Train Epoch: [16]  [ 650/4855]  eta: 2:51:48  lr: 0.000010  ml_loss: 4.6393  mi_loss: 4.5626  train_loss: 9.2019  time: 2.4345  data: 0.0002  max mem: 20911
Train Epoch: [16]  [ 700/4855]  eta: 2:49:44  lr: 0.000010  ml_loss: 4.6516  mi_loss: 4.0960  train_loss: 8.7476  time: 2.4675  data: 0.0001  max mem: 20911
Train Epoch: [16]  [ 750/4855]  eta: 2:47:49  lr: 0.000010  ml_loss: 4.8654  mi_loss: 3.9650  train_loss: 8.8304  time: 2.4849  data: 0.0001  max mem: 20911
Train Epoch: [16]  [ 800/4855]  eta: 2:45:55  lr: 0.000010  ml_loss: 5.3367  mi_loss: 3.8964  train_loss: 9.2331  time: 2.4939  data: 0.0001  max mem: 20911
Train Epoch: [16]  [ 850/4855]  eta: 2:44:02  lr: 0.000010  ml_loss: 3.6906  mi_loss: 3.9607  train_loss: 7.6513  time: 2.4972  data: 0.0002  max mem: 20911
Train Epoch: [16]  [ 900/4855]  eta: 2:42:08  lr: 0.000010  ml_loss: 4.2434  mi_loss: 3.6712  train_loss: 7.9146  time: 2.4882  data: 0.0001  max mem: 20911
Train Epoch: [16]  [ 950/4855]  eta: 2:40:07  lr: 0.000010  ml_loss: 4.7031  mi_loss: 4.0449  train_loss: 8.7480  time: 2.4792  data: 0.0002  max mem: 20911
Train Epoch: [16]  [1000/4855]  eta: 2:38:06  lr: 0.000010  ml_loss: 3.9512  mi_loss: 3.7349  train_loss: 7.6861  time: 2.4790  data: 0.0001  max mem: 20911
Train Epoch: [16]  [1050/4855]  eta: 2:36:06  lr: 0.000010  ml_loss: 4.7837  mi_loss: 4.1272  train_loss: 8.9110  time: 2.4816  data: 0.0002  max mem: 20911
Train Epoch: [16]  [1100/4855]  eta: 2:34:06  lr: 0.000010  ml_loss: 5.0961  mi_loss: 4.0760  train_loss: 9.1721  time: 2.4721  data: 0.0001  max mem: 20911
Train Epoch: [16]  [1150/4855]  eta: 2:32:06  lr: 0.000010  ml_loss: 4.6662  mi_loss: 4.1969  train_loss: 8.8632  time: 2.4813  data: 0.0001  max mem: 20911
Train Epoch: [16]  [1200/4855]  eta: 2:30:08  lr: 0.000010  ml_loss: 4.5164  mi_loss: 3.6666  train_loss: 8.1830  time: 2.4983  data: 0.0002  max mem: 20911
Train Epoch: [16]  [1250/4855]  eta: 2:28:03  lr: 0.000010  ml_loss: 5.4267  mi_loss: 3.8227  train_loss: 9.2494  time: 2.4453  data: 0.0002  max mem: 20911
Train Epoch: [16]  [1300/4855]  eta: 2:26:01  lr: 0.000010  ml_loss: 4.5260  mi_loss: 3.7442  train_loss: 8.2702  time: 2.4741  data: 0.0001  max mem: 20911
Train Epoch: [16]  [1350/4855]  eta: 2:24:01  lr: 0.000010  ml_loss: 4.9306  mi_loss: 3.2138  train_loss: 8.1445  time: 2.4915  data: 0.0001  max mem: 20911
Train Epoch: [16]  [1400/4855]  eta: 2:21:59  lr: 0.000010  ml_loss: 4.1342  mi_loss: 3.7119  train_loss: 7.8461  time: 2.4913  data: 0.0001  max mem: 20911
Train Epoch: [16]  [1450/4855]  eta: 2:19:56  lr: 0.000010  ml_loss: 5.1488  mi_loss: 3.8037  train_loss: 8.9525  time: 2.4662  data: 0.0001  max mem: 20911
Train Epoch: [16]  [1500/4855]  eta: 2:17:54  lr: 0.000010  ml_loss: 4.9860  mi_loss: 3.9329  train_loss: 8.9189  time: 2.4673  data: 0.0002  max mem: 20911
Train Epoch: [16]  [1550/4855]  eta: 2:15:51  lr: 0.000010  ml_loss: 4.4413  mi_loss: 3.8232  train_loss: 8.2645  time: 2.4803  data: 0.0001  max mem: 20911
Train Epoch: [16]  [1600/4855]  eta: 2:13:50  lr: 0.000010  ml_loss: 5.0413  mi_loss: 3.3291  train_loss: 8.3704  time: 2.4943  data: 0.0001  max mem: 20911
Train Epoch: [16]  [1650/4855]  eta: 2:11:49  lr: 0.000010  ml_loss: 4.6814  mi_loss: 4.2269  train_loss: 8.9082  time: 2.4907  data: 0.0002  max mem: 20911
Train Epoch: [16]  [1700/4855]  eta: 2:09:46  lr: 0.000010  ml_loss: 4.5992  mi_loss: 4.0308  train_loss: 8.6300  time: 2.4687  data: 0.0001  max mem: 20911
Train Epoch: [16]  [1750/4855]  eta: 2:07:43  lr: 0.000010  ml_loss: 5.0922  mi_loss: 4.0790  train_loss: 9.1712  time: 2.4817  data: 0.0001  max mem: 20911
Train Epoch: [16]  [1800/4855]  eta: 2:05:42  lr: 0.000010  ml_loss: 5.0062  mi_loss: 3.9658  train_loss: 8.9720  time: 2.4936  data: 0.0002  max mem: 20911
Train Epoch: [16]  [1850/4855]  eta: 2:03:40  lr: 0.000010  ml_loss: 4.7112  mi_loss: 3.9429  train_loss: 8.6541  time: 2.4892  data: 0.0002  max mem: 20911
Train Epoch: [16]  [1900/4855]  eta: 2:01:39  lr: 0.000010  ml_loss: 4.1046  mi_loss: 4.1545  train_loss: 8.2591  time: 2.5059  data: 0.0001  max mem: 20911
Train Epoch: [16]  [1950/4855]  eta: 1:59:36  lr: 0.000010  ml_loss: 4.2878  mi_loss: 4.0970  train_loss: 8.3848  time: 2.4815  data: 0.0001  max mem: 20911
Train Epoch: [16]  [2000/4855]  eta: 1:57:32  lr: 0.000010  ml_loss: 4.6949  mi_loss: 4.0285  train_loss: 8.7234  time: 2.4623  data: 0.0001  max mem: 20911
Train Epoch: [16]  [2050/4855]  eta: 1:55:29  lr: 0.000010  ml_loss: 5.1095  mi_loss: 4.1005  train_loss: 9.2100  time: 2.4714  data: 0.0001  max mem: 20911
Train Epoch: [16]  [2100/4855]  eta: 1:53:26  lr: 0.000010  ml_loss: 4.7985  mi_loss: 4.1278  train_loss: 8.9263  time: 2.4672  data: 0.0001  max mem: 20911
Train Epoch: [16]  [2150/4855]  eta: 1:51:23  lr: 0.000010  ml_loss: 4.6304  mi_loss: 3.5052  train_loss: 8.1356  time: 2.4884  data: 0.0001  max mem: 20911
Train Epoch: [16]  [2200/4855]  eta: 1:49:21  lr: 0.000010  ml_loss: 4.6426  mi_loss: 3.9674  train_loss: 8.6100  time: 2.4884  data: 0.0001  max mem: 20911
Train Epoch: [16]  [2250/4855]  eta: 1:47:17  lr: 0.000010  ml_loss: 4.1560  mi_loss: 3.9052  train_loss: 8.0613  time: 2.4883  data: 0.0001  max mem: 20911
Train Epoch: [16]  [2300/4855]  eta: 1:45:13  lr: 0.000010  ml_loss: 5.1176  mi_loss: 4.1077  train_loss: 9.2253  time: 2.4815  data: 0.0001  max mem: 20911
Train Epoch: [16]  [2350/4855]  eta: 1:43:10  lr: 0.000010  ml_loss: 5.2344  mi_loss: 3.8377  train_loss: 9.0721  time: 2.4736  data: 0.0001  max mem: 20911
Train Epoch: [16]  [2400/4855]  eta: 1:41:06  lr: 0.000010  ml_loss: 4.3305  mi_loss: 4.1833  train_loss: 8.5138  time: 2.4679  data: 0.0001  max mem: 20911
Train Epoch: [16]  [2450/4855]  eta: 1:39:04  lr: 0.000010  ml_loss: 4.1456  mi_loss: 3.6353  train_loss: 7.7809  time: 2.4938  data: 0.0001  max mem: 20911
Train Epoch: [16]  [2500/4855]  eta: 1:37:01  lr: 0.000010  ml_loss: 4.4222  mi_loss: 3.8779  train_loss: 8.3001  time: 2.4921  data: 0.0001  max mem: 20911
Train Epoch: [16]  [2550/4855]  eta: 1:34:57  lr: 0.000010  ml_loss: 4.9688  mi_loss: 3.9887  train_loss: 8.9574  time: 2.4470  data: 0.0001  max mem: 20911
Train Epoch: [16]  [2600/4855]  eta: 1:32:54  lr: 0.000010  ml_loss: 4.4969  mi_loss: 3.7846  train_loss: 8.2815  time: 2.4827  data: 0.0001  max mem: 20911
Train Epoch: [16]  [2650/4855]  eta: 1:30:51  lr: 0.000010  ml_loss: 4.9895  mi_loss: 4.0730  train_loss: 9.0625  time: 2.4955  data: 0.0001  max mem: 20911
Train Epoch: [16]  [2700/4855]  eta: 1:28:48  lr: 0.000010  ml_loss: 4.6207  mi_loss: 3.7609  train_loss: 8.3816  time: 2.4835  data: 0.0001  max mem: 20911
Train Epoch: [16]  [2750/4855]  eta: 1:26:45  lr: 0.000010  ml_loss: 4.9081  mi_loss: 4.0221  train_loss: 8.9302  time: 2.4880  data: 0.0001  max mem: 20911
Train Epoch: [16]  [2800/4855]  eta: 1:24:41  lr: 0.000010  ml_loss: 4.3840  mi_loss: 3.4963  train_loss: 7.8804  time: 2.4683  data: 0.0001  max mem: 20911
Train Epoch: [16]  [2850/4855]  eta: 1:22:38  lr: 0.000010  ml_loss: 4.7765  mi_loss: 4.1895  train_loss: 8.9660  time: 2.4845  data: 0.0001  max mem: 20911
Train Epoch: [16]  [2900/4855]  eta: 1:20:34  lr: 0.000010  ml_loss: 4.6316  mi_loss: 4.1803  train_loss: 8.8119  time: 2.4489  data: 0.0001  max mem: 20911
Train Epoch: [16]  [2950/4855]  eta: 1:18:31  lr: 0.000010  ml_loss: 4.8255  mi_loss: 3.8494  train_loss: 8.6750  time: 2.4776  data: 0.0001  max mem: 20911
Train Epoch: [16]  [3000/4855]  eta: 1:16:27  lr: 0.000010  ml_loss: 4.3572  mi_loss: 3.8110  train_loss: 8.1682  time: 2.4591  data: 0.0001  max mem: 20911
Train Epoch: [16]  [3050/4855]  eta: 1:14:23  lr: 0.000010  ml_loss: 4.6870  mi_loss: 3.8646  train_loss: 8.5516  time: 2.4935  data: 0.0001  max mem: 20911
Train Epoch: [16]  [3100/4855]  eta: 1:12:20  lr: 0.000010  ml_loss: 4.6163  mi_loss: 3.6256  train_loss: 8.2419  time: 2.4637  data: 0.0003  max mem: 20911
Train Epoch: [16]  [3150/4855]  eta: 1:10:16  lr: 0.000010  ml_loss: 4.3834  mi_loss: 4.5813  train_loss: 8.9648  time: 2.4822  data: 0.0003  max mem: 20911
Train Epoch: [16]  [3200/4855]  eta: 1:08:12  lr: 0.000010  ml_loss: 4.8138  mi_loss: 4.0021  train_loss: 8.8159  time: 2.4545  data: 0.0001  max mem: 20911
Train Epoch: [16]  [3250/4855]  eta: 1:06:08  lr: 0.000010  ml_loss: 4.5790  mi_loss: 4.1503  train_loss: 8.7294  time: 2.4888  data: 0.0001  max mem: 20911
Train Epoch: [16]  [3300/4855]  eta: 1:04:05  lr: 0.000010  ml_loss: 4.3301  mi_loss: 3.9941  train_loss: 8.3242  time: 2.4778  data: 0.0001  max mem: 20911
Train Epoch: [16]  [3350/4855]  eta: 1:02:02  lr: 0.000010  ml_loss: 4.7608  mi_loss: 4.3759  train_loss: 9.1368  time: 2.4819  data: 0.0001  max mem: 20911
Train Epoch: [16]  [3400/4855]  eta: 0:59:58  lr: 0.000010  ml_loss: 5.2741  mi_loss: 3.8010  train_loss: 9.0752  time: 2.4681  data: 0.0002  max mem: 20911
Train Epoch: [16]  [3450/4855]  eta: 0:57:54  lr: 0.000010  ml_loss: 4.0075  mi_loss: 3.8154  train_loss: 7.8229  time: 2.4626  data: 0.0001  max mem: 20911
Train Epoch: [16]  [3500/4855]  eta: 0:55:51  lr: 0.000010  ml_loss: 4.0805  mi_loss: 3.8145  train_loss: 7.8950  time: 2.4919  data: 0.0001  max mem: 20911
Train Epoch: [16]  [3550/4855]  eta: 0:53:47  lr: 0.000010  ml_loss: 4.6486  mi_loss: 3.7830  train_loss: 8.4316  time: 2.4667  data: 0.0001  max mem: 20911
Train Epoch: [16]  [3600/4855]  eta: 0:51:44  lr: 0.000010  ml_loss: 4.5467  mi_loss: 3.8022  train_loss: 8.3489  time: 2.4829  data: 0.0001  max mem: 20911
Train Epoch: [16]  [3650/4855]  eta: 0:49:40  lr: 0.000010  ml_loss: 4.7479  mi_loss: 3.9481  train_loss: 8.6960  time: 2.4943  data: 0.0001  max mem: 20911
Train Epoch: [16]  [3700/4855]  eta: 0:47:37  lr: 0.000010  ml_loss: 4.4877  mi_loss: 4.2491  train_loss: 8.7368  time: 2.4868  data: 0.0002  max mem: 20911
Train Epoch: [16]  [3750/4855]  eta: 0:45:33  lr: 0.000010  ml_loss: 5.5005  mi_loss: 3.9985  train_loss: 9.4990  time: 2.4515  data: 0.0001  max mem: 20911
Train Epoch: [16]  [3800/4855]  eta: 0:43:30  lr: 0.000010  ml_loss: 4.4658  mi_loss: 3.9996  train_loss: 8.4654  time: 2.4947  data: 0.0001  max mem: 20911
Train Epoch: [16]  [3850/4855]  eta: 0:41:26  lr: 0.000010  ml_loss: 4.8225  mi_loss: 3.9781  train_loss: 8.8006  time: 2.4809  data: 0.0001  max mem: 20911
Train Epoch: [16]  [3900/4855]  eta: 0:39:22  lr: 0.000010  ml_loss: 4.1053  mi_loss: 3.4271  train_loss: 7.5323  time: 2.4833  data: 0.0001  max mem: 20911
Train Epoch: [16]  [3950/4855]  eta: 0:37:19  lr: 0.000010  ml_loss: 5.3780  mi_loss: 3.5270  train_loss: 8.9050  time: 2.4703  data: 0.0002  max mem: 20911
Train Epoch: [16]  [4000/4855]  eta: 0:35:15  lr: 0.000010  ml_loss: 4.5845  mi_loss: 4.0091  train_loss: 8.5936  time: 2.4792  data: 0.0001  max mem: 20911
Train Epoch: [16]  [4050/4855]  eta: 0:33:11  lr: 0.000010  ml_loss: 4.4939  mi_loss: 4.0672  train_loss: 8.5611  time: 2.4752  data: 0.0001  max mem: 20911
Train Epoch: [16]  [4100/4855]  eta: 0:31:08  lr: 0.000010  ml_loss: 4.8173  mi_loss: 3.8304  train_loss: 8.6476  time: 2.4736  data: 0.0001  max mem: 20911
Train Epoch: [16]  [4150/4855]  eta: 0:29:04  lr: 0.000010  ml_loss: 4.5595  mi_loss: 4.0735  train_loss: 8.6330  time: 2.4844  data: 0.0001  max mem: 20911
Train Epoch: [16]  [4200/4855]  eta: 0:27:00  lr: 0.000010  ml_loss: 4.5598  mi_loss: 3.8032  train_loss: 8.3630  time: 2.4841  data: 0.0001  max mem: 20911
Train Epoch: [16]  [4250/4855]  eta: 0:24:57  lr: 0.000010  ml_loss: 4.6176  mi_loss: 3.9460  train_loss: 8.5636  time: 2.4650  data: 0.0001  max mem: 20911
Train Epoch: [16]  [4300/4855]  eta: 0:22:53  lr: 0.000010  ml_loss: 4.3740  mi_loss: 4.2778  train_loss: 8.6518  time: 2.4813  data: 0.0001  max mem: 20911
Train Epoch: [16]  [4350/4855]  eta: 0:20:49  lr: 0.000010  ml_loss: 5.1960  mi_loss: 3.9959  train_loss: 9.1919  time: 2.4833  data: 0.0001  max mem: 20911
Train Epoch: [16]  [4400/4855]  eta: 0:18:45  lr: 0.000010  ml_loss: 4.7088  mi_loss: 4.2994  train_loss: 9.0082  time: 2.4617  data: 0.0001  max mem: 20911
Train Epoch: [16]  [4450/4855]  eta: 0:16:42  lr: 0.000010  ml_loss: 4.5873  mi_loss: 3.6757  train_loss: 8.2630  time: 2.4889  data: 0.0001  max mem: 20911
Train Epoch: [16]  [4500/4855]  eta: 0:14:38  lr: 0.000010  ml_loss: 4.3534  mi_loss: 3.9085  train_loss: 8.2618  time: 2.4946  data: 0.0001  max mem: 20911
Train Epoch: [16]  [4550/4855]  eta: 0:12:34  lr: 0.000010  ml_loss: 4.0652  mi_loss: 3.3696  train_loss: 7.4348  time: 2.4614  data: 0.0001  max mem: 20911
Train Epoch: [16]  [4600/4855]  eta: 0:10:31  lr: 0.000010  ml_loss: 4.9423  mi_loss: 3.3258  train_loss: 8.2681  time: 2.4659  data: 0.0001  max mem: 20911
Train Epoch: [16]  [4650/4855]  eta: 0:08:27  lr: 0.000010  ml_loss: 3.9627  mi_loss: 4.0526  train_loss: 8.0153  time: 2.4835  data: 0.0001  max mem: 20911
Train Epoch: [16]  [4700/4855]  eta: 0:06:23  lr: 0.000010  ml_loss: 4.8381  mi_loss: 3.7378  train_loss: 8.5758  time: 2.4968  data: 0.0001  max mem: 20911
Train Epoch: [16]  [4750/4855]  eta: 0:04:19  lr: 0.000010  ml_loss: 4.4123  mi_loss: 4.1740  train_loss: 8.5862  time: 2.4477  data: 0.0001  max mem: 20911
Train Epoch: [16]  [4800/4855]  eta: 0:02:16  lr: 0.000010  ml_loss: 4.5986  mi_loss: 3.7452  train_loss: 8.3438  time: 2.4310  data: 0.0001  max mem: 20911
Train Epoch: [16]  [4850/4855]  eta: 0:00:12  lr: 0.000010  ml_loss: 4.6642  mi_loss: 3.6420  train_loss: 8.3062  time: 2.4208  data: 0.0001  max mem: 20911
Train Epoch: [16]  [4854/4855]  eta: 0:00:02  lr: 0.000010  ml_loss: 4.7268  mi_loss: 3.5876  train_loss: 8.3144  time: 2.4290  data: 0.0006  max mem: 20911
Train Epoch: [16] Total time: 3:20:11 (2.4739 s / it)
Val Epoch: [16]  [  0/540]  eta: 0:23:40  ml_loss: 4.5443  mi_loss: 4.0477  val_loss: 8.5920  accML: 0.2831  accMI: 0.1216  time: 2.6314  data: 2.2861  max mem: 20911
Val Epoch: [16]  [ 50/540]  eta: 0:06:38  ml_loss: 4.5692  mi_loss: 3.7905  val_loss: 8.3597  accML: 0.2702  accMI: 0.1850  time: 0.7939  data: 0.6320  max mem: 20911
Val Epoch: [16]  [100/540]  eta: 0:05:56  ml_loss: 4.3308  mi_loss: 4.4149  val_loss: 8.7457  accML: 0.2997  accMI: 0.1573  time: 0.7756  data: 0.6136  max mem: 20911
Val Epoch: [16]  [150/540]  eta: 0:05:26  ml_loss: 4.6754  mi_loss: 4.4604  val_loss: 9.1357  accML: 0.2610  accMI: 0.1321  time: 0.9316  data: 0.7679  max mem: 20911
Val Epoch: [16]  [200/540]  eta: 0:04:45  ml_loss: 4.4227  mi_loss: 4.2520  val_loss: 8.6747  accML: 0.3006  accMI: 0.1230  time: 0.8446  data: 0.6818  max mem: 20911
Val Epoch: [16]  [250/540]  eta: 0:04:01  ml_loss: 4.3385  mi_loss: 3.8219  val_loss: 8.1604  accML: 0.3172  accMI: 0.1712  time: 0.8478  data: 0.6852  max mem: 20911
Val Epoch: [16]  [300/540]  eta: 0:03:19  ml_loss: 3.8141  mi_loss: 3.8327  val_loss: 7.6468  accML: 0.3561  accMI: 0.1828  time: 0.8666  data: 0.7033  max mem: 20911
Val Epoch: [16]  [350/540]  eta: 0:02:37  ml_loss: 4.6686  mi_loss: 3.1044  val_loss: 7.7730  accML: 0.2593  accMI: 0.2933  time: 0.8132  data: 0.6512  max mem: 20911
Val Epoch: [16]  [400/540]  eta: 0:01:56  ml_loss: 5.1571  mi_loss: 4.2319  val_loss: 9.3890  accML: 0.2141  accMI: 0.1048  time: 0.8574  data: 0.6945  max mem: 20911
Val Epoch: [16]  [450/540]  eta: 0:01:15  ml_loss: 4.6969  mi_loss: 3.9289  val_loss: 8.6257  accML: 0.2713  accMI: 0.1573  time: 0.8487  data: 0.6860  max mem: 20911
Val Epoch: [16]  [500/540]  eta: 0:00:33  ml_loss: 4.8034  mi_loss: 3.8401  val_loss: 8.6435  accML: 0.2400  accMI: 0.1541  time: 0.7671  data: 0.6050  max mem: 20911
Val Epoch: [16]  [539/540]  eta: 0:00:00  ml_loss: 4.5864  mi_loss: 3.9513  val_loss: 8.5376  accML: 0.2579  accMI: 0.1802  time: 0.7549  data: 0.5951  max mem: 20911
Val Epoch: [16] Total time: 0:07:32 (0.8378 s / it)
epoch:16, iter:82534, 4854,  train_loss: 8.314401626586914, valid_loss: 8.584502540694343, idiv_loss:(4.585446945826212, 3.9990555935435825), acc:(0.27505222799049484, 0.16362892654207017)
Averaged stats: lr: 0.0000  ml_loss: 4.6524  mi_loss: 3.9102  train_loss: 8.5626
epoch 16 8.314401626586914
Train Epoch: [17]  [   0/4855]  eta: 7:32:56  lr: 0.000010  ml_loss: 4.5505  mi_loss: 3.7810  train_loss: 8.3315  time: 5.5977  data: 2.8496  max mem: 20911
Train Epoch: [17]  [  50/4855]  eta: 3:20:39  lr: 0.000010  ml_loss: 4.4721  mi_loss: 3.5784  train_loss: 8.0505  time: 2.4389  data: 0.0001  max mem: 20911
Train Epoch: [17]  [ 100/4855]  eta: 3:16:20  lr: 0.000010  ml_loss: 4.9579  mi_loss: 4.0912  train_loss: 9.0491  time: 2.4553  data: 0.0001  max mem: 20911
Train Epoch: [17]  [ 150/4855]  eta: 3:13:10  lr: 0.000010  ml_loss: 4.3330  mi_loss: 3.9368  train_loss: 8.2697  time: 2.4214  data: 0.0001  max mem: 20911
Train Epoch: [17]  [ 200/4855]  eta: 3:10:42  lr: 0.000010  ml_loss: 5.2231  mi_loss: 4.0021  train_loss: 9.2253  time: 2.4430  data: 0.0001  max mem: 20911
Train Epoch: [17]  [ 250/4855]  eta: 3:08:38  lr: 0.000010  ml_loss: 4.2268  mi_loss: 2.8006  train_loss: 7.0273  time: 2.4580  data: 0.0001  max mem: 20911
Train Epoch: [17]  [ 300/4855]  eta: 3:06:49  lr: 0.000010  ml_loss: 4.9829  mi_loss: 3.9162  train_loss: 8.8991  time: 2.4678  data: 0.0001  max mem: 20911
Train Epoch: [17]  [ 350/4855]  eta: 3:04:43  lr: 0.000010  ml_loss: 4.3652  mi_loss: 4.3556  train_loss: 8.7208  time: 2.4471  data: 0.0001  max mem: 20911
Train Epoch: [17]  [ 400/4855]  eta: 3:02:36  lr: 0.000010  ml_loss: 4.8142  mi_loss: 3.9221  train_loss: 8.7363  time: 2.4690  data: 0.0001  max mem: 20911
Train Epoch: [17]  [ 450/4855]  eta: 3:00:33  lr: 0.000010  ml_loss: 4.8276  mi_loss: 4.3925  train_loss: 9.2201  time: 2.4516  data: 0.0001  max mem: 20911
Train Epoch: [17]  [ 500/4855]  eta: 2:58:34  lr: 0.000010  ml_loss: 4.5900  mi_loss: 4.2066  train_loss: 8.7967  time: 2.4658  data: 0.0001  max mem: 20911
Train Epoch: [17]  [ 550/4855]  eta: 2:56:32  lr: 0.000010  ml_loss: 4.6014  mi_loss: 4.1430  train_loss: 8.7444  time: 2.4573  data: 0.0001  max mem: 20911
Train Epoch: [17]  [ 600/4855]  eta: 2:54:31  lr: 0.000010  ml_loss: 5.2094  mi_loss: 3.8260  train_loss: 9.0355  time: 2.4621  data: 0.0001  max mem: 20911
Train Epoch: [17]  [ 650/4855]  eta: 2:52:26  lr: 0.000010  ml_loss: 4.8892  mi_loss: 3.8697  train_loss: 8.7590  time: 2.4708  data: 0.0001  max mem: 20911
Train Epoch: [17]  [ 700/4855]  eta: 2:50:17  lr: 0.000010  ml_loss: 4.4268  mi_loss: 3.8167  train_loss: 8.2435  time: 2.4129  data: 0.0001  max mem: 20911
Train Epoch: [17]  [ 750/4855]  eta: 2:48:06  lr: 0.000010  ml_loss: 4.4363  mi_loss: 4.0658  train_loss: 8.5021  time: 2.4488  data: 0.0002  max mem: 20911
Train Epoch: [17]  [ 800/4855]  eta: 2:45:58  lr: 0.000010  ml_loss: 4.5643  mi_loss: 3.6127  train_loss: 8.1770  time: 2.4530  data: 0.0001  max mem: 20911
Train Epoch: [17]  [ 850/4855]  eta: 2:43:58  lr: 0.000010  ml_loss: 4.8681  mi_loss: 3.6343  train_loss: 8.5024  time: 2.4628  data: 0.0002  max mem: 20911
Train Epoch: [17]  [ 900/4855]  eta: 2:41:57  lr: 0.000010  ml_loss: 4.8233  mi_loss: 3.7897  train_loss: 8.6130  time: 2.4622  data: 0.0002  max mem: 20911
Train Epoch: [17]  [ 950/4855]  eta: 2:39:55  lr: 0.000010  ml_loss: 4.5498  mi_loss: 3.6390  train_loss: 8.1888  time: 2.4655  data: 0.0001  max mem: 20911
Train Epoch: [17]  [1000/4855]  eta: 2:37:49  lr: 0.000010  ml_loss: 4.9824  mi_loss: 4.0837  train_loss: 9.0661  time: 2.4335  data: 0.0001  max mem: 20911
Train Epoch: [17]  [1050/4855]  eta: 2:35:45  lr: 0.000010  ml_loss: 4.7840  mi_loss: 4.2192  train_loss: 9.0032  time: 2.4619  data: 0.0001  max mem: 20911
Train Epoch: [17]  [1100/4855]  eta: 2:33:40  lr: 0.000010  ml_loss: 4.1991  mi_loss: 3.4249  train_loss: 7.6240  time: 2.4368  data: 0.0001  max mem: 20911
Train Epoch: [17]  [1150/4855]  eta: 2:31:34  lr: 0.000010  ml_loss: 4.6593  mi_loss: 3.8612  train_loss: 8.5204  time: 2.4385  data: 0.0001  max mem: 20911
Train Epoch: [17]  [1200/4855]  eta: 2:29:28  lr: 0.000010  ml_loss: 4.9474  mi_loss: 3.9062  train_loss: 8.8536  time: 2.4374  data: 0.0001  max mem: 20911
Train Epoch: [17]  [1250/4855]  eta: 2:27:26  lr: 0.000010  ml_loss: 4.3389  mi_loss: 3.9652  train_loss: 8.3042  time: 2.4610  data: 0.0001  max mem: 20911
Train Epoch: [17]  [1300/4855]  eta: 2:25:21  lr: 0.000010  ml_loss: 4.8663  mi_loss: 3.2198  train_loss: 8.0860  time: 2.4422  data: 0.0001  max mem: 20911
Train Epoch: [17]  [1350/4855]  eta: 2:23:18  lr: 0.000010  ml_loss: 4.6828  mi_loss: 3.5038  train_loss: 8.1866  time: 2.4387  data: 0.0001  max mem: 20911
Train Epoch: [17]  [1400/4855]  eta: 2:21:14  lr: 0.000010  ml_loss: 4.0513  mi_loss: 4.4220  train_loss: 8.4732  time: 2.4358  data: 0.0001  max mem: 20911
Train Epoch: [17]  [1450/4855]  eta: 2:19:11  lr: 0.000010  ml_loss: 4.8302  mi_loss: 3.4683  train_loss: 8.2984  time: 2.4628  data: 0.0001  max mem: 20911
Train Epoch: [17]  [1500/4855]  eta: 2:17:07  lr: 0.000010  ml_loss: 5.0660  mi_loss: 4.1981  train_loss: 9.2641  time: 2.4569  data: 0.0001  max mem: 20911
Train Epoch: [17]  [1550/4855]  eta: 2:15:04  lr: 0.000010  ml_loss: 4.3840  mi_loss: 3.8101  train_loss: 8.1941  time: 2.4316  data: 0.0001  max mem: 20911
Train Epoch: [17]  [1600/4855]  eta: 2:13:01  lr: 0.000010  ml_loss: 4.6190  mi_loss: 4.0875  train_loss: 8.7065  time: 2.4672  data: 0.0001  max mem: 20911
Train Epoch: [17]  [1650/4855]  eta: 2:10:57  lr: 0.000010  ml_loss: 2.8702  mi_loss: 3.9107  train_loss: 6.7809  time: 2.4231  data: 0.0001  max mem: 20911
Train Epoch: [17]  [1700/4855]  eta: 2:08:54  lr: 0.000010  ml_loss: 5.0764  mi_loss: 4.1411  train_loss: 9.2175  time: 2.4512  data: 0.0001  max mem: 20911
Train Epoch: [17]  [1750/4855]  eta: 2:06:50  lr: 0.000010  ml_loss: 4.6241  mi_loss: 3.8640  train_loss: 8.4881  time: 2.4339  data: 0.0001  max mem: 20911
Train Epoch: [17]  [1800/4855]  eta: 2:04:47  lr: 0.000010  ml_loss: 4.3815  mi_loss: 3.8926  train_loss: 8.2741  time: 2.4392  data: 0.0001  max mem: 20911
Train Epoch: [17]  [1850/4855]  eta: 2:02:44  lr: 0.000010  ml_loss: 4.6358  mi_loss: 3.9923  train_loss: 8.6281  time: 2.4539  data: 0.0001  max mem: 20911
Train Epoch: [17]  [1900/4855]  eta: 2:00:42  lr: 0.000010  ml_loss: 3.3367  mi_loss: 4.1501  train_loss: 7.4869  time: 2.4802  data: 0.0001  max mem: 20911
Train Epoch: [17]  [1950/4855]  eta: 1:58:41  lr: 0.000010  ml_loss: 4.5103  mi_loss: 4.1721  train_loss: 8.6824  time: 2.4783  data: 0.0001  max mem: 20911
Train Epoch: [17]  [2000/4855]  eta: 1:56:39  lr: 0.000010  ml_loss: 4.9646  mi_loss: 3.9153  train_loss: 8.8799  time: 2.4514  data: 0.0001  max mem: 20911
Train Epoch: [17]  [2050/4855]  eta: 1:54:37  lr: 0.000010  ml_loss: 4.6808  mi_loss: 3.9028  train_loss: 8.5836  time: 2.4776  data: 0.0001  max mem: 20911
Train Epoch: [17]  [2100/4855]  eta: 1:52:36  lr: 0.000010  ml_loss: 4.7542  mi_loss: 3.9614  train_loss: 8.7156  time: 2.4805  data: 0.0001  max mem: 20911
Train Epoch: [17]  [2150/4855]  eta: 1:50:34  lr: 0.000010  ml_loss: 4.0311  mi_loss: 4.0090  train_loss: 8.0401  time: 2.4686  data: 0.0001  max mem: 20911
Train Epoch: [17]  [2200/4855]  eta: 1:48:32  lr: 0.000010  ml_loss: 4.5596  mi_loss: 3.7772  train_loss: 8.3369  time: 2.4682  data: 0.0001  max mem: 20911
Train Epoch: [17]  [2250/4855]  eta: 1:46:30  lr: 0.000010  ml_loss: 4.7021  mi_loss: 4.4743  train_loss: 9.1764  time: 2.4683  data: 0.0001  max mem: 20911
Train Epoch: [17]  [2300/4855]  eta: 1:44:28  lr: 0.000010  ml_loss: 3.9056  mi_loss: 3.4840  train_loss: 7.3897  time: 2.4699  data: 0.0001  max mem: 20911
Train Epoch: [17]  [2350/4855]  eta: 1:42:27  lr: 0.000010  ml_loss: 4.3530  mi_loss: 3.9573  train_loss: 8.3103  time: 2.4740  data: 0.0001  max mem: 20911
Train Epoch: [17]  [2400/4855]  eta: 1:40:25  lr: 0.000010  ml_loss: 4.8799  mi_loss: 3.6619  train_loss: 8.5418  time: 2.4774  data: 0.0001  max mem: 20911
Train Epoch: [17]  [2450/4855]  eta: 1:38:23  lr: 0.000010  ml_loss: 4.6749  mi_loss: 4.3226  train_loss: 8.9974  time: 2.4541  data: 0.0001  max mem: 20911
Train Epoch: [17]  [2500/4855]  eta: 1:36:20  lr: 0.000010  ml_loss: 5.0514  mi_loss: 3.8637  train_loss: 8.9151  time: 2.4614  data: 0.0001  max mem: 20911
Train Epoch: [17]  [2550/4855]  eta: 1:34:18  lr: 0.000010  ml_loss: 4.8437  mi_loss: 3.6682  train_loss: 8.5119  time: 2.4502  data: 0.0001  max mem: 20911
Train Epoch: [17]  [2600/4855]  eta: 1:32:16  lr: 0.000010  ml_loss: 4.4354  mi_loss: 4.2019  train_loss: 8.6373  time: 2.4740  data: 0.0001  max mem: 20911
Train Epoch: [17]  [2650/4855]  eta: 1:30:13  lr: 0.000010  ml_loss: 4.7934  mi_loss: 3.8426  train_loss: 8.6359  time: 2.4660  data: 0.0001  max mem: 20911
Train Epoch: [17]  [2700/4855]  eta: 1:28:11  lr: 0.000010  ml_loss: 4.9287  mi_loss: 3.7899  train_loss: 8.7186  time: 2.4812  data: 0.0001  max mem: 20911
Train Epoch: [17]  [2750/4855]  eta: 1:26:09  lr: 0.000010  ml_loss: 4.8172  mi_loss: 3.8453  train_loss: 8.6625  time: 2.4764  data: 0.0001  max mem: 20911
Train Epoch: [17]  [2800/4855]  eta: 1:24:07  lr: 0.000010  ml_loss: 4.5217  mi_loss: 3.9512  train_loss: 8.4730  time: 2.4603  data: 0.0001  max mem: 20911
Train Epoch: [17]  [2850/4855]  eta: 1:22:05  lr: 0.000010  ml_loss: 4.5972  mi_loss: 3.8840  train_loss: 8.4812  time: 2.4928  data: 0.0001  max mem: 20911
Train Epoch: [17]  [2900/4855]  eta: 1:20:03  lr: 0.000010  ml_loss: 4.8244  mi_loss: 4.0417  train_loss: 8.8661  time: 2.4868  data: 0.0001  max mem: 20911
Train Epoch: [17]  [2950/4855]  eta: 1:18:01  lr: 0.000010  ml_loss: 4.0115  mi_loss: 3.9934  train_loss: 8.0049  time: 2.4668  data: 0.0001  max mem: 20911
Train Epoch: [17]  [3000/4855]  eta: 1:15:58  lr: 0.000010  ml_loss: 4.3191  mi_loss: 3.5472  train_loss: 7.8662  time: 2.4843  data: 0.0001  max mem: 20911
Train Epoch: [17]  [3050/4855]  eta: 1:13:56  lr: 0.000010  ml_loss: 4.7561  mi_loss: 3.9531  train_loss: 8.7092  time: 2.4813  data: 0.0001  max mem: 20911
Train Epoch: [17]  [3100/4855]  eta: 1:11:54  lr: 0.000010  ml_loss: 5.1439  mi_loss: 4.1169  train_loss: 9.2608  time: 2.4700  data: 0.0001  max mem: 20911
Train Epoch: [17]  [3150/4855]  eta: 1:09:50  lr: 0.000010  ml_loss: 4.7326  mi_loss: 3.8426  train_loss: 8.5752  time: 2.4524  data: 0.0001  max mem: 20911
Train Epoch: [17]  [3200/4855]  eta: 1:07:48  lr: 0.000010  ml_loss: 5.1740  mi_loss: 3.9779  train_loss: 9.1520  time: 2.4783  data: 0.0001  max mem: 20911
Train Epoch: [17]  [3250/4855]  eta: 1:05:45  lr: 0.000010  ml_loss: 4.6908  mi_loss: 3.8493  train_loss: 8.5401  time: 2.4428  data: 0.0001  max mem: 20911
Train Epoch: [17]  [3300/4855]  eta: 1:03:42  lr: 0.000010  ml_loss: 4.4551  mi_loss: 4.4975  train_loss: 8.9526  time: 2.4929  data: 0.0001  max mem: 20911
Train Epoch: [17]  [3350/4855]  eta: 1:01:39  lr: 0.000010  ml_loss: 4.1187  mi_loss: 3.0565  train_loss: 7.1752  time: 2.4518  data: 0.0001  max mem: 20911
Train Epoch: [17]  [3400/4855]  eta: 0:59:37  lr: 0.000010  ml_loss: 4.6785  mi_loss: 3.9986  train_loss: 8.6771  time: 2.4586  data: 0.0001  max mem: 20911
Train Epoch: [17]  [3450/4855]  eta: 0:57:34  lr: 0.000010  ml_loss: 4.6483  mi_loss: 3.4164  train_loss: 8.0647  time: 2.4836  data: 0.0001  max mem: 20911
Train Epoch: [17]  [3500/4855]  eta: 0:55:31  lr: 0.000010  ml_loss: 4.4962  mi_loss: 4.3423  train_loss: 8.8385  time: 2.4734  data: 0.0001  max mem: 20911
Train Epoch: [17]  [3550/4855]  eta: 0:53:29  lr: 0.000010  ml_loss: 4.5969  mi_loss: 3.5416  train_loss: 8.1384  time: 2.4540  data: 0.0001  max mem: 20911
Train Epoch: [17]  [3600/4855]  eta: 0:51:25  lr: 0.000010  ml_loss: 4.3750  mi_loss: 3.8918  train_loss: 8.2668  time: 2.4458  data: 0.0001  max mem: 20911
Train Epoch: [17]  [3650/4855]  eta: 0:49:23  lr: 0.000010  ml_loss: 4.9039  mi_loss: 3.7130  train_loss: 8.6170  time: 2.4696  data: 0.0001  max mem: 20911
Train Epoch: [17]  [3700/4855]  eta: 0:47:19  lr: 0.000010  ml_loss: 4.9984  mi_loss: 3.7742  train_loss: 8.7726  time: 2.4435  data: 0.0001  max mem: 20911
Train Epoch: [17]  [3750/4855]  eta: 0:45:16  lr: 0.000010  ml_loss: 4.3102  mi_loss: 3.5117  train_loss: 7.8219  time: 2.4359  data: 0.0001  max mem: 20911
Train Epoch: [17]  [3800/4855]  eta: 0:43:13  lr: 0.000010  ml_loss: 4.6797  mi_loss: 3.7464  train_loss: 8.4261  time: 2.4371  data: 0.0001  max mem: 20911
Train Epoch: [17]  [3850/4855]  eta: 0:41:09  lr: 0.000010  ml_loss: 5.0740  mi_loss: 3.3685  train_loss: 8.4425  time: 2.4117  data: 0.0001  max mem: 20911
Train Epoch: [17]  [3900/4855]  eta: 0:39:07  lr: 0.000010  ml_loss: 4.6114  mi_loss: 3.7176  train_loss: 8.3290  time: 2.4586  data: 0.0001  max mem: 20911
Train Epoch: [17]  [3950/4855]  eta: 0:37:04  lr: 0.000010  ml_loss: 4.1479  mi_loss: 4.1249  train_loss: 8.2728  time: 2.4639  data: 0.0002  max mem: 20911
Train Epoch: [17]  [4000/4855]  eta: 0:35:01  lr: 0.000010  ml_loss: 4.6792  mi_loss: 3.4781  train_loss: 8.1573  time: 2.4693  data: 0.0001  max mem: 20911
Train Epoch: [17]  [4050/4855]  eta: 0:32:58  lr: 0.000010  ml_loss: 4.5374  mi_loss: 4.1374  train_loss: 8.6748  time: 2.4340  data: 0.0001  max mem: 20911
Train Epoch: [17]  [4100/4855]  eta: 0:30:55  lr: 0.000010  ml_loss: 4.9934  mi_loss: 3.9433  train_loss: 8.9368  time: 2.4168  data: 0.0001  max mem: 20911
Train Epoch: [17]  [4150/4855]  eta: 0:28:52  lr: 0.000010  ml_loss: 4.7411  mi_loss: 4.3371  train_loss: 9.0782  time: 2.4323  data: 0.0001  max mem: 20911
Train Epoch: [17]  [4200/4855]  eta: 0:26:49  lr: 0.000010  ml_loss: 4.6289  mi_loss: 3.6008  train_loss: 8.2296  time: 2.4729  data: 0.0001  max mem: 20911
Train Epoch: [17]  [4250/4855]  eta: 0:24:46  lr: 0.000010  ml_loss: 4.5585  mi_loss: 3.5925  train_loss: 8.1509  time: 2.4421  data: 0.0001  max mem: 20911
Train Epoch: [17]  [4300/4855]  eta: 0:22:43  lr: 0.000010  ml_loss: 4.7535  mi_loss: 3.8423  train_loss: 8.5958  time: 2.4464  data: 0.0001  max mem: 20911
Train Epoch: [17]  [4350/4855]  eta: 0:20:40  lr: 0.000010  ml_loss: 4.3124  mi_loss: 3.6648  train_loss: 7.9772  time: 2.4620  data: 0.0001  max mem: 20911
Train Epoch: [17]  [4400/4855]  eta: 0:18:37  lr: 0.000010  ml_loss: 4.6939  mi_loss: 3.9115  train_loss: 8.6054  time: 2.4319  data: 0.0001  max mem: 20911
Train Epoch: [17]  [4450/4855]  eta: 0:16:34  lr: 0.000010  ml_loss: 4.1995  mi_loss: 4.3562  train_loss: 8.5557  time: 2.4525  data: 0.0002  max mem: 20911
Train Epoch: [17]  [4500/4855]  eta: 0:14:31  lr: 0.000010  ml_loss: 4.5159  mi_loss: 3.5501  train_loss: 8.0660  time: 2.4282  data: 0.0001  max mem: 20911
Train Epoch: [17]  [4550/4855]  eta: 0:12:28  lr: 0.000010  ml_loss: 4.8435  mi_loss: 3.8384  train_loss: 8.6819  time: 2.4329  data: 0.0001  max mem: 20911
Train Epoch: [17]  [4600/4855]  eta: 0:10:26  lr: 0.000010  ml_loss: 4.6150  mi_loss: 3.4059  train_loss: 8.0210  time: 2.3992  data: 0.0001  max mem: 20911
Train Epoch: [17]  [4650/4855]  eta: 0:08:23  lr: 0.000010  ml_loss: 4.7504  mi_loss: 3.4494  train_loss: 8.1998  time: 2.3974  data: 0.0001  max mem: 20911
Train Epoch: [17]  [4700/4855]  eta: 0:06:20  lr: 0.000010  ml_loss: 4.9366  mi_loss: 3.4353  train_loss: 8.3719  time: 2.4095  data: 0.0001  max mem: 20911
Train Epoch: [17]  [4750/4855]  eta: 0:04:17  lr: 0.000010  ml_loss: 4.7044  mi_loss: 3.4171  train_loss: 8.1216  time: 2.4216  data: 0.0001  max mem: 20911
Train Epoch: [17]  [4800/4855]  eta: 0:02:14  lr: 0.000010  ml_loss: 4.9157  mi_loss: 3.4667  train_loss: 8.3824  time: 2.4127  data: 0.0001  max mem: 20911
Train Epoch: [17]  [4850/4855]  eta: 0:00:12  lr: 0.000010  ml_loss: 4.1972  mi_loss: 4.1766  train_loss: 8.3738  time: 2.4046  data: 0.0001  max mem: 20911
Train Epoch: [17]  [4854/4855]  eta: 0:00:02  lr: 0.000010  ml_loss: 4.7971  mi_loss: 3.7008  train_loss: 8.4979  time: 2.4207  data: 0.0005  max mem: 20911
Train Epoch: [17] Total time: 3:18:28 (2.4528 s / it)
Val Epoch: [17]  [  0/540]  eta: 0:24:07  ml_loss: 4.8656  mi_loss: 4.0821  val_loss: 8.9477  accML: 0.2332  accMI: 0.1189  time: 2.6811  data: 2.3314  max mem: 20911
Val Epoch: [17]  [ 50/540]  eta: 0:06:38  ml_loss: 4.7671  mi_loss: 3.8543  val_loss: 8.6214  accML: 0.2773  accMI: 0.1877  time: 0.7878  data: 0.6255  max mem: 20911
Val Epoch: [17]  [100/540]  eta: 0:05:55  ml_loss: 4.3167  mi_loss: 4.2580  val_loss: 8.5747  accML: 0.3144  accMI: 0.1493  time: 0.7685  data: 0.6063  max mem: 20911
Val Epoch: [17]  [150/540]  eta: 0:05:24  ml_loss: 4.8793  mi_loss: 4.3950  val_loss: 9.2743  accML: 0.2352  accMI: 0.1402  time: 0.9264  data: 0.7629  max mem: 20911
Val Epoch: [17]  [200/540]  eta: 0:04:44  ml_loss: 4.4393  mi_loss: 4.2704  val_loss: 8.7097  accML: 0.3024  accMI: 0.1310  time: 0.8588  data: 0.6954  max mem: 20911
Val Epoch: [17]  [250/540]  eta: 0:04:01  ml_loss: 4.1313  mi_loss: 3.8311  val_loss: 7.9624  accML: 0.3412  accMI: 0.1549  time: 0.8535  data: 0.6904  max mem: 20911
Val Epoch: [17]  [300/540]  eta: 0:03:20  ml_loss: 3.9951  mi_loss: 3.8379  val_loss: 7.8330  accML: 0.3491  accMI: 0.1882  time: 0.8678  data: 0.7049  max mem: 20911
Val Epoch: [17]  [350/540]  eta: 0:02:38  ml_loss: 4.3779  mi_loss: 3.1126  val_loss: 7.4905  accML: 0.2976  accMI: 0.2907  time: 0.8188  data: 0.6565  max mem: 20911
Val Epoch: [17]  [400/540]  eta: 0:01:57  ml_loss: 5.2069  mi_loss: 4.2620  val_loss: 9.4688  accML: 0.2185  accMI: 0.1102  time: 0.8681  data: 0.7045  max mem: 20911
Val Epoch: [17]  [450/540]  eta: 0:01:15  ml_loss: 5.2596  mi_loss: 3.9511  val_loss: 9.2107  accML: 0.2178  accMI: 0.1547  time: 0.8564  data: 0.6932  max mem: 20911
Val Epoch: [17]  [500/540]  eta: 0:00:33  ml_loss: 4.7814  mi_loss: 3.8150  val_loss: 8.5964  accML: 0.2646  accMI: 0.1432  time: 0.7664  data: 0.6038  max mem: 20911
Val Epoch: [17]  [539/540]  eta: 0:00:00  ml_loss: 4.5152  mi_loss: 4.0867  val_loss: 8.6019  accML: 0.2675  accMI: 0.1757  time: 0.7813  data: 0.6195  max mem: 20911
Val Epoch: [17] Total time: 0:07:35 (0.8429 s / it)
epoch:17, iter:87389, 4854,  train_loss: 8.497933387756348, valid_loss: 8.550415665132029, idiv_loss:(4.559702634369885, 3.990713040917008), acc:(0.2774846608164134, 0.16381074873109658)
Averaged stats: lr: 0.0000  ml_loss: 4.6228  mi_loss: 3.8837  train_loss: 8.5065
epoch 17 8.497933387756348
Train Epoch: [18]  [   0/4855]  eta: 8:03:53  lr: 0.000010  ml_loss: 4.3479  mi_loss: 3.9245  train_loss: 8.2724  time: 5.9802  data: 3.5279  max mem: 20911
Train Epoch: [18]  [  50/4855]  eta: 3:19:40  lr: 0.000010  ml_loss: 5.0487  mi_loss: 3.7877  train_loss: 8.8364  time: 2.4502  data: 0.0001  max mem: 20911
Train Epoch: [18]  [ 100/4855]  eta: 3:15:53  lr: 0.000010  ml_loss: 4.5656  mi_loss: 3.6917  train_loss: 8.2572  time: 2.4459  data: 0.0001  max mem: 20911
Train Epoch: [18]  [ 150/4855]  eta: 3:13:08  lr: 0.000010  ml_loss: 4.4564  mi_loss: 4.0869  train_loss: 8.5434  time: 2.4435  data: 0.0001  max mem: 20911
Train Epoch: [18]  [ 200/4855]  eta: 3:10:53  lr: 0.000010  ml_loss: 4.9994  mi_loss: 3.8638  train_loss: 8.8633  time: 2.4648  data: 0.0001  max mem: 20911
Train Epoch: [18]  [ 250/4855]  eta: 3:08:28  lr: 0.000010  ml_loss: 4.6133  mi_loss: 3.6730  train_loss: 8.2862  time: 2.4504  data: 0.0001  max mem: 20911
Train Epoch: [18]  [ 300/4855]  eta: 3:06:09  lr: 0.000010  ml_loss: 4.4455  mi_loss: 3.8889  train_loss: 8.3344  time: 2.4299  data: 0.0002  max mem: 20911
Train Epoch: [18]  [ 350/4855]  eta: 3:04:03  lr: 0.000010  ml_loss: 4.6612  mi_loss: 3.9670  train_loss: 8.6282  time: 2.4438  data: 0.0001  max mem: 20911
Train Epoch: [18]  [ 400/4855]  eta: 3:01:53  lr: 0.000010  ml_loss: 4.3656  mi_loss: 4.1082  train_loss: 8.4738  time: 2.4191  data: 0.0001  max mem: 20911
Train Epoch: [18]  [ 450/4855]  eta: 2:59:50  lr: 0.000010  ml_loss: 4.5358  mi_loss: 3.6714  train_loss: 8.2072  time: 2.4472  data: 0.0001  max mem: 20911
Train Epoch: [18]  [ 500/4855]  eta: 2:57:44  lr: 0.000010  ml_loss: 4.4371  mi_loss: 4.0863  train_loss: 8.5234  time: 2.4412  data: 0.0001  max mem: 20911
Train Epoch: [18]  [ 550/4855]  eta: 2:55:35  lr: 0.000010  ml_loss: 4.9210  mi_loss: 3.0963  train_loss: 8.0173  time: 2.4112  data: 0.0001  max mem: 20911
Train Epoch: [18]  [ 600/4855]  eta: 2:53:18  lr: 0.000010  ml_loss: 4.8550  mi_loss: 3.9259  train_loss: 8.7809  time: 2.4123  data: 0.0001  max mem: 20911
Train Epoch: [18]  [ 650/4855]  eta: 2:51:12  lr: 0.000010  ml_loss: 4.5427  mi_loss: 4.0905  train_loss: 8.6332  time: 2.4474  data: 0.0001  max mem: 20911
Train Epoch: [18]  [ 700/4855]  eta: 2:49:14  lr: 0.000010  ml_loss: 4.8693  mi_loss: 3.8383  train_loss: 8.7076  time: 2.4576  data: 0.0001  max mem: 20911
Train Epoch: [18]  [ 750/4855]  eta: 2:47:10  lr: 0.000010  ml_loss: 4.9653  mi_loss: 4.1000  train_loss: 9.0653  time: 2.4334  data: 0.0001  max mem: 20911
Train Epoch: [18]  [ 800/4855]  eta: 2:44:58  lr: 0.000010  ml_loss: 4.0724  mi_loss: 3.7027  train_loss: 7.7752  time: 2.4209  data: 0.0001  max mem: 20911
Train Epoch: [18]  [ 850/4855]  eta: 2:42:55  lr: 0.000010  ml_loss: 4.8377  mi_loss: 3.9687  train_loss: 8.8064  time: 2.4350  data: 0.0001  max mem: 20911
Train Epoch: [18]  [ 900/4855]  eta: 2:40:49  lr: 0.000010  ml_loss: 4.9285  mi_loss: 4.0142  train_loss: 8.9428  time: 2.4206  data: 0.0001  max mem: 20911
Train Epoch: [18]  [ 950/4855]  eta: 2:38:42  lr: 0.000010  ml_loss: 4.7526  mi_loss: 3.6372  train_loss: 8.3899  time: 2.3986  data: 0.0001  max mem: 20911
Train Epoch: [18]  [1000/4855]  eta: 2:36:36  lr: 0.000010  ml_loss: 4.2993  mi_loss: 3.9261  train_loss: 8.2254  time: 2.4397  data: 0.0001  max mem: 20911
Train Epoch: [18]  [1050/4855]  eta: 2:34:34  lr: 0.000010  ml_loss: 4.4485  mi_loss: 4.1969  train_loss: 8.6454  time: 2.4474  data: 0.0001  max mem: 20911
Train Epoch: [18]  [1100/4855]  eta: 2:32:33  lr: 0.000010  ml_loss: 4.6909  mi_loss: 3.7131  train_loss: 8.4040  time: 2.4430  data: 0.0001  max mem: 20911
Train Epoch: [18]  [1150/4855]  eta: 2:30:27  lr: 0.000010  ml_loss: 4.6822  mi_loss: 3.4107  train_loss: 8.0929  time: 2.4119  data: 0.0001  max mem: 20911
Train Epoch: [18]  [1200/4855]  eta: 2:28:20  lr: 0.000010  ml_loss: 3.8050  mi_loss: 4.1438  train_loss: 7.9488  time: 2.4144  data: 0.0002  max mem: 20911
Train Epoch: [18]  [1250/4855]  eta: 2:26:16  lr: 0.000010  ml_loss: 5.3182  mi_loss: 3.7420  train_loss: 9.0602  time: 2.4273  data: 0.0001  max mem: 20911
Train Epoch: [18]  [1300/4855]  eta: 2:24:13  lr: 0.000010  ml_loss: 4.2254  mi_loss: 3.9683  train_loss: 8.1937  time: 2.4473  data: 0.0001  max mem: 20911
Train Epoch: [18]  [1350/4855]  eta: 2:22:10  lr: 0.000010  ml_loss: 4.7719  mi_loss: 3.9315  train_loss: 8.7034  time: 2.4300  data: 0.0002  max mem: 20911
Train Epoch: [18]  [1400/4855]  eta: 2:20:07  lr: 0.000010  ml_loss: 4.6393  mi_loss: 3.8864  train_loss: 8.5257  time: 2.4201  data: 0.0001  max mem: 20911
Train Epoch: [18]  [1450/4855]  eta: 2:18:04  lr: 0.000010  ml_loss: 4.9102  mi_loss: 3.8097  train_loss: 8.7199  time: 2.4290  data: 0.0001  max mem: 20911
Train Epoch: [18]  [1500/4855]  eta: 2:16:01  lr: 0.000010  ml_loss: 4.3410  mi_loss: 3.8343  train_loss: 8.1754  time: 2.4188  data: 0.0001  max mem: 20911
Train Epoch: [18]  [1550/4855]  eta: 2:13:56  lr: 0.000010  ml_loss: 5.1287  mi_loss: 3.5919  train_loss: 8.7206  time: 2.4117  data: 0.0001  max mem: 20911
Train Epoch: [18]  [1600/4855]  eta: 2:11:54  lr: 0.000010  ml_loss: 4.7296  mi_loss: 4.0322  train_loss: 8.7618  time: 2.4142  data: 0.0002  max mem: 20911
Train Epoch: [18]  [1650/4855]  eta: 2:09:51  lr: 0.000010  ml_loss: 4.4850  mi_loss: 3.9531  train_loss: 8.4381  time: 2.4304  data: 0.0001  max mem: 20911
Train Epoch: [18]  [1700/4855]  eta: 2:07:52  lr: 0.000010  ml_loss: 3.8561  mi_loss: 3.2167  train_loss: 7.0728  time: 2.4588  data: 0.0001  max mem: 20911
Train Epoch: [18]  [1750/4855]  eta: 2:05:51  lr: 0.000010  ml_loss: 4.1126  mi_loss: 4.0802  train_loss: 8.1928  time: 2.4233  data: 0.0002  max mem: 20911
Train Epoch: [18]  [1800/4855]  eta: 2:03:52  lr: 0.000010  ml_loss: 5.0970  mi_loss: 3.2979  train_loss: 8.3949  time: 2.4633  data: 0.0002  max mem: 20911
Train Epoch: [18]  [1850/4855]  eta: 2:01:53  lr: 0.000010  ml_loss: 4.9248  mi_loss: 4.7213  train_loss: 9.6462  time: 2.4695  data: 0.0001  max mem: 20911
Train Epoch: [18]  [1900/4855]  eta: 1:59:52  lr: 0.000010  ml_loss: 4.9379  mi_loss: 3.8643  train_loss: 8.8022  time: 2.4499  data: 0.0001  max mem: 20911
Train Epoch: [18]  [1950/4855]  eta: 1:57:53  lr: 0.000010  ml_loss: 4.6953  mi_loss: 4.0299  train_loss: 8.7252  time: 2.4587  data: 0.0001  max mem: 20911
Train Epoch: [18]  [2000/4855]  eta: 1:55:52  lr: 0.000010  ml_loss: 4.9034  mi_loss: 3.5220  train_loss: 8.4254  time: 2.4540  data: 0.0001  max mem: 20911
Train Epoch: [18]  [2050/4855]  eta: 1:53:51  lr: 0.000010  ml_loss: 4.7050  mi_loss: 3.7539  train_loss: 8.4589  time: 2.4399  data: 0.0001  max mem: 20911
Train Epoch: [18]  [2100/4855]  eta: 1:51:49  lr: 0.000010  ml_loss: 5.0589  mi_loss: 4.1089  train_loss: 9.1678  time: 2.4518  data: 0.0001  max mem: 20911
Train Epoch: [18]  [2150/4855]  eta: 1:49:48  lr: 0.000010  ml_loss: 4.3489  mi_loss: 4.0198  train_loss: 8.3687  time: 2.4439  data: 0.0001  max mem: 20911
Train Epoch: [18]  [2200/4855]  eta: 1:47:46  lr: 0.000010  ml_loss: 5.3318  mi_loss: 4.1032  train_loss: 9.4350  time: 2.4344  data: 0.0001  max mem: 20911
Train Epoch: [18]  [2250/4855]  eta: 1:45:45  lr: 0.000010  ml_loss: 4.5965  mi_loss: 3.8377  train_loss: 8.4342  time: 2.4519  data: 0.0001  max mem: 20911
Train Epoch: [18]  [2300/4855]  eta: 1:43:44  lr: 0.000010  ml_loss: 5.0152  mi_loss: 3.9322  train_loss: 8.9473  time: 2.4563  data: 0.0001  max mem: 20911
Train Epoch: [18]  [2350/4855]  eta: 1:41:42  lr: 0.000010  ml_loss: 4.6297  mi_loss: 3.6011  train_loss: 8.2307  time: 2.4193  data: 0.0001  max mem: 20911
Train Epoch: [18]  [2400/4855]  eta: 1:39:41  lr: 0.000010  ml_loss: 3.3940  mi_loss: 4.2514  train_loss: 7.6454  time: 2.4573  data: 0.0002  max mem: 20911
Train Epoch: [18]  [2450/4855]  eta: 1:37:40  lr: 0.000010  ml_loss: 4.9351  mi_loss: 3.8888  train_loss: 8.8239  time: 2.4530  data: 0.0001  max mem: 20911
Train Epoch: [18]  [2500/4855]  eta: 1:35:39  lr: 0.000010  ml_loss: 4.8457  mi_loss: 4.2098  train_loss: 9.0556  time: 2.4445  data: 0.0001  max mem: 20911
Train Epoch: [18]  [2550/4855]  eta: 1:33:37  lr: 0.000010  ml_loss: 4.4599  mi_loss: 3.9109  train_loss: 8.3708  time: 2.4389  data: 0.0001  max mem: 20911
Train Epoch: [18]  [2600/4855]  eta: 1:31:36  lr: 0.000010  ml_loss: 4.5276  mi_loss: 3.7207  train_loss: 8.2483  time: 2.4320  data: 0.0001  max mem: 20911
Train Epoch: [18]  [2650/4855]  eta: 1:29:35  lr: 0.000010  ml_loss: 4.0548  mi_loss: 3.4141  train_loss: 7.4689  time: 2.4576  data: 0.0001  max mem: 20911
Train Epoch: [18]  [2700/4855]  eta: 1:27:33  lr: 0.000010  ml_loss: 4.7683  mi_loss: 3.9082  train_loss: 8.6765  time: 2.4384  data: 0.0001  max mem: 20911
Train Epoch: [18]  [2750/4855]  eta: 1:25:31  lr: 0.000010  ml_loss: 4.7271  mi_loss: 3.8576  train_loss: 8.5847  time: 2.4367  data: 0.0001  max mem: 20911
Train Epoch: [18]  [2800/4855]  eta: 1:23:30  lr: 0.000010  ml_loss: 4.8896  mi_loss: 3.1954  train_loss: 8.0850  time: 2.4269  data: 0.0002  max mem: 20911
Train Epoch: [18]  [2850/4855]  eta: 1:21:28  lr: 0.000010  ml_loss: 4.4337  mi_loss: 3.6156  train_loss: 8.0493  time: 2.4501  data: 0.0001  max mem: 20911
Train Epoch: [18]  [2900/4855]  eta: 1:19:27  lr: 0.000010  ml_loss: 4.9244  mi_loss: 3.9527  train_loss: 8.8771  time: 2.4641  data: 0.0001  max mem: 20911
Train Epoch: [18]  [2950/4855]  eta: 1:17:26  lr: 0.000010  ml_loss: 4.9011  mi_loss: 4.1853  train_loss: 9.0865  time: 2.4711  data: 0.0001  max mem: 20911
Train Epoch: [18]  [3000/4855]  eta: 1:15:25  lr: 0.000010  ml_loss: 4.7180  mi_loss: 3.8696  train_loss: 8.5876  time: 2.4398  data: 0.0001  max mem: 20911
Train Epoch: [18]  [3050/4855]  eta: 1:13:23  lr: 0.000010  ml_loss: 4.0056  mi_loss: 3.4872  train_loss: 7.4928  time: 2.4723  data: 0.0001  max mem: 20911
Train Epoch: [18]  [3100/4855]  eta: 1:11:22  lr: 0.000010  ml_loss: 4.4752  mi_loss: 3.5681  train_loss: 8.0433  time: 2.4743  data: 0.0001  max mem: 20911
Train Epoch: [18]  [3150/4855]  eta: 1:09:20  lr: 0.000010  ml_loss: 4.5645  mi_loss: 3.7573  train_loss: 8.3218  time: 2.4586  data: 0.0001  max mem: 20911
Train Epoch: [18]  [3200/4855]  eta: 1:07:18  lr: 0.000010  ml_loss: 5.2677  mi_loss: 3.8667  train_loss: 9.1345  time: 2.4562  data: 0.0002  max mem: 20911
Train Epoch: [18]  [3250/4855]  eta: 1:05:17  lr: 0.000010  ml_loss: 4.4426  mi_loss: 3.9554  train_loss: 8.3980  time: 2.4423  data: 0.0001  max mem: 20911
Train Epoch: [18]  [3300/4855]  eta: 1:03:15  lr: 0.000010  ml_loss: 4.5291  mi_loss: 4.0203  train_loss: 8.5495  time: 2.4371  data: 0.0001  max mem: 20911
Train Epoch: [18]  [3350/4855]  eta: 1:01:13  lr: 0.000010  ml_loss: 4.2227  mi_loss: 3.8651  train_loss: 8.0878  time: 2.4535  data: 0.0002  max mem: 20911
Train Epoch: [18]  [3400/4855]  eta: 0:59:11  lr: 0.000010  ml_loss: 4.5607  mi_loss: 4.2125  train_loss: 8.7732  time: 2.4402  data: 0.0001  max mem: 20911
Train Epoch: [18]  [3450/4855]  eta: 0:57:09  lr: 0.000010  ml_loss: 3.9853  mi_loss: 3.7850  train_loss: 7.7703  time: 2.4456  data: 0.0001  max mem: 20911
Train Epoch: [18]  [3500/4855]  eta: 0:55:07  lr: 0.000010  ml_loss: 4.3590  mi_loss: 3.1431  train_loss: 7.5022  time: 2.4568  data: 0.0001  max mem: 20911
Train Epoch: [18]  [3550/4855]  eta: 0:53:05  lr: 0.000010  ml_loss: 4.5792  mi_loss: 3.8029  train_loss: 8.3821  time: 2.4376  data: 0.0001  max mem: 20911
Train Epoch: [18]  [3600/4855]  eta: 0:51:03  lr: 0.000010  ml_loss: 4.9767  mi_loss: 4.6532  train_loss: 9.6299  time: 2.4637  data: 0.0001  max mem: 20911
Train Epoch: [18]  [3650/4855]  eta: 0:49:02  lr: 0.000010  ml_loss: 4.7688  mi_loss: 4.2908  train_loss: 9.0596  time: 2.4496  data: 0.0001  max mem: 20911
Train Epoch: [18]  [3700/4855]  eta: 0:47:00  lr: 0.000010  ml_loss: 4.9335  mi_loss: 4.3641  train_loss: 9.2976  time: 2.4636  data: 0.0001  max mem: 20911
Train Epoch: [18]  [3750/4855]  eta: 0:44:58  lr: 0.000010  ml_loss: 5.1857  mi_loss: 3.1353  train_loss: 8.3210  time: 2.4907  data: 0.0001  max mem: 20911
Train Epoch: [18]  [3800/4855]  eta: 0:42:57  lr: 0.000010  ml_loss: 4.3758  mi_loss: 4.2248  train_loss: 8.6006  time: 2.4649  data: 0.0001  max mem: 20911
Train Epoch: [18]  [3850/4855]  eta: 0:40:55  lr: 0.000010  ml_loss: 4.4676  mi_loss: 3.4866  train_loss: 7.9542  time: 2.4479  data: 0.0001  max mem: 20911
Train Epoch: [18]  [3900/4855]  eta: 0:38:53  lr: 0.000010  ml_loss: 4.5248  mi_loss: 3.5847  train_loss: 8.1095  time: 2.4782  data: 0.0002  max mem: 20911
Train Epoch: [18]  [3950/4855]  eta: 0:36:51  lr: 0.000010  ml_loss: 4.4380  mi_loss: 4.0412  train_loss: 8.4791  time: 2.4755  data: 0.0001  max mem: 20911
Train Epoch: [18]  [4000/4855]  eta: 0:34:49  lr: 0.000010  ml_loss: 5.0483  mi_loss: 4.1421  train_loss: 9.1905  time: 2.4792  data: 0.0001  max mem: 20911
Train Epoch: [18]  [4050/4855]  eta: 0:32:47  lr: 0.000010  ml_loss: 4.8107  mi_loss: 3.4177  train_loss: 8.2284  time: 2.4565  data: 0.0001  max mem: 20911
Train Epoch: [18]  [4100/4855]  eta: 0:30:45  lr: 0.000010  ml_loss: 4.4976  mi_loss: 4.3577  train_loss: 8.8553  time: 2.4875  data: 0.0001  max mem: 20911
Train Epoch: [18]  [4150/4855]  eta: 0:28:43  lr: 0.000010  ml_loss: 4.8062  mi_loss: 3.5215  train_loss: 8.3277  time: 2.4768  data: 0.0001  max mem: 20911
Train Epoch: [18]  [4200/4855]  eta: 0:26:41  lr: 0.000010  ml_loss: 4.6276  mi_loss: 3.6260  train_loss: 8.2536  time: 2.4887  data: 0.0002  max mem: 20911
Train Epoch: [18]  [4250/4855]  eta: 0:24:39  lr: 0.000010  ml_loss: 4.1073  mi_loss: 3.3184  train_loss: 7.4257  time: 2.4896  data: 0.0001  max mem: 20911
Train Epoch: [18]  [4300/4855]  eta: 0:22:37  lr: 0.000010  ml_loss: 5.0056  mi_loss: 3.9552  train_loss: 8.9608  time: 2.4787  data: 0.0001  max mem: 20911
Train Epoch: [18]  [4350/4855]  eta: 0:20:35  lr: 0.000010  ml_loss: 4.3293  mi_loss: 4.3911  train_loss: 8.7203  time: 2.4847  data: 0.0001  max mem: 20911
Train Epoch: [18]  [4400/4855]  eta: 0:18:33  lr: 0.000010  ml_loss: 4.5498  mi_loss: 3.8214  train_loss: 8.3712  time: 2.4495  data: 0.0001  max mem: 20911
Train Epoch: [18]  [4450/4855]  eta: 0:16:31  lr: 0.000010  ml_loss: 4.2716  mi_loss: 4.0414  train_loss: 8.3131  time: 2.4507  data: 0.0001  max mem: 20911
Train Epoch: [18]  [4500/4855]  eta: 0:14:28  lr: 0.000010  ml_loss: 5.0592  mi_loss: 3.3331  train_loss: 8.3923  time: 2.4763  data: 0.0001  max mem: 20911
Train Epoch: [18]  [4550/4855]  eta: 0:12:26  lr: 0.000010  ml_loss: 3.9542  mi_loss: 4.0372  train_loss: 7.9914  time: 2.4685  data: 0.0001  max mem: 20911
Train Epoch: [18]  [4600/4855]  eta: 0:10:24  lr: 0.000010  ml_loss: 4.7329  mi_loss: 3.6329  train_loss: 8.3658  time: 2.4530  data: 0.0001  max mem: 20911
Train Epoch: [18]  [4650/4855]  eta: 0:08:21  lr: 0.000010  ml_loss: 4.8950  mi_loss: 3.5992  train_loss: 8.4942  time: 2.4500  data: 0.0001  max mem: 20911
Train Epoch: [18]  [4700/4855]  eta: 0:06:19  lr: 0.000010  ml_loss: 5.1019  mi_loss: 3.6828  train_loss: 8.7847  time: 2.4832  data: 0.0001  max mem: 20911
Train Epoch: [18]  [4750/4855]  eta: 0:04:17  lr: 0.000010  ml_loss: 4.8488  mi_loss: 3.8005  train_loss: 8.6493  time: 2.4694  data: 0.0001  max mem: 20911
Train Epoch: [18]  [4800/4855]  eta: 0:02:14  lr: 0.000010  ml_loss: 5.0235  mi_loss: 3.9146  train_loss: 8.9381  time: 2.4594  data: 0.0001  max mem: 20911
Train Epoch: [18]  [4850/4855]  eta: 0:00:12  lr: 0.000010  ml_loss: 4.6234  mi_loss: 3.9661  train_loss: 8.5895  time: 2.4723  data: 0.0002  max mem: 20911
Train Epoch: [18]  [4854/4855]  eta: 0:00:02  lr: 0.000010  ml_loss: 4.5875  mi_loss: 3.3882  train_loss: 7.9757  time: 2.4825  data: 0.0006  max mem: 20911
Train Epoch: [18] Total time: 3:18:10 (2.4491 s / it)
Val Epoch: [18]  [  0/540]  eta: 0:23:12  ml_loss: 4.7703  mi_loss: 4.0429  val_loss: 8.8132  accML: 0.2538  accMI: 0.1351  time: 2.5782  data: 2.2170  max mem: 20911
Val Epoch: [18]  [ 50/540]  eta: 0:06:34  ml_loss: 4.3664  mi_loss: 3.6994  val_loss: 8.0659  accML: 0.3020  accMI: 0.2145  time: 0.7952  data: 0.6329  max mem: 20911
Val Epoch: [18]  [100/540]  eta: 0:05:53  ml_loss: 4.2413  mi_loss: 4.3707  val_loss: 8.6119  accML: 0.3088  accMI: 0.1387  time: 0.7612  data: 0.5990  max mem: 20911
Val Epoch: [18]  [150/540]  eta: 0:05:25  ml_loss: 4.7250  mi_loss: 4.3895  val_loss: 9.1144  accML: 0.2600  accMI: 0.1267  time: 0.9338  data: 0.7690  max mem: 20911
Val Epoch: [18]  [200/540]  eta: 0:04:43  ml_loss: 4.5732  mi_loss: 4.2455  val_loss: 8.8187  accML: 0.2671  accMI: 0.1390  time: 0.8301  data: 0.6666  max mem: 20911
Val Epoch: [18]  [250/540]  eta: 0:04:00  ml_loss: 4.2955  mi_loss: 3.7991  val_loss: 8.0946  accML: 0.3134  accMI: 0.1739  time: 0.8583  data: 0.6952  max mem: 20911
Val Epoch: [18]  [300/540]  eta: 0:03:19  ml_loss: 4.1891  mi_loss: 3.8372  val_loss: 8.0262  accML: 0.3195  accMI: 0.1989  time: 0.8637  data: 0.7002  max mem: 20911
Val Epoch: [18]  [350/540]  eta: 0:02:37  ml_loss: 4.6350  mi_loss: 3.1572  val_loss: 7.7921  accML: 0.2562  accMI: 0.2880  time: 0.8084  data: 0.6460  max mem: 20911
Val Epoch: [18]  [400/540]  eta: 0:01:56  ml_loss: 5.1365  mi_loss: 4.2520  val_loss: 9.3885  accML: 0.2256  accMI: 0.1022  time: 0.8561  data: 0.6927  max mem: 20911
Val Epoch: [18]  [450/540]  eta: 0:01:15  ml_loss: 4.8272  mi_loss: 3.9074  val_loss: 8.7346  accML: 0.2687  accMI: 0.1360  time: 0.8590  data: 0.6957  max mem: 20911
Val Epoch: [18]  [500/540]  eta: 0:00:33  ml_loss: 4.8382  mi_loss: 3.7983  val_loss: 8.6365  accML: 0.2483  accMI: 0.1378  time: 0.7564  data: 0.5943  max mem: 20911
Val Epoch: [18]  [539/540]  eta: 0:00:00  ml_loss: 5.0151  mi_loss: 4.0009  val_loss: 9.0160  accML: 0.2026  accMI: 0.1757  time: 0.7622  data: 0.6022  max mem: 20911
Val Epoch: [18] Total time: 0:07:32 (0.8378 s / it)
epoch:18, iter:92244, 4854,  train_loss: 7.975749969482422, valid_loss: 8.505154554049174, idiv_loss:(4.533214864907442, 3.9719396935568914), acc:(0.2779511571758323, 0.1660458106961515)
Averaged stats: lr: 0.0000  ml_loss: 4.6020  mi_loss: 3.8689  train_loss: 8.4709
epoch 18 7.975749969482422
Train Epoch: [19]  [   0/4855]  eta: 8:09:06  lr: 0.000010  ml_loss: 4.5851  mi_loss: 3.6186  train_loss: 8.2037  time: 6.0445  data: 2.8810  max mem: 20911
Train Epoch: [19]  [  50/4855]  eta: 3:25:04  lr: 0.000010  ml_loss: 4.7976  mi_loss: 4.1229  train_loss: 8.9205  time: 2.4946  data: 0.0001  max mem: 20911
Train Epoch: [19]  [ 100/4855]  eta: 3:19:35  lr: 0.000010  ml_loss: 4.7696  mi_loss: 3.6800  train_loss: 8.4496  time: 2.4685  data: 0.0001  max mem: 20911
Train Epoch: [19]  [ 150/4855]  eta: 3:16:51  lr: 0.000010  ml_loss: 4.9423  mi_loss: 3.9367  train_loss: 8.8790  time: 2.4961  data: 0.0001  max mem: 20911
Train Epoch: [19]  [ 200/4855]  eta: 3:14:26  lr: 0.000010  ml_loss: 4.4055  mi_loss: 3.9728  train_loss: 8.3783  time: 2.4935  data: 0.0001  max mem: 20911
Train Epoch: [19]  [ 250/4855]  eta: 3:12:09  lr: 0.000010  ml_loss: 4.4968  mi_loss: 3.3708  train_loss: 7.8677  time: 2.4908  data: 0.0001  max mem: 20911
Train Epoch: [19]  [ 300/4855]  eta: 3:09:51  lr: 0.000010  ml_loss: 4.7114  mi_loss: 3.8560  train_loss: 8.5674  time: 2.4869  data: 0.0001  max mem: 20911
Train Epoch: [19]  [ 350/4855]  eta: 3:07:36  lr: 0.000010  ml_loss: 4.3602  mi_loss: 3.8013  train_loss: 8.1615  time: 2.4858  data: 0.0001  max mem: 20911
Train Epoch: [19]  [ 400/4855]  eta: 3:05:24  lr: 0.000010  ml_loss: 4.4080  mi_loss: 3.5801  train_loss: 7.9881  time: 2.4892  data: 0.0001  max mem: 20911
Train Epoch: [19]  [ 450/4855]  eta: 3:03:13  lr: 0.000010  ml_loss: 4.8618  mi_loss: 3.8368  train_loss: 8.6986  time: 2.4862  data: 0.0001  max mem: 20911
Train Epoch: [19]  [ 500/4855]  eta: 3:01:04  lr: 0.000010  ml_loss: 5.0641  mi_loss: 3.8542  train_loss: 8.9183  time: 2.4830  data: 0.0001  max mem: 20911
Train Epoch: [19]  [ 550/4855]  eta: 2:58:53  lr: 0.000010  ml_loss: 4.7608  mi_loss: 4.0063  train_loss: 8.7670  time: 2.4716  data: 0.0001  max mem: 20911
Train Epoch: [19]  [ 600/4855]  eta: 2:56:37  lr: 0.000010  ml_loss: 3.9395  mi_loss: 3.3539  train_loss: 7.2934  time: 2.4775  data: 0.0001  max mem: 20911
Train Epoch: [19]  [ 650/4855]  eta: 2:54:25  lr: 0.000010  ml_loss: 5.0546  mi_loss: 3.9139  train_loss: 8.9685  time: 2.4795  data: 0.0001  max mem: 20911
Train Epoch: [19]  [ 700/4855]  eta: 2:52:12  lr: 0.000010  ml_loss: 4.5565  mi_loss: 3.5996  train_loss: 8.1562  time: 2.4583  data: 0.0001  max mem: 20911
Train Epoch: [19]  [ 750/4855]  eta: 2:50:04  lr: 0.000010  ml_loss: 4.2352  mi_loss: 3.7188  train_loss: 7.9540  time: 2.4751  data: 0.0001  max mem: 20911
Train Epoch: [19]  [ 800/4855]  eta: 2:47:58  lr: 0.000010  ml_loss: 4.1765  mi_loss: 4.6184  train_loss: 8.7949  time: 2.4731  data: 0.0001  max mem: 20911
Train Epoch: [19]  [ 850/4855]  eta: 2:45:51  lr: 0.000010  ml_loss: 5.1872  mi_loss: 3.4311  train_loss: 8.6183  time: 2.4870  data: 0.0001  max mem: 20911
Train Epoch: [19]  [ 900/4855]  eta: 2:43:48  lr: 0.000010  ml_loss: 4.4953  mi_loss: 4.1593  train_loss: 8.6546  time: 2.4838  data: 0.0001  max mem: 20911
Train Epoch: [19]  [ 950/4855]  eta: 2:41:40  lr: 0.000010  ml_loss: 4.1600  mi_loss: 3.7480  train_loss: 7.9079  time: 2.4659  data: 0.0001  max mem: 20911
Train Epoch: [19]  [1000/4855]  eta: 2:39:32  lr: 0.000010  ml_loss: 4.3951  mi_loss: 3.6730  train_loss: 8.0681  time: 2.4650  data: 0.0001  max mem: 20911
Train Epoch: [19]  [1050/4855]  eta: 2:37:24  lr: 0.000010  ml_loss: 4.6636  mi_loss: 3.9436  train_loss: 8.6072  time: 2.4724  data: 0.0001  max mem: 20911
Train Epoch: [19]  [1100/4855]  eta: 2:35:17  lr: 0.000010  ml_loss: 4.5117  mi_loss: 3.8101  train_loss: 8.3219  time: 2.4625  data: 0.0001  max mem: 20911
Train Epoch: [19]  [1150/4855]  eta: 2:33:11  lr: 0.000010  ml_loss: 4.4020  mi_loss: 3.8464  train_loss: 8.2484  time: 2.4467  data: 0.0001  max mem: 20911
Train Epoch: [19]  [1200/4855]  eta: 2:31:04  lr: 0.000010  ml_loss: 4.5534  mi_loss: 3.7961  train_loss: 8.3496  time: 2.4716  data: 0.0001  max mem: 20911
Train Epoch: [19]  [1250/4855]  eta: 2:28:59  lr: 0.000010  ml_loss: 4.9421  mi_loss: 4.1599  train_loss: 9.1019  time: 2.4688  data: 0.0001  max mem: 20911
Train Epoch: [19]  [1300/4855]  eta: 2:26:52  lr: 0.000010  ml_loss: 4.8893  mi_loss: 3.5980  train_loss: 8.4873  time: 2.4725  data: 0.0001  max mem: 20911
Train Epoch: [19]  [1350/4855]  eta: 2:24:47  lr: 0.000010  ml_loss: 4.5565  mi_loss: 3.9555  train_loss: 8.5121  time: 2.4784  data: 0.0001  max mem: 20911
Train Epoch: [19]  [1400/4855]  eta: 2:22:40  lr: 0.000010  ml_loss: 4.9054  mi_loss: 2.7766  train_loss: 7.6820  time: 2.4607  data: 0.0001  max mem: 20911
Train Epoch: [19]  [1450/4855]  eta: 2:20:34  lr: 0.000010  ml_loss: 4.0561  mi_loss: 3.7304  train_loss: 7.7865  time: 2.4610  data: 0.0001  max mem: 20911
Train Epoch: [19]  [1500/4855]  eta: 2:18:28  lr: 0.000010  ml_loss: 4.5263  mi_loss: 4.3445  train_loss: 8.8708  time: 2.4512  data: 0.0001  max mem: 20911
Train Epoch: [19]  [1550/4855]  eta: 2:16:23  lr: 0.000010  ml_loss: 4.2829  mi_loss: 3.8828  train_loss: 8.1657  time: 2.4680  data: 0.0001  max mem: 20911
Train Epoch: [19]  [1600/4855]  eta: 2:14:20  lr: 0.000010  ml_loss: 4.3356  mi_loss: 3.4018  train_loss: 7.7373  time: 2.4736  data: 0.0001  max mem: 20911
Train Epoch: [19]  [1650/4855]  eta: 2:12:16  lr: 0.000010  ml_loss: 4.4376  mi_loss: 3.6138  train_loss: 8.0514  time: 2.4803  data: 0.0001  max mem: 20911
Train Epoch: [19]  [1700/4855]  eta: 2:10:11  lr: 0.000010  ml_loss: 4.8736  mi_loss: 4.3408  train_loss: 9.2144  time: 2.4705  data: 0.0001  max mem: 20911
Train Epoch: [19]  [1750/4855]  eta: 2:08:07  lr: 0.000010  ml_loss: 4.5942  mi_loss: 3.8908  train_loss: 8.4850  time: 2.4713  data: 0.0001  max mem: 20911
Train Epoch: [19]  [1800/4855]  eta: 2:06:03  lr: 0.000010  ml_loss: 4.3394  mi_loss: 3.7100  train_loss: 8.0494  time: 2.4728  data: 0.0001  max mem: 20911
Train Epoch: [19]  [1850/4855]  eta: 2:03:57  lr: 0.000010  ml_loss: 4.8992  mi_loss: 2.9979  train_loss: 7.8970  time: 2.4730  data: 0.0001  max mem: 20911
Train Epoch: [19]  [1900/4855]  eta: 2:01:52  lr: 0.000010  ml_loss: 4.9108  mi_loss: 4.1335  train_loss: 9.0443  time: 2.4523  data: 0.0001  max mem: 20911
Train Epoch: [19]  [1950/4855]  eta: 1:59:47  lr: 0.000010  ml_loss: 5.0160  mi_loss: 3.8175  train_loss: 8.8335  time: 2.4609  data: 0.0001  max mem: 20911
Train Epoch: [19]  [2000/4855]  eta: 1:57:43  lr: 0.000010  ml_loss: 4.4693  mi_loss: 3.5823  train_loss: 8.0516  time: 2.4785  data: 0.0001  max mem: 20911
Train Epoch: [19]  [2050/4855]  eta: 1:55:38  lr: 0.000010  ml_loss: 4.5504  mi_loss: 3.8140  train_loss: 8.3644  time: 2.4772  data: 0.0001  max mem: 20911
Train Epoch: [19]  [2100/4855]  eta: 1:53:34  lr: 0.000010  ml_loss: 4.8368  mi_loss: 3.6603  train_loss: 8.4971  time: 2.4487  data: 0.0001  max mem: 20911
Train Epoch: [19]  [2150/4855]  eta: 1:51:29  lr: 0.000010  ml_loss: 4.4119  mi_loss: 3.6257  train_loss: 8.0377  time: 2.4506  data: 0.0001  max mem: 20911
Train Epoch: [19]  [2200/4855]  eta: 1:49:25  lr: 0.000010  ml_loss: 5.0037  mi_loss: 3.8282  train_loss: 8.8318  time: 2.4783  data: 0.0001  max mem: 20911
Train Epoch: [19]  [2250/4855]  eta: 1:47:21  lr: 0.000010  ml_loss: 4.1261  mi_loss: 3.6975  train_loss: 7.8236  time: 2.4632  data: 0.0001  max mem: 20911
Train Epoch: [19]  [2300/4855]  eta: 1:45:16  lr: 0.000010  ml_loss: 4.5052  mi_loss: 3.6778  train_loss: 8.1830  time: 2.4587  data: 0.0001  max mem: 20911
Train Epoch: [19]  [2350/4855]  eta: 1:43:12  lr: 0.000010  ml_loss: 4.8420  mi_loss: 4.0056  train_loss: 8.8476  time: 2.4864  data: 0.0001  max mem: 20911
Train Epoch: [19]  [2400/4855]  eta: 1:41:09  lr: 0.000010  ml_loss: 4.2206  mi_loss: 3.4682  train_loss: 7.6887  time: 2.4550  data: 0.0001  max mem: 20911
Train Epoch: [19]  [2450/4855]  eta: 1:39:04  lr: 0.000010  ml_loss: 4.5094  mi_loss: 4.0465  train_loss: 8.5559  time: 2.4730  data: 0.0001  max mem: 20911
Train Epoch: [19]  [2500/4855]  eta: 1:37:01  lr: 0.000010  ml_loss: 4.8386  mi_loss: 3.8452  train_loss: 8.6838  time: 2.4709  data: 0.0001  max mem: 20911
Train Epoch: [19]  [2550/4855]  eta: 1:34:58  lr: 0.000010  ml_loss: 4.7912  mi_loss: 3.5023  train_loss: 8.2935  time: 2.4774  data: 0.0001  max mem: 20911
Train Epoch: [19]  [2600/4855]  eta: 1:32:54  lr: 0.000010  ml_loss: 4.3219  mi_loss: 3.9952  train_loss: 8.3171  time: 2.4738  data: 0.0001  max mem: 20911
Train Epoch: [19]  [2650/4855]  eta: 1:30:51  lr: 0.000010  ml_loss: 4.2152  mi_loss: 3.8543  train_loss: 8.0695  time: 2.4843  data: 0.0001  max mem: 20911
Train Epoch: [19]  [2700/4855]  eta: 1:28:47  lr: 0.000010  ml_loss: 4.1400  mi_loss: 3.1952  train_loss: 7.3352  time: 2.4681  data: 0.0001  max mem: 20911
Train Epoch: [19]  [2750/4855]  eta: 1:26:43  lr: 0.000010  ml_loss: 3.3397  mi_loss: 3.6377  train_loss: 6.9774  time: 2.4661  data: 0.0001  max mem: 20911
Train Epoch: [19]  [2800/4855]  eta: 1:24:40  lr: 0.000010  ml_loss: 4.9389  mi_loss: 3.6370  train_loss: 8.5759  time: 2.4638  data: 0.0001  max mem: 20911
Train Epoch: [19]  [2850/4855]  eta: 1:22:36  lr: 0.000010  ml_loss: 3.9425  mi_loss: 3.9115  train_loss: 7.8540  time: 2.4674  data: 0.0001  max mem: 20911
Train Epoch: [19]  [2900/4855]  eta: 1:20:32  lr: 0.000010  ml_loss: 4.8477  mi_loss: 3.5571  train_loss: 8.4047  time: 2.4779  data: 0.0001  max mem: 20911
Train Epoch: [19]  [2950/4855]  eta: 1:18:29  lr: 0.000010  ml_loss: 4.3452  mi_loss: 3.7547  train_loss: 8.0999  time: 2.4653  data: 0.0001  max mem: 20911
Train Epoch: [19]  [3000/4855]  eta: 1:16:25  lr: 0.000010  ml_loss: 4.5554  mi_loss: 3.7382  train_loss: 8.2936  time: 2.4850  data: 0.0001  max mem: 20911
Train Epoch: [19]  [3050/4855]  eta: 1:14:22  lr: 0.000010  ml_loss: 4.3876  mi_loss: 3.7253  train_loss: 8.1128  time: 2.4898  data: 0.0001  max mem: 20911
Train Epoch: [19]  [3100/4855]  eta: 1:12:19  lr: 0.000010  ml_loss: 4.6042  mi_loss: 3.8915  train_loss: 8.4957  time: 2.4839  data: 0.0001  max mem: 20911
Train Epoch: [19]  [3150/4855]  eta: 1:10:16  lr: 0.000010  ml_loss: 4.6099  mi_loss: 4.1275  train_loss: 8.7373  time: 2.4933  data: 0.0001  max mem: 20911
Train Epoch: [19]  [3200/4855]  eta: 1:08:12  lr: 0.000010  ml_loss: 4.5558  mi_loss: 3.6169  train_loss: 8.1728  time: 2.4748  data: 0.0001  max mem: 20911
Train Epoch: [19]  [3250/4855]  eta: 1:06:09  lr: 0.000010  ml_loss: 4.2686  mi_loss: 3.6489  train_loss: 7.9174  time: 2.4708  data: 0.0001  max mem: 20911
Train Epoch: [19]  [3300/4855]  eta: 1:04:05  lr: 0.000010  ml_loss: 4.7117  mi_loss: 4.3879  train_loss: 9.0996  time: 2.4889  data: 0.0001  max mem: 20911
Train Epoch: [19]  [3350/4855]  eta: 1:02:02  lr: 0.000010  ml_loss: 4.4811  mi_loss: 4.1231  train_loss: 8.6042  time: 2.4910  data: 0.0001  max mem: 20911
Train Epoch: [19]  [3400/4855]  eta: 0:59:58  lr: 0.000010  ml_loss: 4.6412  mi_loss: 3.8147  train_loss: 8.4559  time: 2.4887  data: 0.0001  max mem: 20911
Train Epoch: [19]  [3450/4855]  eta: 0:57:55  lr: 0.000010  ml_loss: 4.5794  mi_loss: 3.8125  train_loss: 8.3919  time: 2.4970  data: 0.0001  max mem: 20911
Train Epoch: [19]  [3500/4855]  eta: 0:55:52  lr: 0.000010  ml_loss: 4.1276  mi_loss: 3.9471  train_loss: 8.0747  time: 2.4906  data: 0.0001  max mem: 20911
Train Epoch: [19]  [3550/4855]  eta: 0:53:48  lr: 0.000010  ml_loss: 5.2633  mi_loss: 3.8311  train_loss: 9.0944  time: 2.4586  data: 0.0001  max mem: 20911
Train Epoch: [19]  [3600/4855]  eta: 0:51:44  lr: 0.000010  ml_loss: 4.9278  mi_loss: 3.7463  train_loss: 8.6741  time: 2.4659  data: 0.0001  max mem: 20911
Train Epoch: [19]  [3650/4855]  eta: 0:49:40  lr: 0.000010  ml_loss: 4.2040  mi_loss: 3.5144  train_loss: 7.7185  time: 2.4559  data: 0.0001  max mem: 20911
Train Epoch: [19]  [3700/4855]  eta: 0:47:36  lr: 0.000010  ml_loss: 4.7203  mi_loss: 3.3811  train_loss: 8.1014  time: 2.4621  data: 0.0001  max mem: 20911
Train Epoch: [19]  [3750/4855]  eta: 0:45:32  lr: 0.000010  ml_loss: 3.9471  mi_loss: 3.6836  train_loss: 7.6307  time: 2.4570  data: 0.0001  max mem: 20911
Train Epoch: [19]  [3800/4855]  eta: 0:43:29  lr: 0.000010  ml_loss: 4.7613  mi_loss: 3.7585  train_loss: 8.5198  time: 2.4728  data: 0.0001  max mem: 20911
Train Epoch: [19]  [3850/4855]  eta: 0:41:25  lr: 0.000010  ml_loss: 4.2156  mi_loss: 4.4911  train_loss: 8.7067  time: 2.4658  data: 0.0001  max mem: 20911
Train Epoch: [19]  [3900/4855]  eta: 0:39:21  lr: 0.000010  ml_loss: 3.9706  mi_loss: 3.6968  train_loss: 7.6674  time: 2.4610  data: 0.0001  max mem: 20911
Train Epoch: [19]  [3950/4855]  eta: 0:37:18  lr: 0.000010  ml_loss: 4.3295  mi_loss: 4.1373  train_loss: 8.4668  time: 2.4805  data: 0.0001  max mem: 20911
Train Epoch: [19]  [4000/4855]  eta: 0:35:14  lr: 0.000010  ml_loss: 5.0376  mi_loss: 3.9451  train_loss: 8.9826  time: 2.4554  data: 0.0001  max mem: 20911
Train Epoch: [19]  [4050/4855]  eta: 0:33:11  lr: 0.000010  ml_loss: 4.6848  mi_loss: 4.0749  train_loss: 8.7597  time: 2.4975  data: 0.0001  max mem: 20911
Train Epoch: [19]  [4100/4855]  eta: 0:31:07  lr: 0.000010  ml_loss: 4.1841  mi_loss: 3.9789  train_loss: 8.1630  time: 2.4704  data: 0.0001  max mem: 20911
Train Epoch: [19]  [4150/4855]  eta: 0:29:03  lr: 0.000010  ml_loss: 4.9262  mi_loss: 4.2648  train_loss: 9.1910  time: 2.4631  data: 0.0001  max mem: 20911
Train Epoch: [19]  [4200/4855]  eta: 0:27:00  lr: 0.000010  ml_loss: 4.2055  mi_loss: 4.0294  train_loss: 8.2349  time: 2.4921  data: 0.0001  max mem: 20911
Train Epoch: [19]  [4250/4855]  eta: 0:24:56  lr: 0.000010  ml_loss: 4.7782  mi_loss: 3.5890  train_loss: 8.3673  time: 2.4943  data: 0.0001  max mem: 20911
Train Epoch: [19]  [4300/4855]  eta: 0:22:53  lr: 0.000010  ml_loss: 4.7862  mi_loss: 3.9699  train_loss: 8.7561  time: 2.4991  data: 0.0001  max mem: 20911
Train Epoch: [19]  [4350/4855]  eta: 0:20:49  lr: 0.000010  ml_loss: 4.4839  mi_loss: 3.8047  train_loss: 8.2887  time: 2.4960  data: 0.0001  max mem: 20911
Train Epoch: [19]  [4400/4855]  eta: 0:18:45  lr: 0.000010  ml_loss: 3.0671  mi_loss: 3.5301  train_loss: 6.5972  time: 2.4929  data: 0.0001  max mem: 20911
Train Epoch: [19]  [4450/4855]  eta: 0:16:42  lr: 0.000010  ml_loss: 4.5494  mi_loss: 3.9817  train_loss: 8.5312  time: 2.4930  data: 0.0001  max mem: 20911
Train Epoch: [19]  [4500/4855]  eta: 0:14:38  lr: 0.000010  ml_loss: 4.9823  mi_loss: 3.9576  train_loss: 8.9399  time: 2.4927  data: 0.0001  max mem: 20911
Train Epoch: [19]  [4550/4855]  eta: 0:12:34  lr: 0.000010  ml_loss: 4.6599  mi_loss: 3.9862  train_loss: 8.6462  time: 2.4991  data: 0.0001  max mem: 20911
Train Epoch: [19]  [4600/4855]  eta: 0:10:31  lr: 0.000010  ml_loss: 3.7088  mi_loss: 3.8628  train_loss: 7.5716  time: 2.5007  data: 0.0001  max mem: 20911
Train Epoch: [19]  [4650/4855]  eta: 0:08:27  lr: 0.000010  ml_loss: 4.3485  mi_loss: 4.4341  train_loss: 8.7826  time: 2.4953  data: 0.0001  max mem: 20911
Train Epoch: [19]  [4700/4855]  eta: 0:06:23  lr: 0.000010  ml_loss: 4.3831  mi_loss: 2.6307  train_loss: 7.0137  time: 2.4746  data: 0.0001  max mem: 20911
Train Epoch: [19]  [4750/4855]  eta: 0:04:19  lr: 0.000010  ml_loss: 4.4671  mi_loss: 3.9564  train_loss: 8.4235  time: 2.4791  data: 0.0001  max mem: 20911
Train Epoch: [19]  [4800/4855]  eta: 0:02:16  lr: 0.000010  ml_loss: 4.8470  mi_loss: 4.5027  train_loss: 9.3498  time: 2.4818  data: 0.0001  max mem: 20911
Train Epoch: [19]  [4850/4855]  eta: 0:00:12  lr: 0.000010  ml_loss: 4.5088  mi_loss: 3.2928  train_loss: 7.8017  time: 2.4822  data: 0.0001  max mem: 20911
Train Epoch: [19]  [4854/4855]  eta: 0:00:02  lr: 0.000010  ml_loss: 4.6739  mi_loss: 4.2984  train_loss: 8.9723  time: 2.4855  data: 0.0005  max mem: 20911
Train Epoch: [19] Total time: 3:20:22 (2.4763 s / it)
Val Epoch: [19]  [  0/540]  eta: 0:23:13  ml_loss: 4.4755  mi_loss: 4.0693  val_loss: 8.5448  accML: 0.2812  accMI: 0.1243  time: 2.5806  data: 2.2302  max mem: 20911
Val Epoch: [19]  [ 50/540]  eta: 0:06:33  ml_loss: 4.4597  mi_loss: 3.7135  val_loss: 8.1732  accML: 0.3032  accMI: 0.2145  time: 0.7843  data: 0.6222  max mem: 20911
Val Epoch: [19]  [100/540]  eta: 0:05:53  ml_loss: 4.3643  mi_loss: 4.3024  val_loss: 8.6666  accML: 0.3003  accMI: 0.1360  time: 0.7690  data: 0.6067  max mem: 20911
Val Epoch: [19]  [150/540]  eta: 0:05:25  ml_loss: 4.7940  mi_loss: 4.3856  val_loss: 9.1795  accML: 0.2471  accMI: 0.1186  time: 0.9252  data: 0.7609  max mem: 20911
Val Epoch: [19]  [200/540]  eta: 0:04:43  ml_loss: 4.5841  mi_loss: 4.1787  val_loss: 8.7628  accML: 0.2800  accMI: 0.1390  time: 0.8400  data: 0.6771  max mem: 20911
Val Epoch: [19]  [250/540]  eta: 0:04:00  ml_loss: 4.4840  mi_loss: 3.7863  val_loss: 8.2703  accML: 0.2837  accMI: 0.1739  time: 0.8498  data: 0.6871  max mem: 20911
Val Epoch: [19]  [300/540]  eta: 0:03:19  ml_loss: 4.4194  mi_loss: 3.8028  val_loss: 8.2222  accML: 0.2763  accMI: 0.2016  time: 0.8657  data: 0.7026  max mem: 20911
Val Epoch: [19]  [350/540]  eta: 0:02:37  ml_loss: 4.1765  mi_loss: 3.1009  val_loss: 7.2774  accML: 0.3023  accMI: 0.2880  time: 0.8007  data: 0.6386  max mem: 20911
Val Epoch: [19]  [400/540]  eta: 0:01:56  ml_loss: 5.0282  mi_loss: 4.2194  val_loss: 9.2476  accML: 0.2458  accMI: 0.1048  time: 0.8642  data: 0.7012  max mem: 20911
Val Epoch: [19]  [450/540]  eta: 0:01:15  ml_loss: 4.9985  mi_loss: 3.9532  val_loss: 8.9517  accML: 0.2371  accMI: 0.1493  time: 0.8388  data: 0.6760  max mem: 20911
Val Epoch: [19]  [500/540]  eta: 0:00:33  ml_loss: 4.7133  mi_loss: 3.7877  val_loss: 8.5010  accML: 0.2640  accMI: 0.1514  time: 0.7595  data: 0.5975  max mem: 20911
Val Epoch: [19]  [539/540]  eta: 0:00:00  ml_loss: 4.8977  mi_loss: 4.1317  val_loss: 9.0294  accML: 0.2088  accMI: 0.1982  time: 0.7608  data: 0.6008  max mem: 20911
Val Epoch: [19] Total time: 0:07:31 (0.8356 s / it)
epoch:19, iter:97099, 4854,  train_loss: 8.972286224365234, valid_loss: 8.4469762440081, idiv_loss:(4.496153034987273, 3.950823203722636), acc:(0.28092443874036827, 0.16814847482299364)
Averaged stats: lr: 0.0000  ml_loss: 4.5601  mi_loss: 3.8307  train_loss: 8.3908
epoch 19 8.972286224365234
Training time 2 days, 21:09:40
ai-platform-wlf1-ge10-1:85752:85792 [1] NCCL INFO [Service thread] Connection closed by localRank 1
ai-platform-wlf1-ge10-1:85755:85795 [3] NCCL INFO [Service thread] Connection closed by localRank 3
ai-platform-wlf1-ge10-1:85752:85752 [1] NCCL INFO comm 0x42db0530 rank 1 nranks 4 cudaDev 1 busId 24000 - Abort COMPLETE
ai-platform-wlf1-ge10-1:85755:85755 [3] NCCL INFO comm 0x430b9890 rank 3 nranks 4 cudaDev 3 busId e1000 - Abort COMPLETE
ai-platform-wlf1-ge10-1:85751:85794 [0] NCCL INFO [Service thread] Connection closed by localRank 0
ai-platform-wlf1-ge10-1:85751:85751 [0] NCCL INFO comm 0x431a23f0 rank 0 nranks 4 cudaDev 0 busId 1000 - Abort COMPLETE
ai-platform-wlf1-ge10-1:85753:85793 [2] NCCL INFO [Service thread] Connection closed by localRank 2
ai-platform-wlf1-ge10-1:85753:85753 [2] NCCL INFO comm 0x436e6450 rank 2 nranks 4 cudaDev 2 busId 81000 - Abort COMPLETE
