/opt/conda/envs/albef-ab/lib/python3.8/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 3): env://
| distributed init (rank 0): env://
| distributed init (rank 2): env://
| distributed init (rank 1): env://
Creating retrieval dataset
Creating model
load checkpoint from /nlp_group/wuxing/yuhuimu/AB-layoutlmv3/output/albef/pretrain/checkpoint_04.pth
_IncompatibleKeys(missing_keys=['title_head.weight', 'title_head.bias'], unexpected_keys=['image_queue', 'text_queue', 'queue_ptr', 'vision_proj.weight', 'vision_proj.bias', 'text_proj.weight', 'text_proj.bias', 'itm_head.weight', 'itm_head.bias', 'visual_encoder_m.cls_token', 'visual_encoder_m.pos_embed', 'visual_encoder_m.patch_embed.proj.weight', 'visual_encoder_m.patch_embed.proj.bias', 'visual_encoder_m.blocks.0.norm1.weight', 'visual_encoder_m.blocks.0.norm1.bias', 'visual_encoder_m.blocks.0.attn.qkv.weight', 'visual_encoder_m.blocks.0.attn.qkv.bias', 'visual_encoder_m.blocks.0.attn.proj.weight', 'visual_encoder_m.blocks.0.attn.proj.bias', 'visual_encoder_m.blocks.0.norm2.weight', 'visual_encoder_m.blocks.0.norm2.bias', 'visual_encoder_m.blocks.0.mlp.fc1.weight', 'visual_encoder_m.blocks.0.mlp.fc1.bias', 'visual_encoder_m.blocks.0.mlp.fc2.weight', 'visual_encoder_m.blocks.0.mlp.fc2.bias', 'visual_encoder_m.blocks.1.norm1.weight', 'visual_encoder_m.blocks.1.norm1.bias', 'visual_encoder_m.blocks.1.attn.qkv.weight', 'visual_encoder_m.blocks.1.attn.qkv.bias', 'visual_encoder_m.blocks.1.attn.proj.weight', 'visual_encoder_m.blocks.1.attn.proj.bias', 'visual_encoder_m.blocks.1.norm2.weight', 'visual_encoder_m.blocks.1.norm2.bias', 'visual_encoder_m.blocks.1.mlp.fc1.weight', 'visual_encoder_m.blocks.1.mlp.fc1.bias', 'visual_encoder_m.blocks.1.mlp.fc2.weight', 'visual_encoder_m.blocks.1.mlp.fc2.bias', 'visual_encoder_m.blocks.2.norm1.weight', 'visual_encoder_m.blocks.2.norm1.bias', 'visual_encoder_m.blocks.2.attn.qkv.weight', 'visual_encoder_m.blocks.2.attn.qkv.bias', 'visual_encoder_m.blocks.2.attn.proj.weight', 'visual_encoder_m.blocks.2.attn.proj.bias', 'visual_encoder_m.blocks.2.norm2.weight', 'visual_encoder_m.blocks.2.norm2.bias', 'visual_encoder_m.blocks.2.mlp.fc1.weight', 'visual_encoder_m.blocks.2.mlp.fc1.bias', 'visual_encoder_m.blocks.2.mlp.fc2.weight', 'visual_encoder_m.blocks.2.mlp.fc2.bias', 'visual_encoder_m.blocks.3.norm1.weight', 'visual_encoder_m.blocks.3.norm1.bias', 'visual_encoder_m.blocks.3.attn.qkv.weight', 'visual_encoder_m.blocks.3.attn.qkv.bias', 'visual_encoder_m.blocks.3.attn.proj.weight', 'visual_encoder_m.blocks.3.attn.proj.bias', 'visual_encoder_m.blocks.3.norm2.weight', 'visual_encoder_m.blocks.3.norm2.bias', 'visual_encoder_m.blocks.3.mlp.fc1.weight', 'visual_encoder_m.blocks.3.mlp.fc1.bias', 'visual_encoder_m.blocks.3.mlp.fc2.weight', 'visual_encoder_m.blocks.3.mlp.fc2.bias', 'visual_encoder_m.blocks.4.norm1.weight', 'visual_encoder_m.blocks.4.norm1.bias', 'visual_encoder_m.blocks.4.attn.qkv.weight', 'visual_encoder_m.blocks.4.attn.qkv.bias', 'visual_encoder_m.blocks.4.attn.proj.weight', 'visual_encoder_m.blocks.4.attn.proj.bias', 'visual_encoder_m.blocks.4.norm2.weight', 'visual_encoder_m.blocks.4.norm2.bias', 'visual_encoder_m.blocks.4.mlp.fc1.weight', 'visual_encoder_m.blocks.4.mlp.fc1.bias', 'visual_encoder_m.blocks.4.mlp.fc2.weight', 'visual_encoder_m.blocks.4.mlp.fc2.bias', 'visual_encoder_m.blocks.5.norm1.weight', 'visual_encoder_m.blocks.5.norm1.bias', 'visual_encoder_m.blocks.5.attn.qkv.weight', 'visual_encoder_m.blocks.5.attn.qkv.bias', 'visual_encoder_m.blocks.5.attn.proj.weight', 'visual_encoder_m.blocks.5.attn.proj.bias', 'visual_encoder_m.blocks.5.norm2.weight', 'visual_encoder_m.blocks.5.norm2.bias', 'visual_encoder_m.blocks.5.mlp.fc1.weight', 'visual_encoder_m.blocks.5.mlp.fc1.bias', 'visual_encoder_m.blocks.5.mlp.fc2.weight', 'visual_encoder_m.blocks.5.mlp.fc2.bias', 'visual_encoder_m.blocks.6.norm1.weight', 'visual_encoder_m.blocks.6.norm1.bias', 'visual_encoder_m.blocks.6.attn.qkv.weight', 'visual_encoder_m.blocks.6.attn.qkv.bias', 'visual_encoder_m.blocks.6.attn.proj.weight', 'visual_encoder_m.blocks.6.attn.proj.bias', 'visual_encoder_m.blocks.6.norm2.weight', 'visual_encoder_m.blocks.6.norm2.bias', 'visual_encoder_m.blocks.6.mlp.fc1.weight', 'visual_encoder_m.blocks.6.mlp.fc1.bias', 'visual_encoder_m.blocks.6.mlp.fc2.weight', 'visual_encoder_m.blocks.6.mlp.fc2.bias', 'visual_encoder_m.blocks.7.norm1.weight', 'visual_encoder_m.blocks.7.norm1.bias', 'visual_encoder_m.blocks.7.attn.qkv.weight', 'visual_encoder_m.blocks.7.attn.qkv.bias', 'visual_encoder_m.blocks.7.attn.proj.weight', 'visual_encoder_m.blocks.7.attn.proj.bias', 'visual_encoder_m.blocks.7.norm2.weight', 'visual_encoder_m.blocks.7.norm2.bias', 'visual_encoder_m.blocks.7.mlp.fc1.weight', 'visual_encoder_m.blocks.7.mlp.fc1.bias', 'visual_encoder_m.blocks.7.mlp.fc2.weight', 'visual_encoder_m.blocks.7.mlp.fc2.bias', 'visual_encoder_m.blocks.8.norm1.weight', 'visual_encoder_m.blocks.8.norm1.bias', 'visual_encoder_m.blocks.8.attn.qkv.weight', 'visual_encoder_m.blocks.8.attn.qkv.bias', 'visual_encoder_m.blocks.8.attn.proj.weight', 'visual_encoder_m.blocks.8.attn.proj.bias', 'visual_encoder_m.blocks.8.norm2.weight', 'visual_encoder_m.blocks.8.norm2.bias', 'visual_encoder_m.blocks.8.mlp.fc1.weight', 'visual_encoder_m.blocks.8.mlp.fc1.bias', 'visual_encoder_m.blocks.8.mlp.fc2.weight', 'visual_encoder_m.blocks.8.mlp.fc2.bias', 'visual_encoder_m.blocks.9.norm1.weight', 'visual_encoder_m.blocks.9.norm1.bias', 'visual_encoder_m.blocks.9.attn.qkv.weight', 'visual_encoder_m.blocks.9.attn.qkv.bias', 'visual_encoder_m.blocks.9.attn.proj.weight', 'visual_encoder_m.blocks.9.attn.proj.bias', 'visual_encoder_m.blocks.9.norm2.weight', 'visual_encoder_m.blocks.9.norm2.bias', 'visual_encoder_m.blocks.9.mlp.fc1.weight', 'visual_encoder_m.blocks.9.mlp.fc1.bias', 'visual_encoder_m.blocks.9.mlp.fc2.weight', 'visual_encoder_m.blocks.9.mlp.fc2.bias', 'visual_encoder_m.blocks.10.norm1.weight', 'visual_encoder_m.blocks.10.norm1.bias', 'visual_encoder_m.blocks.10.attn.qkv.weight', 'visual_encoder_m.blocks.10.attn.qkv.bias', 'visual_encoder_m.blocks.10.attn.proj.weight', 'visual_encoder_m.blocks.10.attn.proj.bias', 'visual_encoder_m.blocks.10.norm2.weight', 'visual_encoder_m.blocks.10.norm2.bias', 'visual_encoder_m.blocks.10.mlp.fc1.weight', 'visual_encoder_m.blocks.10.mlp.fc1.bias', 'visual_encoder_m.blocks.10.mlp.fc2.weight', 'visual_encoder_m.blocks.10.mlp.fc2.bias', 'visual_encoder_m.blocks.11.norm1.weight', 'visual_encoder_m.blocks.11.norm1.bias', 'visual_encoder_m.blocks.11.attn.qkv.weight', 'visual_encoder_m.blocks.11.attn.qkv.bias', 'visual_encoder_m.blocks.11.attn.proj.weight', 'visual_encoder_m.blocks.11.attn.proj.bias', 'visual_encoder_m.blocks.11.norm2.weight', 'visual_encoder_m.blocks.11.norm2.bias', 'visual_encoder_m.blocks.11.mlp.fc1.weight', 'visual_encoder_m.blocks.11.mlp.fc1.bias', 'visual_encoder_m.blocks.11.mlp.fc2.weight', 'visual_encoder_m.blocks.11.mlp.fc2.bias', 'visual_encoder_m.norm.weight', 'visual_encoder_m.norm.bias', 'vision_proj_m.weight', 'vision_proj_m.bias', 'text_encoder_m.cls.predictions.bias', 'text_encoder_m.cls.predictions.transform.dense.weight', 'text_encoder_m.cls.predictions.transform.dense.bias', 'text_encoder_m.cls.predictions.transform.LayerNorm.weight', 'text_encoder_m.cls.predictions.transform.LayerNorm.bias', 'text_encoder_m.cls.predictions.decoder.weight', 'text_encoder_m.cls.predictions.decoder.bias', 'text_proj_m.weight', 'text_proj_m.bias', 'text_encoder_m.embeddings.position_ids', 'text_encoder_m.embeddings.word_embeddings.weight', 'text_encoder_m.embeddings.position_embeddings.weight', 'text_encoder_m.embeddings.token_type_embeddings.weight', 'text_encoder_m.embeddings.LayerNorm.weight', 'text_encoder_m.embeddings.LayerNorm.bias', 'text_encoder_m.encoder.layer.0.attention.self.query.weight', 'text_encoder_m.encoder.layer.0.attention.self.query.bias', 'text_encoder_m.encoder.layer.0.attention.self.key.weight', 'text_encoder_m.encoder.layer.0.attention.self.key.bias', 'text_encoder_m.encoder.layer.0.attention.self.value.weight', 'text_encoder_m.encoder.layer.0.attention.self.value.bias', 'text_encoder_m.encoder.layer.0.attention.output.dense.weight', 'text_encoder_m.encoder.layer.0.attention.output.dense.bias', 'text_encoder_m.encoder.layer.0.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.0.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.0.intermediate.dense.weight', 'text_encoder_m.encoder.layer.0.intermediate.dense.bias', 'text_encoder_m.encoder.layer.0.output.dense.weight', 'text_encoder_m.encoder.layer.0.output.dense.bias', 'text_encoder_m.encoder.layer.0.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.0.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.1.attention.self.query.weight', 'text_encoder_m.encoder.layer.1.attention.self.query.bias', 'text_encoder_m.encoder.layer.1.attention.self.key.weight', 'text_encoder_m.encoder.layer.1.attention.self.key.bias', 'text_encoder_m.encoder.layer.1.attention.self.value.weight', 'text_encoder_m.encoder.layer.1.attention.self.value.bias', 'text_encoder_m.encoder.layer.1.attention.output.dense.weight', 'text_encoder_m.encoder.layer.1.attention.output.dense.bias', 'text_encoder_m.encoder.layer.1.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.1.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.1.intermediate.dense.weight', 'text_encoder_m.encoder.layer.1.intermediate.dense.bias', 'text_encoder_m.encoder.layer.1.output.dense.weight', 'text_encoder_m.encoder.layer.1.output.dense.bias', 'text_encoder_m.encoder.layer.1.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.1.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.2.attention.self.query.weight', 'text_encoder_m.encoder.layer.2.attention.self.query.bias', 'text_encoder_m.encoder.layer.2.attention.self.key.weight', 'text_encoder_m.encoder.layer.2.attention.self.key.bias', 'text_encoder_m.encoder.layer.2.attention.self.value.weight', 'text_encoder_m.encoder.layer.2.attention.self.value.bias', 'text_encoder_m.encoder.layer.2.attention.output.dense.weight', 'text_encoder_m.encoder.layer.2.attention.output.dense.bias', 'text_encoder_m.encoder.layer.2.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.2.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.2.intermediate.dense.weight', 'text_encoder_m.encoder.layer.2.intermediate.dense.bias', 'text_encoder_m.encoder.layer.2.output.dense.weight', 'text_encoder_m.encoder.layer.2.output.dense.bias', 'text_encoder_m.encoder.layer.2.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.2.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.3.attention.self.query.weight', 'text_encoder_m.encoder.layer.3.attention.self.query.bias', 'text_encoder_m.encoder.layer.3.attention.self.key.weight', 'text_encoder_m.encoder.layer.3.attention.self.key.bias', 'text_encoder_m.encoder.layer.3.attention.self.value.weight', 'text_encoder_m.encoder.layer.3.attention.self.value.bias', 'text_encoder_m.encoder.layer.3.attention.output.dense.weight', 'text_encoder_m.encoder.layer.3.attention.output.dense.bias', 'text_encoder_m.encoder.layer.3.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.3.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.3.intermediate.dense.weight', 'text_encoder_m.encoder.layer.3.intermediate.dense.bias', 'text_encoder_m.encoder.layer.3.output.dense.weight', 'text_encoder_m.encoder.layer.3.output.dense.bias', 'text_encoder_m.encoder.layer.3.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.3.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.4.attention.self.query.weight', 'text_encoder_m.encoder.layer.4.attention.self.query.bias', 'text_encoder_m.encoder.layer.4.attention.self.key.weight', 'text_encoder_m.encoder.layer.4.attention.self.key.bias', 'text_encoder_m.encoder.layer.4.attention.self.value.weight', 'text_encoder_m.encoder.layer.4.attention.self.value.bias', 'text_encoder_m.encoder.layer.4.attention.output.dense.weight', 'text_encoder_m.encoder.layer.4.attention.output.dense.bias', 'text_encoder_m.encoder.layer.4.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.4.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.4.intermediate.dense.weight', 'text_encoder_m.encoder.layer.4.intermediate.dense.bias', 'text_encoder_m.encoder.layer.4.output.dense.weight', 'text_encoder_m.encoder.layer.4.output.dense.bias', 'text_encoder_m.encoder.layer.4.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.4.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.5.attention.self.query.weight', 'text_encoder_m.encoder.layer.5.attention.self.query.bias', 'text_encoder_m.encoder.layer.5.attention.self.key.weight', 'text_encoder_m.encoder.layer.5.attention.self.key.bias', 'text_encoder_m.encoder.layer.5.attention.self.value.weight', 'text_encoder_m.encoder.layer.5.attention.self.value.bias', 'text_encoder_m.encoder.layer.5.attention.output.dense.weight', 'text_encoder_m.encoder.layer.5.attention.output.dense.bias', 'text_encoder_m.encoder.layer.5.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.5.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.5.intermediate.dense.weight', 'text_encoder_m.encoder.layer.5.intermediate.dense.bias', 'text_encoder_m.encoder.layer.5.output.dense.weight', 'text_encoder_m.encoder.layer.5.output.dense.bias', 'text_encoder_m.encoder.layer.5.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.5.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.6.attention.self.query.weight', 'text_encoder_m.encoder.layer.6.attention.self.query.bias', 'text_encoder_m.encoder.layer.6.attention.self.key.weight', 'text_encoder_m.encoder.layer.6.attention.self.key.bias', 'text_encoder_m.encoder.layer.6.attention.self.value.weight', 'text_encoder_m.encoder.layer.6.attention.self.value.bias', 'text_encoder_m.encoder.layer.6.attention.output.dense.weight', 'text_encoder_m.encoder.layer.6.attention.output.dense.bias', 'text_encoder_m.encoder.layer.6.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.6.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.6.crossattention.self.query.weight', 'text_encoder_m.encoder.layer.6.crossattention.self.query.bias', 'text_encoder_m.encoder.layer.6.crossattention.self.key.weight', 'text_encoder_m.encoder.layer.6.crossattention.self.key.bias', 'text_encoder_m.encoder.layer.6.crossattention.self.value.weight', 'text_encoder_m.encoder.layer.6.crossattention.self.value.bias', 'text_encoder_m.encoder.layer.6.crossattention.output.dense.weight', 'text_encoder_m.encoder.layer.6.crossattention.output.dense.bias', 'text_encoder_m.encoder.layer.6.crossattention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.6.crossattention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.6.intermediate.dense.weight', 'text_encoder_m.encoder.layer.6.intermediate.dense.bias', 'text_encoder_m.encoder.layer.6.output.dense.weight', 'text_encoder_m.encoder.layer.6.output.dense.bias', 'text_encoder_m.encoder.layer.6.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.6.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.7.attention.self.query.weight', 'text_encoder_m.encoder.layer.7.attention.self.query.bias', 'text_encoder_m.encoder.layer.7.attention.self.key.weight', 'text_encoder_m.encoder.layer.7.attention.self.key.bias', 'text_encoder_m.encoder.layer.7.attention.self.value.weight', 'text_encoder_m.encoder.layer.7.attention.self.value.bias', 'text_encoder_m.encoder.layer.7.attention.output.dense.weight', 'text_encoder_m.encoder.layer.7.attention.output.dense.bias', 'text_encoder_m.encoder.layer.7.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.7.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.7.crossattention.self.query.weight', 'text_encoder_m.encoder.layer.7.crossattention.self.query.bias', 'text_encoder_m.encoder.layer.7.crossattention.self.key.weight', 'text_encoder_m.encoder.layer.7.crossattention.self.key.bias', 'text_encoder_m.encoder.layer.7.crossattention.self.value.weight', 'text_encoder_m.encoder.layer.7.crossattention.self.value.bias', 'text_encoder_m.encoder.layer.7.crossattention.output.dense.weight', 'text_encoder_m.encoder.layer.7.crossattention.output.dense.bias', 'text_encoder_m.encoder.layer.7.crossattention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.7.crossattention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.7.intermediate.dense.weight', 'text_encoder_m.encoder.layer.7.intermediate.dense.bias', 'text_encoder_m.encoder.layer.7.output.dense.weight', 'text_encoder_m.encoder.layer.7.output.dense.bias', 'text_encoder_m.encoder.layer.7.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.7.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.8.attention.self.query.weight', 'text_encoder_m.encoder.layer.8.attention.self.query.bias', 'text_encoder_m.encoder.layer.8.attention.self.key.weight', 'text_encoder_m.encoder.layer.8.attention.self.key.bias', 'text_encoder_m.encoder.layer.8.attention.self.value.weight', 'text_encoder_m.encoder.layer.8.attention.self.value.bias', 'text_encoder_m.encoder.layer.8.attention.output.dense.weight', 'text_encoder_m.encoder.layer.8.attention.output.dense.bias', 'text_encoder_m.encoder.layer.8.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.8.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.8.crossattention.self.query.weight', 'text_encoder_m.encoder.layer.8.crossattention.self.query.bias', 'text_encoder_m.encoder.layer.8.crossattention.self.key.weight', 'text_encoder_m.encoder.layer.8.crossattention.self.key.bias', 'text_encoder_m.encoder.layer.8.crossattention.self.value.weight', 'text_encoder_m.encoder.layer.8.crossattention.self.value.bias', 'text_encoder_m.encoder.layer.8.crossattention.output.dense.weight', 'text_encoder_m.encoder.layer.8.crossattention.output.dense.bias', 'text_encoder_m.encoder.layer.8.crossattention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.8.crossattention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.8.intermediate.dense.weight', 'text_encoder_m.encoder.layer.8.intermediate.dense.bias', 'text_encoder_m.encoder.layer.8.output.dense.weight', 'text_encoder_m.encoder.layer.8.output.dense.bias', 'text_encoder_m.encoder.layer.8.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.8.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.9.attention.self.query.weight', 'text_encoder_m.encoder.layer.9.attention.self.query.bias', 'text_encoder_m.encoder.layer.9.attention.self.key.weight', 'text_encoder_m.encoder.layer.9.attention.self.key.bias', 'text_encoder_m.encoder.layer.9.attention.self.value.weight', 'text_encoder_m.encoder.layer.9.attention.self.value.bias', 'text_encoder_m.encoder.layer.9.attention.output.dense.weight', 'text_encoder_m.encoder.layer.9.attention.output.dense.bias', 'text_encoder_m.encoder.layer.9.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.9.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.9.crossattention.self.query.weight', 'text_encoder_m.encoder.layer.9.crossattention.self.query.bias', 'text_encoder_m.encoder.layer.9.crossattention.self.key.weight', 'text_encoder_m.encoder.layer.9.crossattention.self.key.bias', 'text_encoder_m.encoder.layer.9.crossattention.self.value.weight', 'text_encoder_m.encoder.layer.9.crossattention.self.value.bias', 'text_encoder_m.encoder.layer.9.crossattention.output.dense.weight', 'text_encoder_m.encoder.layer.9.crossattention.output.dense.bias', 'text_encoder_m.encoder.layer.9.crossattention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.9.crossattention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.9.intermediate.dense.weight', 'text_encoder_m.encoder.layer.9.intermediate.dense.bias', 'text_encoder_m.encoder.layer.9.output.dense.weight', 'text_encoder_m.encoder.layer.9.output.dense.bias', 'text_encoder_m.encoder.layer.9.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.9.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.10.attention.self.query.weight', 'text_encoder_m.encoder.layer.10.attention.self.query.bias', 'text_encoder_m.encoder.layer.10.attention.self.key.weight', 'text_encoder_m.encoder.layer.10.attention.self.key.bias', 'text_encoder_m.encoder.layer.10.attention.self.value.weight', 'text_encoder_m.encoder.layer.10.attention.self.value.bias', 'text_encoder_m.encoder.layer.10.attention.output.dense.weight', 'text_encoder_m.encoder.layer.10.attention.output.dense.bias', 'text_encoder_m.encoder.layer.10.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.10.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.10.crossattention.self.query.weight', 'text_encoder_m.encoder.layer.10.crossattention.self.query.bias', 'text_encoder_m.encoder.layer.10.crossattention.self.key.weight', 'text_encoder_m.encoder.layer.10.crossattention.self.key.bias', 'text_encoder_m.encoder.layer.10.crossattention.self.value.weight', 'text_encoder_m.encoder.layer.10.crossattention.self.value.bias', 'text_encoder_m.encoder.layer.10.crossattention.output.dense.weight', 'text_encoder_m.encoder.layer.10.crossattention.output.dense.bias', 'text_encoder_m.encoder.layer.10.crossattention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.10.crossattention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.10.intermediate.dense.weight', 'text_encoder_m.encoder.layer.10.intermediate.dense.bias', 'text_encoder_m.encoder.layer.10.output.dense.weight', 'text_encoder_m.encoder.layer.10.output.dense.bias', 'text_encoder_m.encoder.layer.10.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.10.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.11.attention.self.query.weight', 'text_encoder_m.encoder.layer.11.attention.self.query.bias', 'text_encoder_m.encoder.layer.11.attention.self.key.weight', 'text_encoder_m.encoder.layer.11.attention.self.key.bias', 'text_encoder_m.encoder.layer.11.attention.self.value.weight', 'text_encoder_m.encoder.layer.11.attention.self.value.bias', 'text_encoder_m.encoder.layer.11.attention.output.dense.weight', 'text_encoder_m.encoder.layer.11.attention.output.dense.bias', 'text_encoder_m.encoder.layer.11.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.11.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.11.crossattention.self.query.weight', 'text_encoder_m.encoder.layer.11.crossattention.self.query.bias', 'text_encoder_m.encoder.layer.11.crossattention.self.key.weight', 'text_encoder_m.encoder.layer.11.crossattention.self.key.bias', 'text_encoder_m.encoder.layer.11.crossattention.self.value.weight', 'text_encoder_m.encoder.layer.11.crossattention.self.value.bias', 'text_encoder_m.encoder.layer.11.crossattention.output.dense.weight', 'text_encoder_m.encoder.layer.11.crossattention.output.dense.bias', 'text_encoder_m.encoder.layer.11.crossattention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.11.crossattention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.11.intermediate.dense.weight', 'text_encoder_m.encoder.layer.11.intermediate.dense.bias', 'text_encoder_m.encoder.layer.11.output.dense.weight', 'text_encoder_m.encoder.layer.11.output.dense.bias', 'text_encoder_m.encoder.layer.11.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.11.output.LayerNorm.bias', 'text_encoder.cls.predictions.bias', 'text_encoder.cls.predictions.transform.dense.weight', 'text_encoder.cls.predictions.transform.dense.bias', 'text_encoder.cls.predictions.transform.LayerNorm.weight', 'text_encoder.cls.predictions.transform.LayerNorm.bias', 'text_encoder.cls.predictions.decoder.weight', 'text_encoder.cls.predictions.decoder.bias'])
Start training
/nlp_group/wuxing/ALBEF/models/model_retrieval_title.py:160: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  title_label = torch.tensor(title_label, dtype=torch.long).to(image.device)
/nlp_group/wuxing/ALBEF/models/model_retrieval_title.py:160: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  title_label = torch.tensor(title_label, dtype=torch.long).to(image.device)
/nlp_group/wuxing/ALBEF/models/model_retrieval_title.py:160: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  title_label = torch.tensor(title_label, dtype=torch.long).to(image.device)
/nlp_group/wuxing/ALBEF/models/model_retrieval_title.py:160: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  title_label = torch.tensor(title_label, dtype=torch.long).to(image.device)
Train Epoch: [0]  [  0/109]  eta: 0:07:15  lr: 0.000001  loss_title: 3.1542  time: 3.9914  data: 0.1697  max mem: 16708
Train Epoch: [0]  [ 50/109]  eta: 0:01:37  lr: 0.000001  loss_title: 3.2465  time: 1.6067  data: 0.1494  max mem: 19052
Train Epoch: [0]  [100/109]  eta: 0:00:14  lr: 0.000001  loss_title: 2.9260  time: 1.6107  data: 0.1505  max mem: 19052
Train Epoch: [0]  [108/109]  eta: 0:00:01  lr: 0.000001  loss_title: 2.8377  time: 1.6114  data: 0.1498  max mem: 19052
Train Epoch: [0] Total time: 0:02:57 (1.6315 s / it)
Averaged stats: lr: 0.0000  loss_title: 3.0194
Val :   [ 0/25]  eta: 0:00:19    time: 0.7833  data: 0.3325  max mem: 19052
Val :   [24/25]  eta: 0:00:00    time: 0.4601  data: 0.3025  max mem: 19052
Val :  Total time: 0:00:11 (0.4757 s / it)
F1-score: 0.02378736436367035
Accuracy: 0.21954314410686493
Specificity: 0.9591708779335022
recall: 0.04596438258886337
Precision: 0.024679329246282578
Confusion Matrics: tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0, 136,   0,   0,   0,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   4,  16,   0,   0, 140,   0,   0,   0,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   8,   0,   0, 164,   0,   0,   0,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   8,   0,   0,  36,   0,   0,   0,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   8,   8,   0,  84,   0,   0,   4,   4],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,  16,   4,   0,  64,   0,   0,   0,   4],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   4,   0,   0,  48,   0,   0,   0,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   8,   0,   0,  24,   0,   0,   0,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,  12,   0,   0,   0,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   4,   0,   0,  80,   0,   0,   0,  12],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,  24,   0,   0,   0,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,  40,   0,   0,   0,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,  52,   4,   0,   0,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,
           0,   0,   4,   0,   0,  80,   0,   0,   0,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,  12,   4,   0,  60,   0,   0,   0,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,  12,   0,   0, 152,   0,   0,   0,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,
           0,   8,  24,   8,   0, 152,   0,   0,   0,   4],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,
           0,   0,  12,   0,   0,  44,   0,   0,   0,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   4,   0,   0,  20,   0,   0,   0,   4],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,  24,   0,   0, 648,   0,   0,   4,  16],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   4,   0,   0,  56,   0,   0,   0,   4],
        [  4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0, 128,   0,   0,   4,   4],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,
           0,   0,  16,   0,   0, 160,   0,   0,   0,  12],
        [  4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,  12,   0,   0, 392,   0,   0,   0,  20]], device='cuda:0')
Evaluation time 0:00:11
Train Epoch: [1]  [  0/109]  eta: 0:03:00  lr: 0.000010  loss_title: 2.9698  time: 1.6561  data: 0.1552  max mem: 19052
Train Epoch: [1]  [ 50/109]  eta: 0:01:34  lr: 0.000010  loss_title: 0.9682  time: 1.6090  data: 0.1479  max mem: 19067
Train Epoch: [1]  [100/109]  eta: 0:00:14  lr: 0.000010  loss_title: 0.7989  time: 1.6105  data: 0.1506  max mem: 19067
Train Epoch: [1]  [108/109]  eta: 0:00:01  lr: 0.000010  loss_title: 1.2206  time: 1.6080  data: 0.1502  max mem: 19067
Train Epoch: [1] Total time: 0:02:55 (1.6092 s / it)
Averaged stats: lr: 0.0000  loss_title: 1.6145
Val :   [ 0/25]  eta: 0:00:11    time: 0.4743  data: 0.3158  max mem: 19067
Val :   [24/25]  eta: 0:00:00    time: 0.4586  data: 0.3026  max mem: 19067
Val :  Total time: 0:00:11 (0.4616 s / it)
F1-score: 0.19695603847503662
Accuracy: 0.4289340078830719
Specificity: 0.9734680652618408
recall: 0.21033433079719543
Precision: 0.2504856288433075
Confusion Matrics: tensor([[ 92,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,
           0,   0,   0,   0,   0,  12,   0,   4,   0,  24],
        [ 20,  60,  24,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   4,  16,   0,   0,  24,   8,   0,   0,   4],
        [ 32,  12,  68,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   4,  24,   0,   0,  24,   0,   0,   0,   8],
        [  4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,  20,   0,   0,   8,   4,   0,   0,   8],
        [ 12,   0,   0,   0,  40,   0,   0,   0,   0,   4,   0,   0,   0,   0,
           0,   8,   4,   0,   0,   0,   4,  12,   0,  24],
        [  0,   0,   0,   0,  16,   0,   0,   0,   0,   8,   0,   0,   0,   0,
           0,   0,   8,   0,   0,   0,   4,  12,  20,  20],
        [  8,   0,   4,   0,   4,   0,   0,   0,   0,   4,   0,   0,   0,   0,
           0,   0,   8,   0,   0,  12,   8,   4,   0,   0],
        [  0,   0,   0,   0,   8,   0,   0,   0,   0,   8,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,  12,   4,   0],
        [  0,   0,   0,   0,   4,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   4,   0,   0,   0,   0,   0,   0,   4],
        [ 12,   0,   0,   0,   0,   0,   0,   0,   0,  20,   0,   0,   0,   0,
           0,   0,   4,   0,   0,   4,   4,  16,  24,  12],
        [  8,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   0,   8,   8],
        [  8,   0,   0,   0,   4,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   4,   0,   0,  12,   0,   4,   8,   0],
        [  4,   0,   0,   0,   0,   0,   0,   0,   0,  12,   0,   0,   0,   0,
           0,   0,   8,   0,   0,   0,   0,   0,  16,  16],
        [  4,   0,   0,   0,   4,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   4,   0,   0,  20,   0,  20,  12,  24],
        [ 20,   0,   0,   0,  12,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           4,   0,   4,   0,   0,   4,   4,  20,   4,   4],
        [  0,   0,   0,   0,   8,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,  44,  76,   0,   0,  16,   0,   0,   4,  16],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  16,   0,   0,   0,   0,
           0,   0, 124,   0,   0,  32,   8,   4,   8,   8],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  12,   0,   0,   0,   0,
           0,   0,   0,   0,   0,  20,   4,   8,   4,  12],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   8,   0,   0,  16,   4,   0,   0,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  12,   0,   0,   0,   0,
           0,   0,  56,   0,   0, 544,   8,  12,  28,  32],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   8,   0,   0,   0,   0,
           0,   0,  20,   0,   0,   0,   4,  12,  12,   8],
        [  4,   0,   4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   4,   0,   0,  28,   0,  40,  36,  24],
        [  4,   0,   0,   0,   0,   0,   0,   0,   0,  24,   0,   0,   0,   0,
           0,   0,   8,   0,   0,  32,   0,   8,  76,  40],
        [  0,   0,   0,   0,   4,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,  92,   4,  20,  72, 236]], device='cuda:0')
Evaluation time 0:00:11
Train Epoch: [2]  [  0/109]  eta: 0:03:01  lr: 0.000010  loss_title: 0.9632  time: 1.6673  data: 0.1529  max mem: 19067
Train Epoch: [2]  [ 50/109]  eta: 0:01:35  lr: 0.000010  loss_title: 0.9461  time: 1.6101  data: 0.1496  max mem: 19067
Train Epoch: [2]  [100/109]  eta: 0:00:14  lr: 0.000010  loss_title: 0.7189  time: 1.6111  data: 0.1534  max mem: 19067
Train Epoch: [2]  [108/109]  eta: 0:00:01  lr: 0.000010  loss_title: 0.5008  time: 1.6098  data: 0.1551  max mem: 19067
Train Epoch: [2] Total time: 0:02:55 (1.6116 s / it)
Averaged stats: lr: 0.0000  loss_title: 0.9171
Val :   [ 0/25]  eta: 0:00:11    time: 0.4737  data: 0.3131  max mem: 19067
Val :   [24/25]  eta: 0:00:00    time: 0.4676  data: 0.3092  max mem: 19067
Val :  Total time: 0:00:11 (0.4691 s / it)
F1-score: 0.2191954106092453
Accuracy: 0.4200507700443268
Specificity: 0.9737244844436646
recall: 0.23611554503440857
Precision: 0.25254693627357483
Confusion Matrics: tensor([[104,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,  16,   0,  12,   4],
        [ 32,  72,  24,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   4,   4,   0,   0,   8,  16,   0,   0,   0],
        [ 60,   8,  72,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   8,   0,   0,   0,  20,   4,   0,   0,   0],
        [ 12,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,
           0,   0,   8,   0,   0,   8,   4,   4,   0,   4],
        [ 12,   0,   0,   0,  44,   4,   0,   0,   0,   4,   0,   0,   0,   0,
           0,   4,   0,   0,   0,   0,  12,  20,   8,   0],
        [  0,   0,   0,   0,   0,   8,   0,   0,   0,   8,   0,   0,   4,   0,
           0,   0,   4,   0,   0,   0,  12,   0,  48,   4],
        [  8,   0,   0,   0,   4,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,  12,  20,   4,   4,   0],
        [  0,   0,   0,   0,   4,   8,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   4,  16,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   4,   8,   0],
        [  8,   0,   0,   0,   0,   0,   0,   0,   0,  24,   0,   0,   0,   0,
           0,   0,   4,   0,   0,   4,   4,   0,  44,   8],
        [  8,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   0,  12,   4],
        [  4,   0,   0,   0,   4,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   4,   0,   0,   8,   4,   0,  16,   0],
        [  4,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,
           0,   0,   4,   0,   0,   0,   8,   4,  24,   8],
        [  4,   0,   0,   0,   0,   4,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   4,   0,  16,  60,   0],
        [  8,   0,   0,   0,  16,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   4,  20,  20,   8],
        [  0,   0,   0,   0,  20,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,  60,  40,   0,   0,  16,  12,   8,   4,   4],
        [  0,   0,   0,   0,   4,   0,   0,   0,   0,   4,   0,   0,   0,   0,
           0,   0,  92,   0,   0,  44,  20,   0,  28,   8],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,
           0,   0,   0,   0,   0,  16,   8,   4,  28,   0],
        [  4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   8,   0,   0,   8,   4,   0,   0,   4],
        [  4,   0,   0,   0,   0,   0,   0,   0,   0,   8,   0,   0,   0,   0,
           0,   0,  32,   0,   0, 500,  20,   8,  76,  44],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   4,   0,   0,   0,  32,   4,  24,   0],
        [  4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   4,   0,   0,  24,   8,  32,  52,  16],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  16,   0,   0,   0,   0,
           0,   0,   8,   0,   0,  12,   4,  12, 120,  20],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,  36,  20,  36, 172, 164]], device='cuda:0')
Evaluation time 0:00:11
Train Epoch: [3]  [  0/109]  eta: 0:03:01  lr: 0.000010  loss_title: 0.8703  time: 1.6629  data: 0.1631  max mem: 19067
Train Epoch: [3]  [ 50/109]  eta: 0:01:34  lr: 0.000010  loss_title: 0.4727  time: 1.6089  data: 0.1493  max mem: 19067
Train Epoch: [3]  [100/109]  eta: 0:00:14  lr: 0.000010  loss_title: 0.6551  time: 1.6095  data: 0.1499  max mem: 19067
Train Epoch: [3]  [108/109]  eta: 0:00:01  lr: 0.000010  loss_title: 0.6203  time: 1.6080  data: 0.1498  max mem: 19067
Train Epoch: [3] Total time: 0:02:55 (1.6085 s / it)
Averaged stats: lr: 0.0000  loss_title: 0.6935
Val :   [ 0/25]  eta: 0:00:11    time: 0.4761  data: 0.3166  max mem: 19067
Val :   [24/25]  eta: 0:00:00    time: 0.4617  data: 0.3052  max mem: 19067
Val :  Total time: 0:00:11 (0.4655 s / it)
F1-score: 0.22283250093460083
Accuracy: 0.4428934156894684
Specificity: 0.9746595621109009
recall: 0.2468356490135193
Precision: 0.2565605342388153
Confusion Matrics: tensor([[100,   4,   4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   4,  16,   8,   0,   0],
        [  0,  76,  56,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   4,   0,   0,   8,  16,   0,   0,   0],
        [ 24,   0, 132,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   4,   0,   0,   0,  12,   0,   0,   0,   0],
        [  4,   8,   4,   4,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   8,   8,   4,   0,   0],
        [  8,   4,   0,   0,  40,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           4,   8,   0,   0,   0,   0,  24,  16,   0,   4],
        [  0,   0,   0,   0,  12,   4,   0,   0,   0,   4,   0,   0,   4,   0,
           0,   0,   0,   0,   0,   0,  28,   8,  16,  12],
        [  8,   4,  12,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   4,   0,   0,   4,  20,   0,   0,   0],
        [  0,   0,   0,   0,   0,  20,   0,   0,   0,   0,   0,   0,   4,   0,
           0,   0,   0,   0,   0,   0,   0,   8,   0,   0],
        [  0,   0,   4,   0,   4,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   4,   0,   0,   0],
        [  4,   0,   0,   0,   0,   4,   0,   0,   0,   8,   0,   0,   0,   0,
           0,   0,   4,   4,   0,   0,  32,   0,  28,  12],
        [  4,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   0,   8,   8],
        [  4,   0,   0,   0,   4,   0,   0,   0,   0,   0,   0,   0,   4,   0,
           0,   0,   4,   0,   0,   4,   8,   8,   0,   4],
        [  0,   0,   4,   4,   0,   4,   0,   0,   0,   0,   0,   0,   4,   0,
           0,   0,   4,   0,   0,   0,  20,   0,   8,   8],
        [  8,   0,   0,   0,   0,   4,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,  12,  16,  20,   4,  24],
        [ 16,   8,   0,   0,  16,   4,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,  16,  12,   0,   4],
        [  0,   0,   0,   0,  16,   0,   4,   0,   0,   0,   0,   0,   0,   0,
           0,  48,  32,   0,   0,  16,  28,  12,   4,   4],
        [  0,   4,   0,   0,   0,   0,   4,   0,   0,   0,   0,   0,   4,   0,
           0,   0,  72,   0,   0,  52,  44,   4,   4,  12],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,
           0,   0,   0,   0,   0,  20,  12,   8,   4,  12],
        [  8,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   4,   0,   0,  12,   4,   0,   0,   0],
        [  4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,  12,   0,   0, 564,  44,   8,  20,  40],
        [  4,   0,   0,   0,   0,   4,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,  52,   0,   4,   0],
        [  8,   0,   4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   4,   0,   0,  28,  28,  36,  16,  16],
        [  4,   0,   0,   0,   0,   0,   0,   0,   0,   8,   0,   0,   0,   0,
           0,   0,   4,   0,   0,  20,  36,  24,  52,  44],
        [  8,   4,   4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,
           0,   0,   0,   0,   0,  80,  56,  32,  36, 204]], device='cuda:0')
Evaluation time 0:00:11
Train Epoch: [4]  [  0/109]  eta: 0:03:01  lr: 0.000010  loss_title: 0.6801  time: 1.6617  data: 0.1595  max mem: 19067
Train Epoch: [4]  [ 50/109]  eta: 0:01:34  lr: 0.000010  loss_title: 0.9480  time: 1.6071  data: 0.1500  max mem: 19067
Train Epoch: [4]  [100/109]  eta: 0:00:14  lr: 0.000010  loss_title: 0.5918  time: 1.6059  data: 0.1527  max mem: 19067
Train Epoch: [4]  [108/109]  eta: 0:00:01  lr: 0.000010  loss_title: 0.3008  time: 1.6086  data: 0.1525  max mem: 19067
Train Epoch: [4] Total time: 0:02:55 (1.6089 s / it)
Averaged stats: lr: 0.0000  loss_title: 0.5489
Val :   [ 0/25]  eta: 0:00:11    time: 0.4755  data: 0.3162  max mem: 19067
Val :   [24/25]  eta: 0:00:00    time: 0.4595  data: 0.3030  max mem: 19067
Val :  Total time: 0:00:11 (0.4623 s / it)
F1-score: 0.2430693805217743
Accuracy: 0.4835025370121002
Specificity: 0.976132869720459
recall: 0.2691120505332947
Precision: 0.2494165003299713
Confusion Matrics: tensor([[100,   8,   4,   0,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,  12,   4,   0,   4],
        [  0, 112,  36,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   4,   4,   0,   0,   0,   4,   0,   0,   0],
        [ 20,   4, 136,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   4,   0,   0,   0,   8,   0,   0,   0,   0],
        [ 12,   4,   4,   0,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,
           0,   0,   0,   0,   0,  12,   8,   0,   0,   0],
        [  8,   4,   0,   0,  56,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,  12,   0,   0,   0,   0,  16,   0,   0,  12],
        [  4,   0,   0,   0,  16,   4,   0,   0,   0,   8,   0,   0,   4,   0,
           0,   0,   4,   0,   0,   0,  12,   0,  20,  16],
        [  8,   4,   8,   0,   4,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   4,   0,   0,   8,  16,   0,   0,   0],
        [  0,   0,   0,   0,  12,  16,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   4,   0,   0],
        [  0,   0,   4,   0,   4,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   0,   0,   4],
        [  4,   0,   0,   0,   0,  12,   0,   0,   0,  20,   0,   0,   0,   0,
           0,   0,   4,   0,   0,   4,  12,   0,  24,  16],
        [  4,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   0,   8,   8],
        [  4,   0,   0,   0,   4,   0,   0,   0,   0,   0,   0,   0,   4,   0,
           0,   0,   8,   0,   0,   4,   4,   4,   0,   8],
        [  4,   0,   0,   0,   0,   4,   0,   0,   0,   0,   0,   0,   4,   0,
           0,   0,   8,   0,   0,   0,  12,   0,  16,   8],
        [  8,   0,   0,   0,   4,   0,   0,   0,   0,   4,   0,   0,   0,   0,
           0,   4,   4,   0,   0,  20,   4,   8,   8,  24],
        [ 16,   0,   0,   0,  28,   4,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   4,  12,   0,   4,   8],
        [  0,   0,   0,   0,   4,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,  96,  36,   0,   0,   8,   8,   0,   4,   8],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,
           0,  12, 108,   0,   0,  44,  16,   0,   4,  12],
        [  4,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,
           0,   4,   0,   0,   0,  24,  12,   0,   4,   8],
        [  4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   8,   0,   0,  12,   4,   0,   0,   0],
        [  4,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,
           0,   0,  52,   0,   0, 540,  16,   0,  12,  64],
        [  4,   4,   0,   0,   0,   0,   0,   0,   0,  12,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,  36,   0,   8,   0],
        [  4,   0,   4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   8,   0,   0,  28,  16,  16,  16,  48],
        [  4,   0,   0,   0,   0,   0,   0,   0,   0,  12,   0,   0,   0,   0,
           0,   0,   4,   0,   0,  28,  36,   4,  40,  64],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,  24,   0,   0,  88,  24,   0,  36, 256]], device='cuda:0')
Evaluation time 0:00:11
Train Epoch: [5]  [  0/109]  eta: 0:03:12  lr: 0.000010  loss_title: 0.3077  time: 1.7700  data: 0.1598  max mem: 19067
Train Epoch: [5]  [ 50/109]  eta: 0:01:35  lr: 0.000010  loss_title: 0.4013  time: 1.6089  data: 0.1494  max mem: 19067
Train Epoch: [5]  [100/109]  eta: 0:00:14  lr: 0.000010  loss_title: 0.5519  time: 1.6097  data: 0.1492  max mem: 19067
Train Epoch: [5]  [108/109]  eta: 0:00:01  lr: 0.000010  loss_title: 0.6823  time: 1.6101  data: 0.1496  max mem: 19067
Train Epoch: [5] Total time: 0:02:55 (1.6100 s / it)
Averaged stats: lr: 0.0000  loss_title: 0.4875
Val :   [ 0/25]  eta: 0:00:11    time: 0.4734  data: 0.3125  max mem: 19067
Val :   [24/25]  eta: 0:00:00    time: 0.4583  data: 0.3021  max mem: 19067
Val :  Total time: 0:00:11 (0.4616 s / it)
F1-score: 0.24176231026649475
Accuracy: 0.44796955585479736
Specificity: 0.9752461910247803
recall: 0.2604100704193115
Precision: 0.3042578101158142
Confusion Matrics: tensor([[104,   4,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,  12,   8,   0,   4],
        [  0,  96,  44,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   4,   0,   0,   4,  12,   0,   0,   0],
        [ 28,   0, 128,   4,   0,   0,   4,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   8,   0,   0],
        [ 12,   4,   4,   4,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   4,   8,   4,   0,   0],
        [ 12,   4,   0,   0,  28,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,  20,  40,   0,   4],
        [  0,   0,   0,   0,   0,   8,   0,   0,   0,   8,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,  28,  16,  12,  16],
        [  8,   0,   8,   0,   0,   0,   4,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   4,  24,   4,   0,   0],
        [  0,   0,   0,   0,   0,  20,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,  12,   0,   0],
        [  0,   4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   4,   0,   4],
        [  4,   0,   0,   0,   0,  12,   0,   0,   0,  12,   0,   0,   0,   0,
           0,   0,   4,   0,   0,   0,  32,   0,  24,   8],
        [  4,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   0,   8,   8],
        [  4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,
           0,   0,   4,   0,   0,   4,   4,  12,   4,   4],
        [  4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   8,   0,
           0,   0,   0,   0,   0,   0,  20,   4,  16,   4],
        [  8,   0,   0,   0,   0,   4,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   4,   8,  28,  16,  20],
        [ 12,   0,   0,   0,   4,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,  24,  32,   0,   4],
        [  0,   4,   0,   0,  24,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,  32,  32,   0,   0,  12,  12,  32,   4,  12],
        [  0,   0,   0,   0,   4,   0,   8,   0,   0,   0,   0,   0,   0,   0,
           0,   0,  68,   0,   0,  32,  36,  28,   4,  20],
        [  4,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,
           0,   0,   0,   0,   0,  12,   8,  12,   8,  12],
        [ 12,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   4,   0,   0,   4,   4,   0,   0,   4],
        [  4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,  28,   0,   0, 468,  36,  32,  32,  92],
        [  4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,  44,   4,  12,   0],
        [  8,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   8,   0,   0,  12,  16,  64,   8,  20],
        [  4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   4,   0,   0,   4,  36,  48,  68,  28],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   8,   0,
           0,   0,   0,   0,   0,  24,  24,  52,  44, 276]], device='cuda:0')
Evaluation time 0:00:11
Train Epoch: [6]  [  0/109]  eta: 0:03:01  lr: 0.000010  loss_title: 0.7981  time: 1.6622  data: 0.1480  max mem: 19067
Train Epoch: [6]  [ 50/109]  eta: 0:01:34  lr: 0.000010  loss_title: 0.4361  time: 1.6066  data: 0.1487  max mem: 19067
Train Epoch: [6]  [100/109]  eta: 0:00:14  lr: 0.000010  loss_title: 0.9238  time: 1.6027  data: 0.1491  max mem: 19067
Train Epoch: [6]  [108/109]  eta: 0:00:01  lr: 0.000010  loss_title: 0.1805  time: 1.6077  data: 0.1492  max mem: 19067
Train Epoch: [6] Total time: 0:02:55 (1.6074 s / it)
Averaged stats: lr: 0.0000  loss_title: 0.3829
Val :   [ 0/25]  eta: 0:00:11    time: 0.4739  data: 0.3137  max mem: 19067
Val :   [24/25]  eta: 0:00:00    time: 0.4594  data: 0.3029  max mem: 19067
Val :  Total time: 0:00:11 (0.4619 s / it)
F1-score: 0.2574402987957001
Accuracy: 0.4809644818305969
Specificity: 0.9763697385787964
recall: 0.2811794877052307
Precision: 0.2699381113052368
Confusion Matrics: tensor([[112,   4,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,  12,   0,   4,   0],
        [  0,  84,  64,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   8,   0,   0,   0,   4,   0,   0,   0],
        [ 20,   0, 136,  12,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   0,   0,   4],
        [  8,   4,   4,   8,   0,   0,   0,   0,   0,   8,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   4,   4,   0,   4,   0],
        [ 12,   4,   0,   0,  48,   0,   0,   0,   0,   4,   0,   0,   0,   0,
           0,  12,   0,   0,   0,   0,  12,   4,   0,  12],
        [  4,   0,   0,   0,  12,  12,   0,   0,   0,  12,   0,   0,   8,   0,
           0,   0,   0,   0,   0,   0,  12,   4,  16,   8],
        [  8,   4,  12,   0,   0,   0,   4,   0,   0,   4,   0,   0,   0,   0,
           0,   0,   4,   0,   0,   4,  12,   0,   0,   0],
        [  0,   0,   0,   0,   0,  24,   0,   0,   0,   0,   0,   0,   4,   0,
           0,   0,   0,   0,   0,   0,   0,   4,   0,   0],
        [  0,   0,   4,   0,   4,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   0,   0,   4],
        [  8,   0,   0,   0,   0,   8,   0,   0,   0,  40,   0,   0,   0,   0,
           0,   0,   4,   0,   0,   0,   8,   0,  20,   8],
        [  4,   0,   0,   0,   0,   0,   0,   0,   0,   8,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   0,   8,   4],
        [  4,   0,   0,   0,   4,   0,   0,   0,   0,   0,   0,   0,   4,   0,
           0,   0,   4,   0,   0,   4,   8,   4,   4,   4],
        [  4,   0,   4,   0,   0,   0,   4,   0,   0,  16,   0,   0,   0,   0,
           0,   0,   4,   0,   0,   0,   4,   0,  16,   4],
        [  8,   0,   0,   0,   0,   4,   0,   0,   0,   4,   0,   0,   0,   0,
           0,   4,   4,   0,   0,  20,   4,   4,  28,   8],
        [ 16,   4,   0,   0,  16,   8,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   4,   0,   0,   0,  16,   0,   8,   4],
        [  0,   8,   0,   0,  12,   0,   4,   0,   0,   0,   0,   0,   0,   0,
           0,  68,  32,   0,   0,  12,   0,   4,   8,  16],
        [  8,   0,   0,   0,   4,   0,   0,   0,   0,   8,   0,   0,   0,   0,
           0,   4,  84,   0,   0,  52,  16,   0,  12,  12],
        [  8,   0,   0,   0,   0,   0,   0,   0,   0,   8,   0,   0,   0,   0,
           0,   0,   0,   0,   0,  12,   4,   8,   8,  12],
        [ 12,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   4,   0,   0,   8,   4,   0,   0,   0],
        [  8,   0,   4,   0,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,
           0,   0,  32,   0,   0, 536,  20,   0,  28,  60],
        [  4,   0,   0,   0,   0,   0,   0,   0,   0,  12,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,  36,   0,  12,   0],
        [ 12,   0,   0,   0,   0,   0,   4,   0,   0,   4,   0,   0,   0,   0,
           0,   0,   8,   0,   0,  20,   8,  24,  28,  32],
        [  4,   4,   0,   0,   0,   0,   0,   0,   0,   8,   0,   0,   0,   0,
           0,   0,   0,   0,   0,  16,  36,   8,  88,  28],
        [  4,   0,   4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   8,   0,
           0,   0,   0,   0,   0,  72,  28,  16,  60, 236]], device='cuda:0')
Evaluation time 0:00:11
Train Epoch: [7]  [  0/109]  eta: 0:03:01  lr: 0.000009  loss_title: 0.1874  time: 1.6607  data: 0.1543  max mem: 19067
Train Epoch: [7]  [ 50/109]  eta: 0:01:34  lr: 0.000009  loss_title: 0.3794  time: 1.6057  data: 0.1484  max mem: 19067
Train Epoch: [7]  [100/109]  eta: 0:00:14  lr: 0.000009  loss_title: 0.1911  time: 1.6068  data: 0.1488  max mem: 19067
Train Epoch: [7]  [108/109]  eta: 0:00:01  lr: 0.000009  loss_title: 0.1745  time: 1.6085  data: 0.1476  max mem: 19067
Train Epoch: [7] Total time: 0:02:55 (1.6080 s / it)
Averaged stats: lr: 0.0000  loss_title: 0.3323
Val :   [ 0/25]  eta: 0:00:11    time: 0.4736  data: 0.3131  max mem: 19067
Val :   [24/25]  eta: 0:00:00    time: 0.4593  data: 0.3030  max mem: 19067
Val :  Total time: 0:00:11 (0.4619 s / it)
F1-score: 0.263630747795105
Accuracy: 0.43908628821372986
Specificity: 0.974820613861084
recall: 0.28588157892227173
Precision: 0.3349118232727051
Confusion Matrics: tensor([[104,   4,   0,   0,   0,   4,   0,   0,   0,   4,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,  12,   0,   8,   0],
        [  4,  44,  88,   0,   0,   0,   4,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   8,   0,   0,   4,   8,   0,   0,   0],
        [ 20,   0, 136,   8,   0,   0,   4,   0,   0,   4,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
        [ 12,   4,   0,   8,   0,   4,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   4,   0,   0,   0,   8,   0,   4,   0],
        [  8,   0,   0,   0,  56,  16,   0,   0,   0,   4,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   8,   8,   4,   4],
        [  0,   0,   0,   0,   0,  44,   0,   0,   0,   4,   0,   0,   8,   0,
           0,   0,   0,   0,   0,   0,   0,   0,  20,  12],
        [  0,   0,   4,   0,   0,   8,  20,   0,   0,   8,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   4,   8,   0,   0,   0],
        [  0,   0,   0,   0,   0,  24,   0,   0,   0,   0,   0,   0,   4,   0,
           0,   0,   0,   0,   0,   0,   0,   4,   0,   0],
        [  0,   0,   0,   0,   0,   4,   4,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   0,   4,   0],
        [  8,   0,   0,   0,   0,  24,   0,   0,   0,  16,   0,   0,   0,   0,
           0,   0,   4,   0,   0,   0,  12,   0,  28,   4],
        [  4,   0,   0,   0,   0,   4,   0,   0,   0,   4,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   0,   8,   4],
        [  4,   0,   0,   0,   4,   0,   0,   0,   0,   0,   0,   0,   4,   0,
           0,   0,   4,   0,   0,   0,   4,   0,  16,   4],
        [  4,   0,   0,   0,   0,  16,   0,   0,   0,   4,   0,   0,   4,   0,
           0,   0,   4,   0,   0,   0,   0,   0,  20,   4],
        [  8,   0,   0,   0,   0,   8,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   4,   0,  12,  48,   8],
        [ 12,   0,   0,   0,  12,  16,   0,   0,   0,   0,   0,   0,   0,   0,
           4,   0,   0,   0,   0,   0,   8,   4,  12,   8],
        [  0,   0,   0,   0,  28,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,  56,  32,   0,   0,   8,  12,  12,   8,   8],
        [ 12,   0,   0,   0,   8,   0,   4,   0,   0,   4,   0,   0,   4,   0,
           0,   4,  64,   0,   0,  28,  20,   4,  32,  16],
        [  0,   0,   0,   0,   0,   4,   0,   0,   0,   8,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   8,   0,   4,  16,  20],
        [ 12,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   4,   0,   0,   4,   4,   0,   0,   4],
        [  4,   0,   0,   0,   0,   0,   0,   0,   0,  12,   0,   0,   0,   0,
           0,   0,  48,   0,   0, 404,  24,   4,  88, 108],
        [  0,   0,   0,   0,   0,   4,   4,   0,   0,   4,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,  36,   0,  16,   0],
        [  4,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   8,   0,   0,  16,  16,  20,  40,  32],
        [  0,   4,   0,   0,   0,   4,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,  28,   4, 120,  32],
        [  0,   0,   0,   0,   0,   8,   0,   0,   0,   0,   0,   0,  12,   0,
           0,   0,   0,   0,   0,  24,  16,  12, 108, 248]], device='cuda:0')
Evaluation time 0:00:11
Train Epoch: [8]  [  0/109]  eta: 0:02:59  lr: 0.000009  loss_title: 0.5086  time: 1.6481  data: 0.1506  max mem: 19067
Train Epoch: [8]  [ 50/109]  eta: 0:01:34  lr: 0.000009  loss_title: 0.1704  time: 1.6045  data: 0.1479  max mem: 19067
Train Epoch: [8]  [100/109]  eta: 0:00:14  lr: 0.000009  loss_title: 0.9414  time: 1.6086  data: 0.1481  max mem: 19067
Train Epoch: [8]  [108/109]  eta: 0:00:01  lr: 0.000009  loss_title: 0.1451  time: 1.6108  data: 0.1486  max mem: 19067
Train Epoch: [8] Total time: 0:02:55 (1.6086 s / it)
Averaged stats: lr: 0.0000  loss_title: 0.2691
Val :   [ 0/25]  eta: 0:00:11    time: 0.4731  data: 0.3144  max mem: 19067
Val :   [24/25]  eta: 0:00:00    time: 0.4595  data: 0.3029  max mem: 19067
Val :  Total time: 0:00:11 (0.4623 s / it)
F1-score: 0.2570444345474243
Accuracy: 0.4746192991733551
Specificity: 0.9757580161094666
recall: 0.2715933322906494
Precision: 0.2837534546852112
Confusion Matrics: tensor([[108,   4,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   8,   4,   8,   0],
        [  4,  76,  60,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   8,   0,   0,   4,   8,   0,   0,   0],
        [ 16,   0, 132,  12,   0,   0,   4,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   8,   0,   0,   0,   0],
        [  4,   4,   4,  12,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   4,   8,   0,   4,   0],
        [ 20,   4,   0,   0,  36,   0,   0,   0,   0,   4,   0,   0,   0,   0,
           4,   8,   0,   0,   0,   0,  12,  12,   0,   8],
        [  8,   0,   0,   0,   4,   8,   0,   0,   0,   8,   0,   0,   8,   0,
           0,   0,   0,   0,   0,   0,   4,   8,  20,  20],
        [  8,   0,   8,   0,   0,   0,  12,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,  12,  12,   0,   0,   0],
        [  0,   0,   0,   0,   0,  24,   0,   0,   0,   0,   0,   0,   4,   0,
           0,   0,   0,   0,   0,   0,   0,   4,   0,   0],
        [  0,   0,   0,   0,   4,   0,   4,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   0,   4,   0],
        [  4,   0,   0,   0,   0,   4,   0,   0,   0,  12,   0,   0,   0,   0,
           0,   0,   4,   0,   0,   4,  16,   0,  36,  16],
        [  4,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   0,  12,   4],
        [  8,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,
           0,   0,   4,   0,   0,   4,   4,   8,   0,   8],
        [  4,   0,   4,   0,   0,   4,   4,   0,   0,   0,   0,   0,   4,   4,
           0,   0,   4,   0,   0,   0,   8,   0,  12,   8],
        [  8,   0,   0,   0,   0,   0,   8,   0,   0,   0,   0,   0,   0,   0,
           0,   4,   0,   0,   0,  32,   4,   4,  16,  12],
        [  8,   0,   0,   0,   8,   0,   0,   0,   0,   0,   0,   0,   0,   4,
           0,   0,   0,   0,   0,   4,  12,  16,  16,   8],
        [  0,   8,   0,   0,   8,   0,   8,   0,   0,   0,   0,   0,   0,   0,
           0,  52,  40,   0,   0,  16,   0,   8,   8,  16],
        [ 12,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,
           0,   0,  72,   0,   0,  76,  12,   0,  12,  12],
        [  8,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,  20,   0,   8,   8,  12],
        [  8,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   4,   0,   0,  12,   4,   0,   0,   0],
        [  8,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,
           0,   0,   4,   0,   0, 576,  20,   8,  24,  48],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,  40,   4,  16,   0],
        [  4,   0,   4,   0,   0,   0,   4,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   8,   0,   0,  20,  12,  36,  20,  32],
        [  4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   4,   0,   0,   0,  16,  28,  36,  76,  28],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   8,   0,
           0,   0,   0,   0,   0,  92,  12,  12,  60, 244]], device='cuda:0')
Evaluation time 0:00:11
Train Epoch: [9]  [  0/109]  eta: 0:02:59  lr: 0.000009  loss_title: 0.0715  time: 1.6485  data: 0.1497  max mem: 19067
Train Epoch: [9]  [ 50/109]  eta: 0:01:34  lr: 0.000009  loss_title: 0.1870  time: 1.6058  data: 0.1507  max mem: 19067
Train Epoch: [9]  [100/109]  eta: 0:00:14  lr: 0.000009  loss_title: 0.1988  time: 1.6135  data: 0.1486  max mem: 19067
Train Epoch: [9]  [108/109]  eta: 0:00:01  lr: 0.000009  loss_title: 0.1409  time: 1.6033  data: 0.1501  max mem: 19067
Train Epoch: [9] Total time: 0:02:55 (1.6089 s / it)
Averaged stats: lr: 0.0000  loss_title: 0.2408
Val :   [ 0/25]  eta: 0:00:12    time: 0.4929  data: 0.3305  max mem: 19067
Val :   [24/25]  eta: 0:00:00    time: 0.4607  data: 0.3040  max mem: 19067
Val :  Total time: 0:00:11 (0.4652 s / it)
F1-score: 0.25491830706596375
Accuracy: 0.4581218361854553
Specificity: 0.9753503799438477
recall: 0.2700047791004181
Precision: 0.34018224477767944
Confusion Matrics: tensor([[104,   4,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,  12,   0,   8,   4],
        [  0,  88,  52,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   8,   0,   0,   4,   8,   0,   0,   0],
        [ 24,   4, 132,   4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   4,   0,   0,   0,   4],
        [  4,   8,   4,   8,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,
           0,   0,   4,   0,   0,   0,   8,   0,   4,   0],
        [ 16,   8,   0,   0,  32,   0,   0,   0,   0,   4,   0,   0,   0,   0,
           0,   8,   4,   0,   0,   0,  16,  12,   0,   8],
        [  4,   0,   0,   0,   8,  16,   0,   0,   0,   4,   0,   0,   8,   0,
           0,   0,   0,   0,   0,   0,   8,   8,  16,  16],
        [  8,   0,   8,   0,   0,   0,   8,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   4,   0,   0,   8,   8,   0,   4,   4],
        [  0,   0,   0,   0,   4,  16,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   4,   8,   0],
        [  0,   4,   0,   0,   4,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   0,   4,   0],
        [  4,   0,   0,   0,   0,   8,   0,   0,   0,  12,   0,   0,   0,   0,
           0,   0,   4,   0,   0,   0,  20,   0,  36,  12],
        [  4,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   0,  12,   4],
        [  8,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,
           0,   0,   4,   0,   0,   4,   8,   0,  12,   0],
        [  0,   0,   0,   0,   4,   4,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   8,   0,   0,   0,  16,   0,  16,   8],
        [  8,   0,   0,   0,   0,   4,   0,   0,   0,   8,   0,   0,   0,   0,
           0,   4,   0,   0,   0,   8,   0,   8,  32,  16],
        [  8,   0,   0,   0,   4,   4,   0,   0,   0,   0,   0,   0,   0,   0,
           4,   0,   0,   0,   0,   4,  12,  16,  16,   8],
        [  0,   8,   0,   0,  12,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,  40,  56,   0,   0,  12,   0,  12,   8,  16],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,
           0,   0,  96,   0,   0,  44,  16,   0,  24,  16],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,  12,   8,   4,  24,  12],
        [  8,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   4,   0,   0,  12,   4,   0,   0,   0],
        [  4,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,
           0,   0,  40,   0,   0, 472,  28,   8,  60,  76],
        [  4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,  44,   0,  16,   0],
        [  4,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   8,   0,   0,  20,  12,  32,  24,  36],
        [  4,   4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,  12,  24,  28,  88,  32],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,
           0,   0,   4,   0,   0,  44,  24,  12,  72, 268]], device='cuda:0')
Evaluation time 0:00:11
Train Epoch: [10]  [  0/109]  eta: 0:02:53  lr: 0.000009  loss_title: 0.1025  time: 1.5943  data: 0.1478  max mem: 19067
