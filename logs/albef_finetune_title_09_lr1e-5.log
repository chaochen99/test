/opt/conda/envs/albef-ab/lib/python3.8/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 0): env://
| distributed init (rank 1): env://
| distributed init (rank 3): env://
| distributed init (rank 2): env://
Creating retrieval dataset
Creating model
load checkpoint from /nlp_group/wuxing/yuhuimu/AB-layoutlmv3/output/albef/pretrain/checkpoint_09.pth
_IncompatibleKeys(missing_keys=['title_head.weight', 'title_head.bias'], unexpected_keys=['image_queue', 'text_queue', 'queue_ptr', 'vision_proj.weight', 'vision_proj.bias', 'text_proj.weight', 'text_proj.bias', 'itm_head.weight', 'itm_head.bias', 'visual_encoder_m.cls_token', 'visual_encoder_m.pos_embed', 'visual_encoder_m.patch_embed.proj.weight', 'visual_encoder_m.patch_embed.proj.bias', 'visual_encoder_m.blocks.0.norm1.weight', 'visual_encoder_m.blocks.0.norm1.bias', 'visual_encoder_m.blocks.0.attn.qkv.weight', 'visual_encoder_m.blocks.0.attn.qkv.bias', 'visual_encoder_m.blocks.0.attn.proj.weight', 'visual_encoder_m.blocks.0.attn.proj.bias', 'visual_encoder_m.blocks.0.norm2.weight', 'visual_encoder_m.blocks.0.norm2.bias', 'visual_encoder_m.blocks.0.mlp.fc1.weight', 'visual_encoder_m.blocks.0.mlp.fc1.bias', 'visual_encoder_m.blocks.0.mlp.fc2.weight', 'visual_encoder_m.blocks.0.mlp.fc2.bias', 'visual_encoder_m.blocks.1.norm1.weight', 'visual_encoder_m.blocks.1.norm1.bias', 'visual_encoder_m.blocks.1.attn.qkv.weight', 'visual_encoder_m.blocks.1.attn.qkv.bias', 'visual_encoder_m.blocks.1.attn.proj.weight', 'visual_encoder_m.blocks.1.attn.proj.bias', 'visual_encoder_m.blocks.1.norm2.weight', 'visual_encoder_m.blocks.1.norm2.bias', 'visual_encoder_m.blocks.1.mlp.fc1.weight', 'visual_encoder_m.blocks.1.mlp.fc1.bias', 'visual_encoder_m.blocks.1.mlp.fc2.weight', 'visual_encoder_m.blocks.1.mlp.fc2.bias', 'visual_encoder_m.blocks.2.norm1.weight', 'visual_encoder_m.blocks.2.norm1.bias', 'visual_encoder_m.blocks.2.attn.qkv.weight', 'visual_encoder_m.blocks.2.attn.qkv.bias', 'visual_encoder_m.blocks.2.attn.proj.weight', 'visual_encoder_m.blocks.2.attn.proj.bias', 'visual_encoder_m.blocks.2.norm2.weight', 'visual_encoder_m.blocks.2.norm2.bias', 'visual_encoder_m.blocks.2.mlp.fc1.weight', 'visual_encoder_m.blocks.2.mlp.fc1.bias', 'visual_encoder_m.blocks.2.mlp.fc2.weight', 'visual_encoder_m.blocks.2.mlp.fc2.bias', 'visual_encoder_m.blocks.3.norm1.weight', 'visual_encoder_m.blocks.3.norm1.bias', 'visual_encoder_m.blocks.3.attn.qkv.weight', 'visual_encoder_m.blocks.3.attn.qkv.bias', 'visual_encoder_m.blocks.3.attn.proj.weight', 'visual_encoder_m.blocks.3.attn.proj.bias', 'visual_encoder_m.blocks.3.norm2.weight', 'visual_encoder_m.blocks.3.norm2.bias', 'visual_encoder_m.blocks.3.mlp.fc1.weight', 'visual_encoder_m.blocks.3.mlp.fc1.bias', 'visual_encoder_m.blocks.3.mlp.fc2.weight', 'visual_encoder_m.blocks.3.mlp.fc2.bias', 'visual_encoder_m.blocks.4.norm1.weight', 'visual_encoder_m.blocks.4.norm1.bias', 'visual_encoder_m.blocks.4.attn.qkv.weight', 'visual_encoder_m.blocks.4.attn.qkv.bias', 'visual_encoder_m.blocks.4.attn.proj.weight', 'visual_encoder_m.blocks.4.attn.proj.bias', 'visual_encoder_m.blocks.4.norm2.weight', 'visual_encoder_m.blocks.4.norm2.bias', 'visual_encoder_m.blocks.4.mlp.fc1.weight', 'visual_encoder_m.blocks.4.mlp.fc1.bias', 'visual_encoder_m.blocks.4.mlp.fc2.weight', 'visual_encoder_m.blocks.4.mlp.fc2.bias', 'visual_encoder_m.blocks.5.norm1.weight', 'visual_encoder_m.blocks.5.norm1.bias', 'visual_encoder_m.blocks.5.attn.qkv.weight', 'visual_encoder_m.blocks.5.attn.qkv.bias', 'visual_encoder_m.blocks.5.attn.proj.weight', 'visual_encoder_m.blocks.5.attn.proj.bias', 'visual_encoder_m.blocks.5.norm2.weight', 'visual_encoder_m.blocks.5.norm2.bias', 'visual_encoder_m.blocks.5.mlp.fc1.weight', 'visual_encoder_m.blocks.5.mlp.fc1.bias', 'visual_encoder_m.blocks.5.mlp.fc2.weight', 'visual_encoder_m.blocks.5.mlp.fc2.bias', 'visual_encoder_m.blocks.6.norm1.weight', 'visual_encoder_m.blocks.6.norm1.bias', 'visual_encoder_m.blocks.6.attn.qkv.weight', 'visual_encoder_m.blocks.6.attn.qkv.bias', 'visual_encoder_m.blocks.6.attn.proj.weight', 'visual_encoder_m.blocks.6.attn.proj.bias', 'visual_encoder_m.blocks.6.norm2.weight', 'visual_encoder_m.blocks.6.norm2.bias', 'visual_encoder_m.blocks.6.mlp.fc1.weight', 'visual_encoder_m.blocks.6.mlp.fc1.bias', 'visual_encoder_m.blocks.6.mlp.fc2.weight', 'visual_encoder_m.blocks.6.mlp.fc2.bias', 'visual_encoder_m.blocks.7.norm1.weight', 'visual_encoder_m.blocks.7.norm1.bias', 'visual_encoder_m.blocks.7.attn.qkv.weight', 'visual_encoder_m.blocks.7.attn.qkv.bias', 'visual_encoder_m.blocks.7.attn.proj.weight', 'visual_encoder_m.blocks.7.attn.proj.bias', 'visual_encoder_m.blocks.7.norm2.weight', 'visual_encoder_m.blocks.7.norm2.bias', 'visual_encoder_m.blocks.7.mlp.fc1.weight', 'visual_encoder_m.blocks.7.mlp.fc1.bias', 'visual_encoder_m.blocks.7.mlp.fc2.weight', 'visual_encoder_m.blocks.7.mlp.fc2.bias', 'visual_encoder_m.blocks.8.norm1.weight', 'visual_encoder_m.blocks.8.norm1.bias', 'visual_encoder_m.blocks.8.attn.qkv.weight', 'visual_encoder_m.blocks.8.attn.qkv.bias', 'visual_encoder_m.blocks.8.attn.proj.weight', 'visual_encoder_m.blocks.8.attn.proj.bias', 'visual_encoder_m.blocks.8.norm2.weight', 'visual_encoder_m.blocks.8.norm2.bias', 'visual_encoder_m.blocks.8.mlp.fc1.weight', 'visual_encoder_m.blocks.8.mlp.fc1.bias', 'visual_encoder_m.blocks.8.mlp.fc2.weight', 'visual_encoder_m.blocks.8.mlp.fc2.bias', 'visual_encoder_m.blocks.9.norm1.weight', 'visual_encoder_m.blocks.9.norm1.bias', 'visual_encoder_m.blocks.9.attn.qkv.weight', 'visual_encoder_m.blocks.9.attn.qkv.bias', 'visual_encoder_m.blocks.9.attn.proj.weight', 'visual_encoder_m.blocks.9.attn.proj.bias', 'visual_encoder_m.blocks.9.norm2.weight', 'visual_encoder_m.blocks.9.norm2.bias', 'visual_encoder_m.blocks.9.mlp.fc1.weight', 'visual_encoder_m.blocks.9.mlp.fc1.bias', 'visual_encoder_m.blocks.9.mlp.fc2.weight', 'visual_encoder_m.blocks.9.mlp.fc2.bias', 'visual_encoder_m.blocks.10.norm1.weight', 'visual_encoder_m.blocks.10.norm1.bias', 'visual_encoder_m.blocks.10.attn.qkv.weight', 'visual_encoder_m.blocks.10.attn.qkv.bias', 'visual_encoder_m.blocks.10.attn.proj.weight', 'visual_encoder_m.blocks.10.attn.proj.bias', 'visual_encoder_m.blocks.10.norm2.weight', 'visual_encoder_m.blocks.10.norm2.bias', 'visual_encoder_m.blocks.10.mlp.fc1.weight', 'visual_encoder_m.blocks.10.mlp.fc1.bias', 'visual_encoder_m.blocks.10.mlp.fc2.weight', 'visual_encoder_m.blocks.10.mlp.fc2.bias', 'visual_encoder_m.blocks.11.norm1.weight', 'visual_encoder_m.blocks.11.norm1.bias', 'visual_encoder_m.blocks.11.attn.qkv.weight', 'visual_encoder_m.blocks.11.attn.qkv.bias', 'visual_encoder_m.blocks.11.attn.proj.weight', 'visual_encoder_m.blocks.11.attn.proj.bias', 'visual_encoder_m.blocks.11.norm2.weight', 'visual_encoder_m.blocks.11.norm2.bias', 'visual_encoder_m.blocks.11.mlp.fc1.weight', 'visual_encoder_m.blocks.11.mlp.fc1.bias', 'visual_encoder_m.blocks.11.mlp.fc2.weight', 'visual_encoder_m.blocks.11.mlp.fc2.bias', 'visual_encoder_m.norm.weight', 'visual_encoder_m.norm.bias', 'vision_proj_m.weight', 'vision_proj_m.bias', 'text_encoder_m.cls.predictions.bias', 'text_encoder_m.cls.predictions.transform.dense.weight', 'text_encoder_m.cls.predictions.transform.dense.bias', 'text_encoder_m.cls.predictions.transform.LayerNorm.weight', 'text_encoder_m.cls.predictions.transform.LayerNorm.bias', 'text_encoder_m.cls.predictions.decoder.weight', 'text_encoder_m.cls.predictions.decoder.bias', 'text_proj_m.weight', 'text_proj_m.bias', 'text_encoder_m.embeddings.position_ids', 'text_encoder_m.embeddings.word_embeddings.weight', 'text_encoder_m.embeddings.position_embeddings.weight', 'text_encoder_m.embeddings.token_type_embeddings.weight', 'text_encoder_m.embeddings.LayerNorm.weight', 'text_encoder_m.embeddings.LayerNorm.bias', 'text_encoder_m.encoder.layer.0.attention.self.query.weight', 'text_encoder_m.encoder.layer.0.attention.self.query.bias', 'text_encoder_m.encoder.layer.0.attention.self.key.weight', 'text_encoder_m.encoder.layer.0.attention.self.key.bias', 'text_encoder_m.encoder.layer.0.attention.self.value.weight', 'text_encoder_m.encoder.layer.0.attention.self.value.bias', 'text_encoder_m.encoder.layer.0.attention.output.dense.weight', 'text_encoder_m.encoder.layer.0.attention.output.dense.bias', 'text_encoder_m.encoder.layer.0.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.0.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.0.intermediate.dense.weight', 'text_encoder_m.encoder.layer.0.intermediate.dense.bias', 'text_encoder_m.encoder.layer.0.output.dense.weight', 'text_encoder_m.encoder.layer.0.output.dense.bias', 'text_encoder_m.encoder.layer.0.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.0.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.1.attention.self.query.weight', 'text_encoder_m.encoder.layer.1.attention.self.query.bias', 'text_encoder_m.encoder.layer.1.attention.self.key.weight', 'text_encoder_m.encoder.layer.1.attention.self.key.bias', 'text_encoder_m.encoder.layer.1.attention.self.value.weight', 'text_encoder_m.encoder.layer.1.attention.self.value.bias', 'text_encoder_m.encoder.layer.1.attention.output.dense.weight', 'text_encoder_m.encoder.layer.1.attention.output.dense.bias', 'text_encoder_m.encoder.layer.1.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.1.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.1.intermediate.dense.weight', 'text_encoder_m.encoder.layer.1.intermediate.dense.bias', 'text_encoder_m.encoder.layer.1.output.dense.weight', 'text_encoder_m.encoder.layer.1.output.dense.bias', 'text_encoder_m.encoder.layer.1.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.1.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.2.attention.self.query.weight', 'text_encoder_m.encoder.layer.2.attention.self.query.bias', 'text_encoder_m.encoder.layer.2.attention.self.key.weight', 'text_encoder_m.encoder.layer.2.attention.self.key.bias', 'text_encoder_m.encoder.layer.2.attention.self.value.weight', 'text_encoder_m.encoder.layer.2.attention.self.value.bias', 'text_encoder_m.encoder.layer.2.attention.output.dense.weight', 'text_encoder_m.encoder.layer.2.attention.output.dense.bias', 'text_encoder_m.encoder.layer.2.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.2.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.2.intermediate.dense.weight', 'text_encoder_m.encoder.layer.2.intermediate.dense.bias', 'text_encoder_m.encoder.layer.2.output.dense.weight', 'text_encoder_m.encoder.layer.2.output.dense.bias', 'text_encoder_m.encoder.layer.2.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.2.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.3.attention.self.query.weight', 'text_encoder_m.encoder.layer.3.attention.self.query.bias', 'text_encoder_m.encoder.layer.3.attention.self.key.weight', 'text_encoder_m.encoder.layer.3.attention.self.key.bias', 'text_encoder_m.encoder.layer.3.attention.self.value.weight', 'text_encoder_m.encoder.layer.3.attention.self.value.bias', 'text_encoder_m.encoder.layer.3.attention.output.dense.weight', 'text_encoder_m.encoder.layer.3.attention.output.dense.bias', 'text_encoder_m.encoder.layer.3.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.3.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.3.intermediate.dense.weight', 'text_encoder_m.encoder.layer.3.intermediate.dense.bias', 'text_encoder_m.encoder.layer.3.output.dense.weight', 'text_encoder_m.encoder.layer.3.output.dense.bias', 'text_encoder_m.encoder.layer.3.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.3.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.4.attention.self.query.weight', 'text_encoder_m.encoder.layer.4.attention.self.query.bias', 'text_encoder_m.encoder.layer.4.attention.self.key.weight', 'text_encoder_m.encoder.layer.4.attention.self.key.bias', 'text_encoder_m.encoder.layer.4.attention.self.value.weight', 'text_encoder_m.encoder.layer.4.attention.self.value.bias', 'text_encoder_m.encoder.layer.4.attention.output.dense.weight', 'text_encoder_m.encoder.layer.4.attention.output.dense.bias', 'text_encoder_m.encoder.layer.4.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.4.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.4.intermediate.dense.weight', 'text_encoder_m.encoder.layer.4.intermediate.dense.bias', 'text_encoder_m.encoder.layer.4.output.dense.weight', 'text_encoder_m.encoder.layer.4.output.dense.bias', 'text_encoder_m.encoder.layer.4.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.4.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.5.attention.self.query.weight', 'text_encoder_m.encoder.layer.5.attention.self.query.bias', 'text_encoder_m.encoder.layer.5.attention.self.key.weight', 'text_encoder_m.encoder.layer.5.attention.self.key.bias', 'text_encoder_m.encoder.layer.5.attention.self.value.weight', 'text_encoder_m.encoder.layer.5.attention.self.value.bias', 'text_encoder_m.encoder.layer.5.attention.output.dense.weight', 'text_encoder_m.encoder.layer.5.attention.output.dense.bias', 'text_encoder_m.encoder.layer.5.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.5.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.5.intermediate.dense.weight', 'text_encoder_m.encoder.layer.5.intermediate.dense.bias', 'text_encoder_m.encoder.layer.5.output.dense.weight', 'text_encoder_m.encoder.layer.5.output.dense.bias', 'text_encoder_m.encoder.layer.5.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.5.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.6.attention.self.query.weight', 'text_encoder_m.encoder.layer.6.attention.self.query.bias', 'text_encoder_m.encoder.layer.6.attention.self.key.weight', 'text_encoder_m.encoder.layer.6.attention.self.key.bias', 'text_encoder_m.encoder.layer.6.attention.self.value.weight', 'text_encoder_m.encoder.layer.6.attention.self.value.bias', 'text_encoder_m.encoder.layer.6.attention.output.dense.weight', 'text_encoder_m.encoder.layer.6.attention.output.dense.bias', 'text_encoder_m.encoder.layer.6.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.6.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.6.crossattention.self.query.weight', 'text_encoder_m.encoder.layer.6.crossattention.self.query.bias', 'text_encoder_m.encoder.layer.6.crossattention.self.key.weight', 'text_encoder_m.encoder.layer.6.crossattention.self.key.bias', 'text_encoder_m.encoder.layer.6.crossattention.self.value.weight', 'text_encoder_m.encoder.layer.6.crossattention.self.value.bias', 'text_encoder_m.encoder.layer.6.crossattention.output.dense.weight', 'text_encoder_m.encoder.layer.6.crossattention.output.dense.bias', 'text_encoder_m.encoder.layer.6.crossattention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.6.crossattention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.6.intermediate.dense.weight', 'text_encoder_m.encoder.layer.6.intermediate.dense.bias', 'text_encoder_m.encoder.layer.6.output.dense.weight', 'text_encoder_m.encoder.layer.6.output.dense.bias', 'text_encoder_m.encoder.layer.6.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.6.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.7.attention.self.query.weight', 'text_encoder_m.encoder.layer.7.attention.self.query.bias', 'text_encoder_m.encoder.layer.7.attention.self.key.weight', 'text_encoder_m.encoder.layer.7.attention.self.key.bias', 'text_encoder_m.encoder.layer.7.attention.self.value.weight', 'text_encoder_m.encoder.layer.7.attention.self.value.bias', 'text_encoder_m.encoder.layer.7.attention.output.dense.weight', 'text_encoder_m.encoder.layer.7.attention.output.dense.bias', 'text_encoder_m.encoder.layer.7.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.7.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.7.crossattention.self.query.weight', 'text_encoder_m.encoder.layer.7.crossattention.self.query.bias', 'text_encoder_m.encoder.layer.7.crossattention.self.key.weight', 'text_encoder_m.encoder.layer.7.crossattention.self.key.bias', 'text_encoder_m.encoder.layer.7.crossattention.self.value.weight', 'text_encoder_m.encoder.layer.7.crossattention.self.value.bias', 'text_encoder_m.encoder.layer.7.crossattention.output.dense.weight', 'text_encoder_m.encoder.layer.7.crossattention.output.dense.bias', 'text_encoder_m.encoder.layer.7.crossattention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.7.crossattention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.7.intermediate.dense.weight', 'text_encoder_m.encoder.layer.7.intermediate.dense.bias', 'text_encoder_m.encoder.layer.7.output.dense.weight', 'text_encoder_m.encoder.layer.7.output.dense.bias', 'text_encoder_m.encoder.layer.7.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.7.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.8.attention.self.query.weight', 'text_encoder_m.encoder.layer.8.attention.self.query.bias', 'text_encoder_m.encoder.layer.8.attention.self.key.weight', 'text_encoder_m.encoder.layer.8.attention.self.key.bias', 'text_encoder_m.encoder.layer.8.attention.self.value.weight', 'text_encoder_m.encoder.layer.8.attention.self.value.bias', 'text_encoder_m.encoder.layer.8.attention.output.dense.weight', 'text_encoder_m.encoder.layer.8.attention.output.dense.bias', 'text_encoder_m.encoder.layer.8.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.8.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.8.crossattention.self.query.weight', 'text_encoder_m.encoder.layer.8.crossattention.self.query.bias', 'text_encoder_m.encoder.layer.8.crossattention.self.key.weight', 'text_encoder_m.encoder.layer.8.crossattention.self.key.bias', 'text_encoder_m.encoder.layer.8.crossattention.self.value.weight', 'text_encoder_m.encoder.layer.8.crossattention.self.value.bias', 'text_encoder_m.encoder.layer.8.crossattention.output.dense.weight', 'text_encoder_m.encoder.layer.8.crossattention.output.dense.bias', 'text_encoder_m.encoder.layer.8.crossattention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.8.crossattention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.8.intermediate.dense.weight', 'text_encoder_m.encoder.layer.8.intermediate.dense.bias', 'text_encoder_m.encoder.layer.8.output.dense.weight', 'text_encoder_m.encoder.layer.8.output.dense.bias', 'text_encoder_m.encoder.layer.8.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.8.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.9.attention.self.query.weight', 'text_encoder_m.encoder.layer.9.attention.self.query.bias', 'text_encoder_m.encoder.layer.9.attention.self.key.weight', 'text_encoder_m.encoder.layer.9.attention.self.key.bias', 'text_encoder_m.encoder.layer.9.attention.self.value.weight', 'text_encoder_m.encoder.layer.9.attention.self.value.bias', 'text_encoder_m.encoder.layer.9.attention.output.dense.weight', 'text_encoder_m.encoder.layer.9.attention.output.dense.bias', 'text_encoder_m.encoder.layer.9.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.9.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.9.crossattention.self.query.weight', 'text_encoder_m.encoder.layer.9.crossattention.self.query.bias', 'text_encoder_m.encoder.layer.9.crossattention.self.key.weight', 'text_encoder_m.encoder.layer.9.crossattention.self.key.bias', 'text_encoder_m.encoder.layer.9.crossattention.self.value.weight', 'text_encoder_m.encoder.layer.9.crossattention.self.value.bias', 'text_encoder_m.encoder.layer.9.crossattention.output.dense.weight', 'text_encoder_m.encoder.layer.9.crossattention.output.dense.bias', 'text_encoder_m.encoder.layer.9.crossattention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.9.crossattention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.9.intermediate.dense.weight', 'text_encoder_m.encoder.layer.9.intermediate.dense.bias', 'text_encoder_m.encoder.layer.9.output.dense.weight', 'text_encoder_m.encoder.layer.9.output.dense.bias', 'text_encoder_m.encoder.layer.9.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.9.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.10.attention.self.query.weight', 'text_encoder_m.encoder.layer.10.attention.self.query.bias', 'text_encoder_m.encoder.layer.10.attention.self.key.weight', 'text_encoder_m.encoder.layer.10.attention.self.key.bias', 'text_encoder_m.encoder.layer.10.attention.self.value.weight', 'text_encoder_m.encoder.layer.10.attention.self.value.bias', 'text_encoder_m.encoder.layer.10.attention.output.dense.weight', 'text_encoder_m.encoder.layer.10.attention.output.dense.bias', 'text_encoder_m.encoder.layer.10.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.10.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.10.crossattention.self.query.weight', 'text_encoder_m.encoder.layer.10.crossattention.self.query.bias', 'text_encoder_m.encoder.layer.10.crossattention.self.key.weight', 'text_encoder_m.encoder.layer.10.crossattention.self.key.bias', 'text_encoder_m.encoder.layer.10.crossattention.self.value.weight', 'text_encoder_m.encoder.layer.10.crossattention.self.value.bias', 'text_encoder_m.encoder.layer.10.crossattention.output.dense.weight', 'text_encoder_m.encoder.layer.10.crossattention.output.dense.bias', 'text_encoder_m.encoder.layer.10.crossattention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.10.crossattention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.10.intermediate.dense.weight', 'text_encoder_m.encoder.layer.10.intermediate.dense.bias', 'text_encoder_m.encoder.layer.10.output.dense.weight', 'text_encoder_m.encoder.layer.10.output.dense.bias', 'text_encoder_m.encoder.layer.10.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.10.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.11.attention.self.query.weight', 'text_encoder_m.encoder.layer.11.attention.self.query.bias', 'text_encoder_m.encoder.layer.11.attention.self.key.weight', 'text_encoder_m.encoder.layer.11.attention.self.key.bias', 'text_encoder_m.encoder.layer.11.attention.self.value.weight', 'text_encoder_m.encoder.layer.11.attention.self.value.bias', 'text_encoder_m.encoder.layer.11.attention.output.dense.weight', 'text_encoder_m.encoder.layer.11.attention.output.dense.bias', 'text_encoder_m.encoder.layer.11.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.11.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.11.crossattention.self.query.weight', 'text_encoder_m.encoder.layer.11.crossattention.self.query.bias', 'text_encoder_m.encoder.layer.11.crossattention.self.key.weight', 'text_encoder_m.encoder.layer.11.crossattention.self.key.bias', 'text_encoder_m.encoder.layer.11.crossattention.self.value.weight', 'text_encoder_m.encoder.layer.11.crossattention.self.value.bias', 'text_encoder_m.encoder.layer.11.crossattention.output.dense.weight', 'text_encoder_m.encoder.layer.11.crossattention.output.dense.bias', 'text_encoder_m.encoder.layer.11.crossattention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.11.crossattention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.11.intermediate.dense.weight', 'text_encoder_m.encoder.layer.11.intermediate.dense.bias', 'text_encoder_m.encoder.layer.11.output.dense.weight', 'text_encoder_m.encoder.layer.11.output.dense.bias', 'text_encoder_m.encoder.layer.11.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.11.output.LayerNorm.bias', 'text_encoder.cls.predictions.bias', 'text_encoder.cls.predictions.transform.dense.weight', 'text_encoder.cls.predictions.transform.dense.bias', 'text_encoder.cls.predictions.transform.LayerNorm.weight', 'text_encoder.cls.predictions.transform.LayerNorm.bias', 'text_encoder.cls.predictions.decoder.weight', 'text_encoder.cls.predictions.decoder.bias'])
Start training
/nlp_group/wuxing/ALBEF/models/model_retrieval_title.py:160: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  title_label = torch.tensor(title_label, dtype=torch.long).to(image.device)
/nlp_group/wuxing/ALBEF/models/model_retrieval_title.py:160: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  title_label = torch.tensor(title_label, dtype=torch.long).to(image.device)
/nlp_group/wuxing/ALBEF/models/model_retrieval_title.py:160: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  title_label = torch.tensor(title_label, dtype=torch.long).to(image.device)
/nlp_group/wuxing/ALBEF/models/model_retrieval_title.py:160: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  title_label = torch.tensor(title_label, dtype=torch.long).to(image.device)
Train Epoch: [0]  [  0/109]  eta: 0:07:00  lr: 0.000001  loss_title: 3.2409  time: 3.8568  data: 0.1683  max mem: 16708
Train Epoch: [0]  [ 50/109]  eta: 0:01:35  lr: 0.000001  loss_title: 3.1741  time: 1.5741  data: 0.1499  max mem: 19052
Train Epoch: [0]  [100/109]  eta: 0:00:14  lr: 0.000001  loss_title: 2.7010  time: 1.5811  data: 0.1502  max mem: 19052
Train Epoch: [0]  [108/109]  eta: 0:00:01  lr: 0.000001  loss_title: 2.7635  time: 1.5792  data: 0.1497  max mem: 19052
Train Epoch: [0] Total time: 0:02:53 (1.5951 s / it)
Averaged stats: lr: 0.0000  loss_title: 2.9952
Val :   [ 0/25]  eta: 0:00:19    time: 0.7942  data: 0.3343  max mem: 19052
Val :   [24/25]  eta: 0:00:00    time: 0.4666  data: 0.3079  max mem: 19052
Val :  Total time: 0:00:12 (0.4821 s / it)
F1-score: 0.040832988917827606
Accuracy: 0.22208121418952942
Specificity: 0.9604373574256897
recall: 0.05841824412345886
Precision: 0.0809171050786972
Confusion Matrics: tensor([[  4,   0,   0,   0,   0,   0,   0,   0,   4,   4,   0,   0,   0,   0,
           0,   0,  12,   0,   0, 104,   8,   0,   0,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   8,   0,   0,   0,   0,   0,
           0,   0,   4,   0,   0, 144,   4,   0,   0,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   8,   0,   0,   0,   0,   0,
           0,   0,   4,   0,   0, 160,   0,   0,   0,   0],
        [  4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   8,   0,   0,  28,   4,   0,   0,   0],
        [  8,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,
           0,   8,   4,   0,   0,  60,  16,   0,   8,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  16,   0,   0,   0,   0,
           0,   0,   0,   0,   0,  60,  12,   0,   0,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   4,   0,  44,   4,   0,   0,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   8,   0,   0,   0,   0,
           0,   0,   0,   0,   0,  24,   0,   0,   0,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,  12,   0,   0,   0,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,
           0,   0,   8,   0,   0,  56,  28,   0,   0,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   8,   0,   0,   0,   0,
           0,   0,   0,   0,   0,  16,   0,   0,   0,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,  40,   0,   0,   0,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,  44,  12,   0,   0,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,
           0,   0,   0,   0,   0,  84,   0,   0,   0,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,  56,  16,   0,   0,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   4,   4,   0,   0,   0,   0,
           0,  12,  20,   0,   0, 112,   8,   4,   0,   0],
        [  4,   0,   0,   0,   0,   0,   0,   0,   0,  12,   0,   0,   0,   0,
           0,   0,  32,   0,   0, 136,  16,   0,   0,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,
           0,   0,   4,   0,   0,  44,   8,   0,   0,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,
           0,   0,   0,   0,   0,  12,  12,   0,   0,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   8,   0,   0,   0,   0,
           0,   0,  40,   0,   0, 612,  28,   0,   4,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,   0,
           0,   0,   4,   0,   0,  44,   8,   0,   4,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   4,   0,   0, 120,   8,   0,   8,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   8,   0,   4,   0,   0,
           0,   0,   4,   0,   0, 132,  24,   0,   8,  12],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   4,  32,   0,   0, 300,  32,   0,  40,  20]], device='cuda:0')
Evaluation time 0:00:12
Train Epoch: [1]  [  0/109]  eta: 0:02:56  lr: 0.000010  loss_title: 2.7572  time: 1.6213  data: 0.1641  max mem: 19052
Train Epoch: [1]  [ 50/109]  eta: 0:01:33  lr: 0.000010  loss_title: 0.9000  time: 1.5778  data: 0.1481  max mem: 19067
Train Epoch: [1]  [100/109]  eta: 0:00:14  lr: 0.000010  loss_title: 0.6208  time: 1.5803  data: 0.1500  max mem: 19067
Train Epoch: [1]  [108/109]  eta: 0:00:01  lr: 0.000010  loss_title: 0.9226  time: 1.5799  data: 0.1500  max mem: 19067
Train Epoch: [1] Total time: 0:02:51 (1.5773 s / it)
Averaged stats: lr: 0.0000  loss_title: 1.4647
Val :   [ 0/25]  eta: 0:00:11    time: 0.4786  data: 0.3162  max mem: 19067
Val :   [24/25]  eta: 0:00:00    time: 0.4648  data: 0.3071  max mem: 19067
Val :  Total time: 0:00:11 (0.4678 s / it)
F1-score: 0.25356534123420715
Accuracy: 0.5
Specificity: 0.9772603511810303
recall: 0.2712838351726532
Precision: 0.26340189576148987
Confusion Matrics: tensor([[ 72,   8,  12,   0,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,
           0,   0,   4,   0,   0,   0,   4,  20,   0,  12],
        [  0,  96,  28,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   4,  24,   0,   0,   4,   0,   4,   0,   0],
        [ 12,  28, 104,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   4,  16,   0,   0,   8,   0,   0,   0,   0],
        [  8,   0,   8,   0,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,
           0,   0,  20,   0,   0,   0,   0,   4,   0,   0],
        [  8,   0,   0,   0,  56,   0,   0,   0,   0,   4,   0,   0,   0,   0,
           0,   4,  24,   0,   0,   0,   0,   8,   0,   4],
        [  0,   0,   0,   0,   8,   0,   0,   0,   0,  16,   0,   0,   0,   0,
           4,   0,   4,   0,   0,   0,  20,  16,   4,  16],
        [  8,   0,   4,   0,   4,   0,   0,   0,   0,   8,   0,   0,   0,   4,
           0,   0,  12,   0,   0,   4,   0,   8,   0,   0],
        [  0,   0,   0,   0,   4,   0,   0,   0,   0,  20,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   8,   0,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   4,   0,   0,   0,   0,   4,   4,   0],
        [  0,   0,   0,   0,   4,   0,   0,   0,   0,  40,   0,   0,   4,   0,
           0,   0,   0,   0,   0,   4,   4,  16,   8,  16],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   8,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   8,   0,   8],
        [  4,   0,   0,   0,   4,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   8,   0,   0,   4,   0,   8,   0,  12],
        [  0,   0,   0,   0,   4,   0,   0,   0,   0,   4,   0,   0,   4,   4,
           0,   0,  12,   0,   0,   0,   0,   4,   8,  16],
        [  4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,
           0,   0,   8,   0,   0,   8,   0,  44,   8,  12],
        [  4,   4,   4,   0,  20,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   8,   0,   0,   0,  12,  20,   4,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,  84,  64,   0,   0,   4,   4,   0,   4,   4],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,
           0,   0, 160,   0,   0,  24,   0,   0,   0,  12],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,
           0,   0,  12,   0,   0,  16,   4,   4,   8,  12],
        [  0,   0,   4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,  20,   0,   0,   0,   4,   0,   0,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  12,   0,   0,   0,   0,
           0,   0, 136,   0,   0, 496,   0,   0,  12,  36],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,
           0,   0,  16,   0,   0,   0,  20,   8,   8,   8],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,
           0,   0,  20,   0,   0,  16,   4,  36,  12,  48],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   8,   0,   0,   0,   0,
           0,   0,   4,   0,   0,  12,   8,  16,  76,  68],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,
           0,   0,   8,   0,   0,  32,   8,  12,  32, 332]], device='cuda:0')
Evaluation time 0:00:11
Train Epoch: [2]  [  0/109]  eta: 0:02:52  lr: 0.000010  loss_title: 0.6174  time: 1.5818  data: 0.1562  max mem: 19067
Train Epoch: [2]  [ 50/109]  eta: 0:01:32  lr: 0.000010  loss_title: 0.8329  time: 1.5756  data: 0.1467  max mem: 19067
Train Epoch: [2]  [100/109]  eta: 0:00:14  lr: 0.000010  loss_title: 0.4283  time: 1.5785  data: 0.1489  max mem: 19067
Train Epoch: [2]  [108/109]  eta: 0:00:01  lr: 0.000010  loss_title: 0.6101  time: 1.5780  data: 0.1499  max mem: 19067
Train Epoch: [2] Total time: 0:02:51 (1.5762 s / it)
Averaged stats: lr: 0.0000  loss_title: 0.7494
Val :   [ 0/25]  eta: 0:00:11    time: 0.4765  data: 0.3166  max mem: 19067
Val :   [24/25]  eta: 0:00:00    time: 0.4636  data: 0.3067  max mem: 19067
Val :  Total time: 0:00:11 (0.4666 s / it)
F1-score: 0.2687014043331146
Accuracy: 0.49873095750808716
Specificity: 0.9771113395690918
recall: 0.28519144654273987
Precision: 0.34094488620758057
Confusion Matrics: tensor([[ 76,   8,   8,   0,   0,   0,   4,   0,   0,   4,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   8,  12,   8,   4,   4],
        [  4,  68,  76,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   4,   0,   0,   4,   4,   0,   0,   0],
        [ 24,   4, 136,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   8,   0,   0,   0,   0],
        [ 12,   0,   0,   8,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,
           0,   0,   4,   0,   0,   4,   8,   4,   0,   0],
        [ 16,   0,   0,   0,  44,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,  12,   0,   0,   0,  20,  16,   0,   0],
        [  4,   0,   0,   0,   0,   8,   0,   0,   0,  20,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,  32,  12,   8,   4],
        [ 16,   0,   4,   4,   0,   0,   4,   0,   0,   4,   0,   0,   0,   0,
           0,   0,   4,   0,   0,   8,   8,   0,   0,   0],
        [  0,   0,   0,   0,   0,   4,   4,   0,   0,   8,   0,   0,   4,   0,
           0,   0,   0,   0,   0,   0,   8,   4,   0,   0],
        [  4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   4,   4,   0,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  40,   0,   0,   8,   0,
           0,   0,   0,   0,   0,   4,  24,   0,  16,   4],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   8,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   8,   0,   8],
        [  8,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,
           0,   0,   4,   0,   0,  12,  12,   0,   0,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,
           0,   0,  12,   0,   0,   0,  16,   4,  20,   0],
        [  8,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   8,   0,
           0,   0,   4,   0,   0,  20,  20,   8,  20,   0],
        [ 12,   4,   4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   4,
           0,   0,  12,   0,   0,   0,  16,  20,   4,   0],
        [  0,   4,   0,   0,   4,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,  48,  64,   0,   0,  24,  12,   0,   4,   4],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0, 140,   0,   0,  44,   8,   4,   4,   0],
        [  8,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   8,   0,   0,  24,   4,   8,   8,   0],
        [  4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   8,   0,   0,  12,   4,   0,   0,   0],
        [  4,   0,   0,   0,   0,   0,   4,   0,   0,  12,   0,   0,   0,   0,
           0,   0,  56,   0,   0, 584,   8,   4,   8,  12],
        [  4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   4,   0,   0,   0,  44,   4,   4,   4],
        [  4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,  12,   0,   0,  20,  16,  32,  36,  20],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,
           0,   0,   0,   0,   0,  28,  20,   8, 100,  32],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,
           0,   0,   4,   0,   0,  68,  16,  12,  88, 236]], device='cuda:0')
Evaluation time 0:00:11
Train Epoch: [3]  [  0/109]  eta: 0:02:53  lr: 0.000010  loss_title: 0.7025  time: 1.5941  data: 0.1551  max mem: 19067
Train Epoch: [3]  [ 50/109]  eta: 0:01:32  lr: 0.000010  loss_title: 0.2301  time: 1.5737  data: 0.1491  max mem: 19067
Train Epoch: [3]  [100/109]  eta: 0:00:14  lr: 0.000010  loss_title: 0.5496  time: 1.5782  data: 0.1497  max mem: 19067
Train Epoch: [3]  [108/109]  eta: 0:00:01  lr: 0.000010  loss_title: 0.6458  time: 1.5774  data: 0.1496  max mem: 19067
Train Epoch: [3] Total time: 0:02:51 (1.5758 s / it)
Averaged stats: lr: 0.0000  loss_title: 0.5315
Val :   [ 0/25]  eta: 0:00:11    time: 0.4785  data: 0.3175  max mem: 19067
Val :   [24/25]  eta: 0:00:00    time: 0.4597  data: 0.3029  max mem: 19067
Val :  Total time: 0:00:11 (0.4632 s / it)
F1-score: 0.29884636402130127
Accuracy: 0.5380710363388062
Specificity: 0.978889524936676
recall: 0.3148716688156128
Precision: 0.34451594948768616
Confusion Matrics: tensor([[ 92,  16,   4,   0,   0,   0,   4,   0,   0,   4,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   8,   4,   0,   4],
        [  4, 136,   8,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   4,   0,   0,   4,   4,   0,   0,   0],
        [ 16,  28, 124,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   4,   0,   0],
        [  4,   8,   0,  12,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   4,   0,   0,   4,   8,   4,   0,   0],
        [ 16,   0,   0,   0,  52,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,  16,   0,   0,   0,  12,  12,   0,   0],
        [  4,   0,   0,   0,   8,   0,   0,   0,   0,   8,   0,   0,   0,   8,
          12,   0,   0,   0,   0,   0,  24,  16,   0,   8],
        [ 12,   0,   4,   4,   0,   0,   8,   0,   0,   4,   0,   0,   0,   0,
           4,   0,   4,   0,   0,   8,   4,   0,   0,   0],
        [  0,   0,   0,   0,   8,   4,   0,   0,   0,   0,   0,   0,   0,   4,
           4,   0,   0,   0,   0,   0,   8,   4,   0,   0],
        [  4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   4,   4,   0,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  24,   0,   0,   8,   0,
           0,   0,   0,   0,   0,   4,  36,   0,  20,   4],
        [  0,   0,   0,   0,   0,   0,   8,   0,   0,   4,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   4,   0,   8],
        [  4,   0,   0,   0,   4,   0,   4,   0,   0,   0,   0,   0,   4,   0,
           0,   0,   8,   0,   0,   4,   4,   4,   0,   4],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   8,   4,
           0,   0,   8,   0,   0,   0,  20,   4,   4,   8],
        [  4,   4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   4,   0,   0,  20,  16,  16,  12,  12],
        [  8,   4,   0,   0,  16,   0,   0,   0,   0,   0,   0,   0,   0,   4,
           4,   0,  12,   0,   0,   0,  16,  12,   0,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,  52,  72,   0,   0,   8,  12,   4,   8,   8],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0, 144,   0,   0,  40,   8,   4,   0,   4],
        [  4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   8,   0,   0,  28,   0,  12,   4,   4],
        [  0,   4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   8,   0,   0,  12,   4,   0,   0,   0],
        [  8,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,  48,   0,   0, 576,  12,   4,   4,  40],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,
           0,   0,   4,   0,   0,   0,  48,   0,   8,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   8,   0,   0,  20,  24,  40,  20,  28],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   4,   0,   0,  32,  24,  20,  60,  52],
        [  4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   4,   0,   0,  52,  16,  16,  20, 316]], device='cuda:0')
Evaluation time 0:00:11
Train Epoch: [4]  [  0/109]  eta: 0:02:55  lr: 0.000010  loss_title: 0.6420  time: 1.6068  data: 0.1546  max mem: 19067
Train Epoch: [4]  [ 50/109]  eta: 0:01:33  lr: 0.000010  loss_title: 0.5388  time: 1.5774  data: 0.1492  max mem: 19067
Train Epoch: [4]  [100/109]  eta: 0:00:14  lr: 0.000010  loss_title: 0.2596  time: 1.5782  data: 0.1501  max mem: 19067
Train Epoch: [4]  [108/109]  eta: 0:00:01  lr: 0.000010  loss_title: 0.3014  time: 1.5752  data: 0.1487  max mem: 19067
Train Epoch: [4] Total time: 0:02:51 (1.5763 s / it)
Averaged stats: lr: 0.0000  loss_title: 0.4008
Val :   [ 0/25]  eta: 0:00:11    time: 0.4763  data: 0.3161  max mem: 19067
Val :   [24/25]  eta: 0:00:00    time: 0.4637  data: 0.3059  max mem: 19067
Val :  Total time: 0:00:11 (0.4659 s / it)
F1-score: 0.2933313846588135
Accuracy: 0.5
Specificity: 0.9769652485847473
recall: 0.2973090410232544
Precision: 0.40429002046585083
Confusion Matrics: tensor([[ 96,   8,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   4,   4,   8,  12],
        [  4, 112,  32,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   4,   0,   0,   4,   4,   0,   0,   0],
        [ 36,  12, 104,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   8,   0,   4,   4,   4],
        [  4,   0,   0,  20,   0,   0,   0,   0,   0,   8,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   4,   4,   0,   0,   4],
        [ 24,   0,   0,   0,  28,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           8,   0,  12,   0,   0,   0,  16,   8,   0,  12],
        [ 12,   0,   0,   0,   0,   8,   0,   0,   0,  16,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,  24,   0,   4,  24],
        [ 20,   0,   0,   4,   0,   0,   4,   0,   0,   8,   0,   0,   0,   0,
           0,   0,   4,   0,   0,   8,   4,   0,   0,   0],
        [  0,   0,   0,   0,   0,   4,   0,   0,   0,   8,   0,   0,   4,   0,
           4,   0,   0,   0,   0,   0,   8,   0,   0,   4],
        [  4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   4,   4,   0,   0],
        [  4,   0,   0,   0,   0,   0,   0,   0,   0,  36,   0,   0,   4,   0,
           0,   0,   0,   0,   0,   0,  28,   0,  20,   4],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  12,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   0,   4,   8],
        [  8,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,   0,   4,   0,
           0,   0,   0,   0,   0,   8,   0,   4,   0,  12],
        [  0,   0,   0,   0,   0,   0,   4,   0,   0,   8,   0,   0,   8,   0,
           0,   0,   4,   0,   0,   0,   8,   0,  16,   8],
        [ 12,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           4,   0,   0,   0,   0,  12,   4,   4,  36,  16],
        [ 16,   0,   0,   0,   0,   4,   0,   0,   0,   0,   0,   0,   0,   8,
           8,   0,   8,   0,   0,   0,  12,   8,   4,   8],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,  56,  48,   0,   0,  28,   8,   0,   4,  20],
        [  8,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   4,
           0,   0, 104,   0,   0,  52,  12,   0,   8,   8],
        [  8,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   4,   0,  16,   0,   4,   8,  20],
        [  4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   8,   0,   0,  12,   4,   0,   0,   0],
        [  4,   0,   0,   0,   0,   0,  12,   0,   0,   8,   0,   0,   0,   0,
           0,   0,  24,   0,   0, 540,   8,   0,  16,  80],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,  40,   0,  16,   4],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   4,   0,   0,  20,  12,  12,  36,  56],
        [  4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,  12,  16,   0,  96,  64],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,
           0,   0,   0,   0,   0,  44,  16,   4,  60, 300]], device='cuda:0')
Evaluation time 0:00:11
Train Epoch: [5]  [  0/109]  eta: 0:02:56  lr: 0.000010  loss_title: 0.4579  time: 1.6150  data: 0.1542  max mem: 19067
Train Epoch: [5]  [ 50/109]  eta: 0:01:33  lr: 0.000010  loss_title: 0.2894  time: 1.5756  data: 0.1488  max mem: 19067
Train Epoch: [5]  [100/109]  eta: 0:00:14  lr: 0.000010  loss_title: 0.3932  time: 1.5812  data: 0.1494  max mem: 19067
Train Epoch: [5]  [108/109]  eta: 0:00:01  lr: 0.000010  loss_title: 0.1818  time: 1.5794  data: 0.1492  max mem: 19067
Train Epoch: [5] Total time: 0:02:51 (1.5771 s / it)
Averaged stats: lr: 0.0000  loss_title: 0.3371
Val :   [ 0/25]  eta: 0:00:12    time: 0.4805  data: 0.3217  max mem: 19067
Val :   [24/25]  eta: 0:00:00    time: 0.4606  data: 0.3036  max mem: 19067
Val :  Total time: 0:00:11 (0.4636 s / it)
F1-score: 0.32240429520606995
Accuracy: 0.5418781638145447
Specificity: 0.9792840480804443
recall: 0.3404153883457184
Precision: 0.3537992835044861
Confusion Matrics: tensor([[ 96,   8,   0,   0,   0,   0,   4,   0,   0,   4,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   8,   8,   0,   8],
        [  4, 132,  16,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   4,   0,   0,   4,   0,   0,   0,   0],
        [ 16,  16, 132,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   4,   0,   0,   0,   0,   0,   4,   0,   0],
        [  4,   8,   4,  12,   0,   4,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   4,   4,   0,   0,   4],
        [ 20,   0,   0,   0,  48,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           4,   0,   4,   0,   0,   0,  16,  12,   0,   4],
        [  4,   0,   0,   0,   0,   0,   0,   0,   0,  12,   0,   0,   4,   0,
          16,   0,   0,   0,   0,   0,  24,   8,   0,  20],
        [ 12,   0,   4,   4,   0,   0,   8,   0,   0,   4,   0,   0,   0,   0,
           0,   0,   4,   0,   0,   0,  16,   0,   0,   0],
        [  0,   0,   0,   0,   0,   4,   0,   0,   0,   4,   0,   0,   4,   0,
           8,   0,   0,   0,   0,   0,   8,   4,   0,   0],
        [  0,   0,   4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   4,   4,   0,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  32,   0,   0,   8,   0,
           0,   0,   0,   0,   0,   0,  40,   0,  12,   4],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   8,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   4,   4,   0,   8],
        [  4,   0,   0,   0,   4,   0,   4,   0,   0,   0,   0,   0,   8,   0,
           0,   0,   4,   0,   0,   0,   8,   4,   0,   4],
        [  0,   0,   0,   0,   4,   0,   4,   0,   0,   0,   0,   0,  12,   0,
           0,   0,   0,   0,   0,   0,  12,   4,   8,  12],
        [  8,   4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   8,   0,
           4,   0,   0,   0,   0,  12,  12,  20,   8,  12],
        [ 12,   0,   0,   0,   4,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          24,   0,   4,   0,   0,   0,  16,  16,   0,   0],
        [  0,   4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,  80,  40,   0,   4,   4,   4,   0,   4,  24],
        [  4,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,   0,   8,   0,
           0,   0, 116,   0,   0,  32,  16,   0,   0,  20],
        [ 12,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,  16,   4,   8,   4,  16],
        [  4,   4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   8,   0,   0,   8,   4,   0,   0,   0],
        [ 12,   0,   0,   0,   0,   0,  12,   0,   0,   0,   0,   0,   4,   0,
           0,   0,  36,   0,   0, 524,  20,   4,   4,  76],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,  56,   0,   8,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   4,   0,   0,  12,  16,  56,   8,  44],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   4,   4,   0,   0,   8,  32,  32,  52,  60],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,
           0,   0,   0,   0,   0,  20,  24,  32,  20, 328]], device='cuda:0')
Evaluation time 0:00:11
Train Epoch: [6]  [  0/109]  eta: 0:02:57  lr: 0.000010  loss_title: 0.3090  time: 1.6262  data: 0.1517  max mem: 19067
Train Epoch: [6]  [ 50/109]  eta: 0:01:32  lr: 0.000010  loss_title: 0.3449  time: 1.5733  data: 0.1483  max mem: 19067
Train Epoch: [6]  [100/109]  eta: 0:00:14  lr: 0.000010  loss_title: 0.6968  time: 1.5782  data: 0.1492  max mem: 19067
Train Epoch: [6]  [108/109]  eta: 0:00:01  lr: 0.000010  loss_title: 0.2211  time: 1.5780  data: 0.1501  max mem: 19067
Train Epoch: [6] Total time: 0:02:51 (1.5769 s / it)
Averaged stats: lr: 0.0000  loss_title: 0.2575
Val :   [ 0/25]  eta: 0:00:11    time: 0.4765  data: 0.3157  max mem: 19067
Val :   [24/25]  eta: 0:00:00    time: 0.4630  data: 0.3058  max mem: 19067
Val :  Total time: 0:00:11 (0.4653 s / it)
F1-score: 0.32623985409736633
Accuracy: 0.546954333782196
Specificity: 0.9792734384536743
recall: 0.33406010270118713
Precision: 0.3523704707622528
Confusion Matrics: tensor([[ 76,  12,  16,   0,   0,   0,   4,   0,   0,   4,   0,   0,   0,   4,
           0,   0,   0,   0,   0,   0,   4,   0,   8,   8],
        [  4, 124,  24,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   4,   0,   0,   0,   4],
        [  0,  16, 156,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
        [  0,   0,  12,  16,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   4,   4,   0,   0,   4],
        [ 12,  12,   0,   0,  44,   0,   0,   0,   0,   0,   0,   0,   0,   4,
           0,   4,   8,   0,   0,   0,   8,  12,   0,   4],
        [  4,   0,   0,   0,  12,   8,   0,   0,   0,   4,   0,   0,   4,   0,
          16,   0,   0,   0,   0,   0,   4,   8,  12,  16],
        [  4,   0,  16,   0,   0,   0,   8,   0,   0,   4,   0,   0,   0,   0,
           4,   0,   4,   0,   0,   8,   4,   0,   0,   0],
        [  0,   0,   0,   0,   8,   8,   0,   0,   0,   0,   0,   0,   0,   0,
           8,   0,   0,   0,   0,   0,   0,   0,   8,   0],
        [  4,   0,   4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   4,   0,   0],
        [  8,   0,   0,   0,   0,   4,   0,   0,   0,  36,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,  16,   4,  24,   4],
        [  0,   0,   0,   0,   0,   0,   4,   0,   0,   8,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   4,   0,   8],
        [  0,   0,   4,   0,   4,   0,   4,   0,   0,   4,   0,   0,   8,   0,
           0,   4,   0,   0,   0,   4,   4,   0,   4,   0],
        [  0,   0,   4,   0,   0,   0,   4,   0,   0,   8,   0,   0,   8,   0,
           0,   0,   4,   0,   0,   0,   4,   0,  16,   8],
        [  4,   8,   0,   0,   4,   0,   0,   0,   0,   0,   0,   0,   4,   4,
           0,   0,   4,   0,   0,  12,   0,  12,  24,  12],
        [  8,   4,   0,   0,  12,   0,   0,   0,   0,   0,   0,   0,   0,   4,
          16,   0,  12,   0,   0,   0,   0,  12,   8,   0],
        [  0,   8,   0,   4,   0,   0,   0,   0,   0,   8,   0,   0,   0,   0,
           0,  88,  32,   0,   0,   4,   0,   0,   4,  16],
        [  4,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,   0,   4,   0,
           0,   8, 116,   0,   4,  48,   4,   4,   4,   0],
        [ 12,   4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,  24,   0,   8,   8,   4],
        [  0,   4,   4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   8,   0,   0,  12,   0,   0,   0,   0],
        [  4,   0,   0,   0,   0,   0,  12,   0,   0,   4,   0,   0,   4,   0,
           0,   0,  28,   0,   0, 560,   4,   0,  24,  52],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,  36,   8,  16,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   4,   0,   0,  24,   0,  44,  40,  28],
        [  4,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,   0,   0,   0,
           0,   4,   0,   0,   0,  16,  16,   4, 100,  44],
        [  0,   4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   4,
           0,   0,   0,   0,   0,  44,   8,   8,  72, 284]], device='cuda:0')
Evaluation time 0:00:11
Train Epoch: [7]  [  0/109]  eta: 0:02:53  lr: 0.000009  loss_title: 0.2375  time: 1.5941  data: 0.1535  max mem: 19067
Train Epoch: [7]  [ 50/109]  eta: 0:01:32  lr: 0.000009  loss_title: 0.1509  time: 1.5720  data: 0.1488  max mem: 19067
Train Epoch: [7]  [100/109]  eta: 0:00:14  lr: 0.000009  loss_title: 0.1314  time: 1.5761  data: 0.1487  max mem: 19067
Train Epoch: [7]  [108/109]  eta: 0:00:01  lr: 0.000009  loss_title: 0.0473  time: 1.5757  data: 0.1478  max mem: 19067
Train Epoch: [7] Total time: 0:02:51 (1.5751 s / it)
Averaged stats: lr: 0.0000  loss_title: 0.2183
Val :   [ 0/25]  eta: 0:00:11    time: 0.4769  data: 0.3177  max mem: 19067
Val :   [24/25]  eta: 0:00:00    time: 0.4596  data: 0.3019  max mem: 19067
Val :  Total time: 0:00:11 (0.4625 s / it)
F1-score: 0.32653412222862244
Accuracy: 0.546954333782196
Specificity: 0.9794091582298279
recall: 0.34253865480422974
Precision: 0.36129289865493774
Confusion Matrics: tensor([[112,   8,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   4,   0,   0,   8],
        [  4,  88,  64,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   4,   0,   0,   0,   0,   0,   0,   0],
        [ 12,   4, 156,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
        [  8,   4,   4,  12,   0,   0,   0,   0,   0,   4,   0,   0,   0,   4,
           0,   0,   0,   0,   0,   4,   4,   0,   0,   0],
        [ 20,   4,   0,   0,  40,   0,   0,   0,   0,   0,   0,   0,   0,   4,
           4,   4,   8,   0,   0,   0,  12,   0,   0,  12],
        [ 16,   0,   0,   0,   0,  16,   0,   0,   0,   8,   0,   0,   0,   4,
          12,   0,   0,   0,   0,   0,   8,   0,   8,  16],
        [ 16,   0,   4,   4,   0,   0,   8,   0,   0,   4,   0,   0,   0,   0,
           4,   0,   4,   0,   0,   4,   4,   0,   0,   0],
        [  0,   0,   0,   0,   4,  12,   0,   0,   0,   0,   0,   0,   4,   0,
           8,   0,   0,   0,   0,   0,   4,   0,   0,   0],
        [  4,   0,   4,   0,   0,   0,   4,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
        [  0,   0,   0,   0,   0,   8,   0,   0,   0,  32,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   4,  28,   0,  20,   4],
        [  0,   0,   0,   0,   0,   0,   4,   0,   0,   8,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   0,   4,   8],
        [  4,   0,   4,   0,   4,   0,   4,   0,   0,   4,   0,   0,   8,   0,
           0,   4,   0,   0,   0,   0,   4,   0,   0,   4],
        [  0,   0,   4,   0,   0,   0,   4,   0,   0,   8,   0,   0,  12,   0,
           0,   0,   4,   0,   0,   0,   8,   0,   8,   8],
        [  4,   8,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,   4,   8,
           0,   0,   0,   0,   0,   4,   8,   4,  28,  16],
        [ 12,   0,   0,   0,   4,   0,   0,   0,   0,   0,   0,   0,   0,   8,
          24,   0,   4,   0,   0,   0,   8,   4,   8,   4],
        [  0,   4,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,   0,   4,
           0, 100,  28,   0,   0,   4,   0,   0,   4,  16],
        [ 12,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   4, 120,   0,   4,  36,   4,   0,   4,  16],
        [ 12,   4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,  16,   8,   4,   8,   8],
        [  0,   8,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   8,   0,   0,  12,   0,   0,   0,   0],
        [  8,   0,   0,   0,   0,   0,   8,   0,   0,   8,   0,   0,   4,   4,
           0,   0,  28,   0,   0, 536,   8,   0,   8,  80],
        [  4,   0,   0,   4,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,
           0,   0,   0,   0,   0,   0,  48,   0,   4,   0],
        [  0,   4,   0,   4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   8,   0,   0,  12,  16,  12,  28,  56],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,
           0,   4,   4,   0,   0,  12,  28,   4,  88,  48],
        [  8,   4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   4,
           0,   0,   0,   0,   0,  28,  16,   0,  52, 312]], device='cuda:0')
Evaluation time 0:00:11
Train Epoch: [8]  [  0/109]  eta: 0:02:54  lr: 0.000009  loss_title: 0.1788  time: 1.6041  data: 0.1445  max mem: 19067
Train Epoch: [8]  [ 50/109]  eta: 0:01:33  lr: 0.000009  loss_title: 0.1006  time: 1.5775  data: 0.1477  max mem: 19067
Train Epoch: [8]  [100/109]  eta: 0:00:14  lr: 0.000009  loss_title: 0.6455  time: 1.5730  data: 0.1486  max mem: 19067
Train Epoch: [8]  [108/109]  eta: 0:00:01  lr: 0.000009  loss_title: 0.0420  time: 1.5758  data: 0.1491  max mem: 19067
Train Epoch: [8] Total time: 0:02:51 (1.5763 s / it)
Averaged stats: lr: 0.0000  loss_title: 0.1778
Val :   [ 0/25]  eta: 0:00:11    time: 0.4785  data: 0.3174  max mem: 19067
Val :   [24/25]  eta: 0:00:00    time: 0.4604  data: 0.3032  max mem: 19067
Val :  Total time: 0:00:11 (0.4634 s / it)
F1-score: 0.3355666995048523
Accuracy: 0.5507614016532898
Specificity: 0.9795895218849182
recall: 0.3504543900489807
Precision: 0.3623337745666504
Confusion Matrics: tensor([[108,   4,   4,   0,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   8,   4,   0,   4],
        [  4, 108,  40,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   4,   0,   0,   4,   0,   0,   0,   0],
        [ 12,   4, 156,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
        [  8,   4,   4,  12,   0,   4,   0,   0,   0,   4,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   4,   4,   0,   0,   0],
        [ 20,   0,   0,   0,  48,   0,   4,   0,   0,   0,   0,   0,   0,   0,
           4,   0,   4,   0,   0,   0,  12,   8,   0,   8],
        [ 12,   0,   0,   0,   8,   8,   0,   0,   0,   4,   0,   0,   4,   0,
          12,   0,   0,   0,   0,   0,  12,   8,   4,  16],
        [ 12,   0,   0,   4,   0,   0,  16,   0,   0,   4,   0,   0,   0,   0,
           4,   0,   4,   0,   0,   4,   4,   0,   0,   0],
        [  0,   0,   0,   0,   4,   8,   0,   0,   0,   0,   0,   0,   0,   0,
          12,   0,   0,   0,   0,   0,   8,   0,   0,   0],
        [  4,   0,   4,   0,   0,   0,   4,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
        [  0,   0,   0,   0,   0,   8,   0,   0,   0,  32,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,  36,   0,  12,   8],
        [  0,   0,   0,   0,   0,   0,   4,   0,   0,   8,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   4,   0,   8],
        [  4,   0,   0,   0,   4,   0,   4,   0,   0,   4,   0,   0,   4,   0,
           0,   0,   4,   0,   0,   0,   8,   4,   0,   4],
        [  0,   0,   0,   0,   4,   0,   4,   0,   0,  12,   0,   0,  12,   0,
           0,   0,   4,   0,   0,   0,   4,   0,   4,  12],
        [  8,   4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,
           4,   0,   0,   0,   0,   8,  12,  20,  16,  12],
        [ 16,   0,   0,   0,   4,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          28,   0,   4,   0,   0,   0,   8,  12,   4,   0],
        [  0,   4,   0,   0,   4,   0,   0,   0,   0,   0,   0,   0,   0,   4,
           0,  88,  36,   0,   0,   8,   0,   0,   4,  16],
        [  4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,
           0,   0, 120,   0,   0,  40,  12,   4,   0,  16],
        [ 16,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,  16,   4,   8,   8,   8],
        [  0,   4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   8,   0,   0,  12,   4,   0,   0,   0],
        [ 20,   0,   0,   0,   0,   0,  12,   0,   0,   4,   0,   0,   0,   0,
           0,   0,  36,   0,   0, 548,   8,   0,   0,  64],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,   4,   0,
           0,   0,   0,   0,   0,   0,  44,   4,   8,   0],
        [  4,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   8,   0,   0,   8,  12,  52,  20,  32],
        [  4,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,   0,   0,   0,
           0,   4,   4,   0,   0,  16,  24,  28,  64,  44],
        [ 12,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,
           0,   0,   0,   0,   0,  44,  16,  28,  32, 292]], device='cuda:0')
Evaluation time 0:00:11
Train Epoch: [9]  [  0/109]  eta: 0:02:56  lr: 0.000009  loss_title: 0.0862  time: 1.6199  data: 0.1506  max mem: 19067
Train Epoch: [9]  [ 50/109]  eta: 0:01:32  lr: 0.000009  loss_title: 0.2554  time: 1.5766  data: 0.1510  max mem: 19067
Train Epoch: [9]  [100/109]  eta: 0:00:14  lr: 0.000009  loss_title: 0.1338  time: 1.5815  data: 0.1483  max mem: 19067
Train Epoch: [9]  [108/109]  eta: 0:00:01  lr: 0.000009  loss_title: 0.0330  time: 1.5766  data: 0.1492  max mem: 19067
Train Epoch: [9] Total time: 0:02:51 (1.5760 s / it)
Averaged stats: lr: 0.0000  loss_title: 0.1519
Val :   [ 0/25]  eta: 0:00:11    time: 0.4742  data: 0.3125  max mem: 19067
Val :   [24/25]  eta: 0:00:00    time: 0.4613  data: 0.3041  max mem: 19067
Val :  Total time: 0:00:11 (0.4646 s / it)
F1-score: 0.3015216290950775
Accuracy: 0.5431472063064575
Specificity: 0.9789172410964966
recall: 0.3122670650482178
Precision: 0.3970435857772827
Confusion Matrics: tensor([[ 92,   8,   8,   0,   0,   0,   0,   0,   0,   4,   0,   0,   0,   4,
           0,   0,   0,   0,   0,   0,   4,   4,   4,   8],
        [  4, 140,   8,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   4,   0,   0,   0,   4],
        [  8,  16, 148,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
        [  8,   8,   4,   4,   0,   4,   0,   0,   0,   4,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   4,   4,   0,   0,   4],
        [ 24,   8,   0,   0,  24,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           8,   0,   4,   0,   0,   0,  16,   4,   0,  20],
        [  4,   0,   0,   0,   0,   8,   0,   0,   0,   4,   0,   0,   8,   8,
           4,   0,   0,   0,   0,   0,  12,   0,  20,  20],
        [ 12,   0,   4,   0,   0,   0,   4,   0,   0,   4,   0,   0,   8,   0,
           0,   0,   4,   0,   0,   8,   8,   0,   0,   0],
        [  0,   0,   0,   0,   0,   4,   0,   0,   0,   4,   0,   0,   8,   0,
           4,   0,   0,   0,   0,   0,   0,   0,   8,   4],
        [  4,   0,   4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   4,   0,   0],
        [  4,   0,   0,   0,   0,   0,   0,   0,   0,  36,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   4,  12,   0,  24,  16],
        [  0,   0,   0,   0,   0,   0,   4,   0,   0,   8,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   0,   4,   8],
        [  4,   0,   0,   0,   0,   0,   4,   0,   0,   4,   0,   0,   4,   0,
           0,   0,   4,   0,   0,   4,   0,   4,   4,   8],
        [  0,   0,   4,   0,   0,   0,   4,   0,   0,   8,   0,   0,   8,   0,
           0,   0,   4,   0,   0,   0,   4,   0,  12,  12],
        [  4,   8,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   8,
           0,   0,   0,   0,   0,  12,   0,   0,  36,  20],
        [ 12,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   4,  16,
           8,   0,   4,   0,   0,   0,   4,   8,   8,  12],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,  64,  48,   0,   4,  12,   0,   0,   8,  28],
        [  8,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   8,   0,
           0,   0,  92,   0,   4,  60,  12,   0,   0,  16],
        [  4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,  32,   0,   4,   8,  12],
        [  0,   4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   8,   0,   0,  12,   4,   0,   0,   0],
        [ 12,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,   4,   0,
           0,   0,   8,   0,   0, 576,   8,   0,   8,  72],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,  48,   0,  16,   0],
        [  0,   4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   8,   0,   0,  12,   8,  28,  36,  44],
        [  0,   4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,  12,  20,  12,  92,  52],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   4,
           0,   0,   0,   0,   0,  28,   8,   0,  52, 332]], device='cuda:0')
Evaluation time 0:00:11
Train Epoch: [10]  [  0/109]  eta: 0:02:56  lr: 0.000009  loss_title: 0.0433  time: 1.6175  data: 0.1474  max mem: 19067
Train Epoch: [10]  [ 50/109]  eta: 0:01:33  lr: 0.000009  loss_title: 0.0558  time: 1.5784  data: 0.1500  max mem: 19067
